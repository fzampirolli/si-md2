< 1.  Sistemas Inteligentes
<     =====================
< 
<     1.  Introdução
<         ----------
---
> Independentemente da natureza do sistema inteligente, ele terá que
> demonstrar habilidade para adaptar-se a mudanças em seu ambiente não
> previstas pelo projetista e tomar decisões baseadas em novos
> conhecimentos adquiridos com experiência própria. Para ilustrar a
> diferença entre um sistema tradicional e um inteligente, primeiramente
> pense num programa capaz de emitir extratos bancários a milhões de
> correntistas. Embora a implementação de tal programa possa ser algo nada
> simples, as condições em que ele vai operar podem ser minuciosamente
> antecipadas, e seu comportamento será essencialmente algorítmico. Agora
> pense num programa reconhecedor de voz humana. O projetista do sistema
> não pode prever quem vai utilizar o sistema, muito menos o conteúdo de
> sua fala. No comportamento desse sistema deve haver um componente
> empírico. Ou pense num sistema capaz de ler endereços preenchidos
> manualmente. Neste caso, não basta tentar utilizar apenas um tradicional
> reconhecedor óptico de caracteres, porque cada ser humano tem seu
> próprio estilo de escrita. É preciso desenvolver um programa que
> "aprenda" a reconhecer caracteres por meio de um treinamento com muitas
> variações de um mesmo caractere.
509,523c547,554
< Para entender o significado de "**Sistemas Inteligentes**", uma forma possível é iniciar com uma acareação sobre "Sistema" e "Inteligente". Do grego, o termo "sistema" significa "combinar", "ajustar", "formar um conjunto", como por exemplo em "sistema respiratório", que reúne vários órgãos responsáveis pelo fornecimento de oxigênio para as células, ou "sistema financeiro", que compreende pessoas, prédio, regras etc., combinados para realizar operações financeiras. Um sistema pode ser formado por um conjunto de pessoas, recursos, instalações e métodos direcionados a atingir um fim.
< 
< Embora seja muito difícil definir "inteligência", verifica-se que no "comportamento inteligente" dos seres humanos estão presentes ao menos a habilidade de resolver novos problemas, de adaptar-se às mudanças do ambiente, de fazer previsão, de raciocinar, de planejar, de tomar decisões compatíveis com determinada situação, de melhorar seu desempenho com a experiência, de comunicar, de entender, de fazer inferências lógicas, entre outras. Inteligência também tem sido definida como síntese de conhecimentos, ou seja, um **agente** possuindo a capacidade de sintetizar conhecimentos pode atingir um objetivo identificável exercitando algumas das habilidades acima enumeradas, como a do raciocínio.
< 
< Nas máquinas, a simulação de comportamento inteligente geralmente reproduz apenas partes das habilidades humanas, dentre elas a capacidade de "aprender". Basicamente, em uma abordagem operacional que mantenha somente os atributos funcionais do conceito, por **Sistema Inteligente** entende-se aquele sistema capaz de melhorar seu desempenho a partir da própria experiência. Em outras palavras, um Sistema Inteligente deve ter a capacidade de "aprender" com as informações disponíveis, ou com seus erros.
< 
< Note que na primeira tentativa de definição, inteligência estava associada à síntese de conhecimento e raciocínio para atingir um objetivo, enquanto que nesta segunda definição, inteligência está associada à melhora de desempenho e comportamento. E melhora de desempenho não necessariamente envolve conhecimento.
< 
< Entre os seres humanos, o processo cognitivo de *aprender* geralmente pressupõe *intencionalidade* ou *propósito* por parte do **sujeito**, caso contrário, utiliza-se o termo *treinamento*, quando então a intencionalidade passa a ser associada ao treinador e não ao agente sendo treinado. Porém, falar de intencionalidade em máquinas é uma questão filosoficamente controversa. Quando uma máquina produz respostas que fazem sentido para o **usuário**, pode-se detectar intencionalidade nestas respostas, mas trata-se de uma *intencionalidade derivada* da interpretação do usuário. Por isso, quando afirmamos que determinada máquina, determinado agente ou programa tem a capacidade de "aprender", estamos usando o conceito num sentido mais raso, i.e., estamos usando uma abordagem operacional ou funcional.
< 
< Um sistema inteligente pode ser um sistema físico (essencialmente hardware com capacidade adaptativa), um sistema computacional (predominantemente um software que comanda uma máquina) ou um sistema híbrido (um robô com sensores, atuadores, sistema operacional, programas computacionais etc.). Assim, por exemplo, um sistema inteligente pode ser aquele capaz de estabelecer conexão automaticamente com a internet, executar **aplicações nativas** ou **em nuvem**, fazer a análise de dados coletados e tomar uma decisão. Para o escopo deste curso, vamos nos limitar aos sistemas computacionais inteligentes, que geralmente utilizam *aprendizado de máquina* para tomar decisões inteligentes em áreas científicas, comerciais, de segurança, entre outras.
< 
< Independentemente da natureza do sistema inteligente, ele terá que demonstrar habilidade para adaptar-se a mudanças em seu ambiente não previstas pelo projetista e tomar decisões baseadas em novos conhecimentos adquiridos com experiência própria. Para ilustrar a diferença entre um sistema tradicional e um inteligente, primeiramente pense num programa capaz de emitir extratos bancários a milhões de correntistas. Embora a implementação de tal programa possa ser algo nada simples, as condições em que ele vai operar podem ser minuciosamente antecipadas, e seu comportamento será essencialmente algorítmico. Agora pense num programa reconhecedor de voz humana. O projetista do sistema não pode prever quem vai utilizar o sistema, muito menos o conteúdo de sua fala. No comportamento desse sistema deve haver um componente empírico. Ou pense num sistema capaz de ler endereços preenchidos manualmente. Neste caso, não basta tentar utilizar apenas um tradicional reconhecedor óptico de caracteres, porque cada ser humano tem seu próprio estilo de escrita. É preciso desenvolver um programa que "aprenda" a reconhecer caracteres por meio de um treinamento com muitas variações de um mesmo caractere.
< 
< Ao tentar definir inteligência, acabamos usando conceitos como *conhecimento* e *desempenho*. Precisamos, portanto, agora discorrer como se produz conhecimento e o que se entende por desempenho. Como se sabe, esta sequência de definições remete a uma recursão infinita. Por isso, para simplificar nossa tarefa e torná-la factível, vamos adotar a estratégia de definir *dado* e *informação* para chegar a *conhecimento*, e daí retornar ao conceito de *inteligência* associada a *desempenho*.
---
> Ao tentar definir inteligência, acabamos usando conceitos como
> *conhecimento* e *desempenho*. Precisamos, portanto, agora discorrer
> como se produz conhecimento e o que se entende por desempenho. Como se
> sabe, esta sequência de definições remete a uma recursão infinita. Por
> isso, para simplificar nossa tarefa e torná-la factível, vamos adotar a
> estratégia de definir *dado* e *informação* para chegar a
> *conhecimento*, e daí retornar ao conceito de *inteligência* associada a
> *desempenho*.
528,552c559,632
< Ao tentar definir conceitos muito abrangentes é conveniente limitar o domínio de aplicação, principalmente pela dificuldade de se chegar a um consenso entre especialistas, e depois porque, em nosso caso, estamos interessados em direcionar as definições ao domínio de **Tecnologia e Sistemas de Informação**. Pode parecer paradoxal afirmar que em plena "Era da Informação" não haja uma visão clara do que é *informação*. Convém, no entanto, relembrar que este mesmo cenário já ocorreu em outros períodos da história humana.
< 
< A genética mendeliana do século XIX, por exemplo, descobriu experimentalmente que certas características das ervilhas poderiam ser transmitidas através da hibridação das plantas. Mas foi preciso esperar por um século até a descoberta da estrutura do DNA para que uma teoria robusta explicasse o mecanismo da herança genética. Antes disso, as explicações dos fenômenos de transmissão de herança genética eram meramente funcionais.
< 
< É certo que vivemos na era da informação, mas ainda não temos pleno domínio sobre ela, justamente porque não conseguimos caracterizá-la adequadamente. Mesmo assim, é importante definir Dado, Informação e Conhecimento porque eles estão na base do Aprendizado.
< 
< ### Dado
< 
< É um **fato registrado** ou uma quantidade (ou qualidade) conhecida sem a necessidade de elaboração. Por ex., o peso (ou massa!) de uma pessoa, o valor da dívida de um cliente, os registros de temperatura dos últimos anos, os conceitos ou as notas de provas de alunos, o nome de um empregado etc.
< 
< ### Informação
< 
< Quando os dados apresentam alguma relação entre si, eles podem ser contextualizados ou interpretados, adquirindo um **significado**. Neste caso, a informação envolve **dados contextualizados** ou padrões de associação escondidos numa coleção de dados. Alguns dados podem fazer referência a outros dados, e não a fatos ou objetos. Esses dados são conhecidos como metadados e se confundem com o conceito de informação, ou estão na origem da informação.
< 
< Por exemplo, associando-se o peso (ou massa) de uma pessoa à sua altura, obtém-se o Índice de Massa Corporal (IMC). Nesse contexto, peso e altura são dados, IMC é informação. Apenas o valor da dívida de um cliente não permite a um gerente de banco decidir sobre um empréstimo. É necessário levar em conta a renda do cliente, ou talvez o histórico de suas movimentações, para que uma interpretação confiável de seus dados possa ser feita. A taxa de reprovação em uma disciplina é uma informação que se obtém a partir dos dados reunidos dos conceitos de provas dos alunos.
< 
< Note que o que consideramos informação em um contexto, pode tornar-se dado em outro, dependendo da referência utilizada. Por exemplo, o IMC quando relacionado à idade (ou ao sexo) de um paciente pode funcionar como um dado, que associado a outro dado, pode revelar importante informação sobre sua saúde.
< 
< ### Conhecimento
< 
< As **informações úteis a um propósito** permitem ao indivíduo compreender uma situação, ou formar uma crença justificada sobre um fato. Portanto, o conhecimento se forma a partir das informações necessárias para o **entendimento** de uma situação. Nesse contexto, conhecimento é o resultado da análise das informações relacionadas a um fato ou evento, ou ainda a percepção de como certa informação pode ajudar na realização de uma tarefa específica.
< 
< No mundo corporativo, o conhecimento produzido com regras de inferência sobre as informações analíticas da empresa ou com mineração de dados operacionais torna-se um importante aliado durante o processo de tomada de decisões gerenciais.
< 
< Embora a diferenciação entre dados, informação e conhecimento seja tênue, é comumente aceito que estes três conceitos podem ser relacionados em uma estrutura hierárquica, como a representada pela Figura 1.1.
---
> Ao tentar definir conceitos muito abrangentes é conveniente limitar o
> domínio de aplicação, principalmente pela dificuldade de se chegar a um
> consenso entre especialistas, e depois porque, em nosso caso, estamos
> interessados em direcionar as definições ao domínio de **Tecnologia e
> Sistemas de Informação**. Pode parecer paradoxal afirmar que em plena
> "Era da Informação" não haja uma visão clara do que é *informação*.
> Convém, no entanto, relembrar que este mesmo cenário já ocorreu em
> outros períodos da história humana.
> 
> A genética mendeliana do século XIX, por exemplo, descobriu
> experimentalmente que certas características das ervilhas poderiam ser
> transmitidas através da hibridação das plantas. Mas foi preciso esperar
> por um século até a descoberta da estrutura do DNA para que uma teoria
> robusta explicasse o mecanismo da herança genética. Antes disso, as
> explicações dos fenômenos de transmissão de herança genética eram
> meramente funcionais.
> 
> É certo que vivemos na era da informação, mas ainda não temos pleno
> domínio sobre ela, justamente porque não conseguimos caracterizá-la
> adequadamente. Mesmo assim, é importante definir Dado, Informação e
> Conhecimento porque eles estão na base do Aprendizado.
> 
> **Dado**
> 
> É um **fato registrado** ou uma quantidade (ou qualidade) conhecida sem
> a necessidade de elaboração. Por ex., o peso (ou massa!) de uma pessoa,
> o valor da dívida de um cliente, os registros de temperatura dos últimos
> anos, os conceitos ou as notas de provas de alunos, o nome de um
> empregado etc.
> 
> **Informação**
> 
> Quando os dados apresentam alguma relação entre si, eles podem ser
> contextualizados ou interpretados, adquirindo um **significado**. Neste
> caso, a informação envolve **dados contextualizados** ou padrões de
> associação escondidos numa coleção de dados. Alguns dados podem fazer
> referência a outros dados, e não a fatos ou objetos. Esses dados são
> conhecidos como metadados e se confundem com o conceito de informação,
> ou estão na origem da informação.
> 
> Por ex., associando-se o peso (ou massa) de uma pessoa à sua altura,
> obtém-se o Índice de Massa Corporal (IMC). Nesse contexto, peso e altura
> são dados, IMC é informação. Apenas o valor da dívida de um cliente não
> permite a um gerente de banco decidir sobre um empréstimo. É necessário
> levar em conta a renda do cliente, ou talvez o histórico de suas
> movimentações, para que uma interpretação confiável possa ser feita. A
> taxa de reprovação em uma disciplina é uma informação que se obtém a
> partir dos dados reunidos dos conceitos de provas dos alunos.
> 
> Note que o que consideramos informação em um contexto, pode tornar-se
> dado em outro, dependendo da referência utilizada. Por ex., o IMC quando
> relacionado à idade (ou ao sexo) de um paciente pode funcionar como um
> dado, que associado a outro dado, pode revelar importante informação
> sobre sua saúde.
> 
> **Conhecimento**
> 
> As **informações úteis a um propósito** permitem ao indivíduo
> compreender uma situação, ou formar uma crença justificada sobre um
> fato. Portanto, o conhecimento se forma a partir das informações
> necessárias para o **entendimento** de uma situação. Nesse contexto,
> conhecimento é o resultado da análise das informações relacionadas a um
> fato ou evento, ou ainda a percepção de como certa informação pode
> ajudar na realização de uma tarefa específica.
> 
> No mundo corporativo, o conhecimento produzido com regras de inferência
> sobre as informações analíticas da empresa ou com mineração de dados
> operacionais torna-se um importante aliado durante o processo de tomada
> de decisões gerenciais.
> 
> Embora a diferenciação entre dados, informação e conhecimento seja
> tênue, é comumente aceito que estes três conceitos podem ser
> relacionados em uma estrutura hierárquica, como a representada pela
> Figura 1.1.
556c636
< ### Desempenho
---
> **Desempenho**
558,566c638,669
< O desempenho de um sistema pode ser aferido comparando-se o resultado obtido com o esperado, ou com os recursos empregados para chegar àquele resultado. Quando alguém toma um remédio para curar uma doença, e se cura, geralmente dizemos que tal remédio foi **eficaz** porque o resultado obtido se aproximou do esperado. Note que neste caso, para medir o desempenho do sistema, comparamos sua saída com o resultado esperado.
< 
< Por outro lado, quando dizemos que a **eficiência** de um motor a combustão está em torno de 30%, estamos comparando a energia de entrada (combustível) com a de saída (potência mecânica). Agora o desempenho foi caracterizado pela relação entre entrada e saída do sistema.
< 
< ### Inteligência
< 
< Para manipular com eficiência o grande volume de dados atualmente gerados pelos processos operacionais de empresas ou instituições foram desenvolvidos Sistemas de Software Inteligentes, ou seja, sistemas capazes de aplicar conhecimentos adquiridos e melhorar seu desempenho a partir da própria experiência. No mundo corporativo, inteligência, portanto, pode ser vista como a aplicação do conhecimento gerado para a obtenção de um fim determinado, que traga uma vantagem competitiva ou evite o comprometimento de interesses.
< 
< Nas últimas décadas foram criados vários sistemas para otimizar cada etapa do processo de extração de conhecimento. Esses sistemas cuidam desde a coleta de dados operacionais de uma organização, incluindo os dados fornecidos por um especialista, passando pela Mineração de Dados, até a análise dos resultados. Atualmente o processo geral que abrange os sistemas citados para a extração de conhecimento é chamado de *Descoberta ou Extração de Conhecimento em Bases de Dados*, ou *Knowledge Discovery in Databases*, ou simplesmente *KDD*.
---
> O desempenho de um sistema pode ser aferido comparando-se o resultado
> obtido com o esperado, ou com os recursos empregados para chegar àquele
> resultado. Quando alguém toma um remédio para curar uma doença, e se
> cura, geralmente dizemos que tal remédio foi **eficaz** porque o
> resultado obtido se aproximou do esperado. Note que neste caso, para
> medir o desempenho do sistema, comparamos sua saída com o resultado
> esperado.
> 
> Por outro lado, quando dizemos que a **eficiência** de um motor a
> combustão está em torno de 30%, estamos comparando a energia de entrada
> (combustível) com a de saída (potência mecânica). Agora o desempenho foi
> caracterizado pela relação entre entrada e saída do sistema.
> 
> **Inteligência**
> 
> Para manipular com eficiência o grande volume de dados atualmente
> gerados pelos processos operacionais de empresas ou instituições foram
> desenvolvidos Sistemas de Software Inteligentes, ou seja, sistemas
> capazes de aplicar conhecimentos adquiridos e melhorar seu desempenho a
> partir da própria experiência. No mundo corporativo, inteligência,
> portanto, pode ser vista como a aplicação do conhecimento gerado para a
> obtenção de um fim determinado, que traga uma vantagem competitiva ou
> evite o comprometimento de interesses.
> 
> Nas últimas décadas foram criados vários sistemas para otimizar cada
> etapa do processo de extração de conhecimento. Esses sistemas cuidam
> desde a coleta de dados operacionais de uma organização, incluindo os
> dados fornecidos por um especialista, passando pela Mineração de Dados,
> até a análise dos resultados. Atualmente o processo geral que abrange os
> sistemas citados para a extração de conhecimento é chamado de
> *Descoberta ou Extração de Conhecimento em Bases de Dados*, ou
> *Knowledge Discovery in Databases*, ou simplesmente *KDD*.
571,577c674,705
< Modelos ideais podem não resolver plenamente problemas de sistemas reais, porque dados reais geralmente apresentam redundâncias, ausências de valores, erros, inconsistências etc. Processamento de dados geralmente requer pré-processamento, pois a qualidade dos dados de entrada pode ter um impacto significativo sobre a etapa seguinte, a de Mineração de Dados.
< 
< O que se espera com a **Mineração de Dados** é obter conhecimento, ou uma representação de conhecimento na forma de regras ou de estruturas equivalentes, que oriente uma decisão. Além disso, quando aplicado de modo inteligente, esse conhecimento alarga horizontes, permitindo fazer previsões (ou modelagem preditiva), descobrir novas associações (ou modelagem descritiva), refinar agrupamentos efetuados por critério de semelhança ou certificar-se de anomalias de comportamento.
< 
< E, com a representação do conhecimento em mãos, há a necessidade de um pós-processamento para interpretar e validar os resultados obtidos. Considere o caso de Sistemas Inteligentes conhecidos como Sistemas Especialistas, utilizados por exemplo para diagnóstico médico, que precisam expor de forma inteligível a um especialista todas as etapas do encadeamento lógico de inferências que levaram àquele resultado. Caso contrário, o médico poderá não se sentir seguro para acolher o diagnóstico produzido pelo sistema.
< 
< A Figura 1.2 ilustra as principais etapas do processo de Descoberta de Conhecimento em Bases de Dados. O propósito do ***Pré-processamento*** é eliminar eventuais problemas nos dados brutos e colocá-los num formato apropriado para a etapa seguinte, a da ***Mineração de Dados***, visando com isso melhorar significativamente a eficiência dos algoritmos que serão usados. Os dados originais podem ter sido coletados e reunidos por diferentes departamentos, apresentando valores espúrios ou ausentes, ou contendo redundâncias.
---
> Modelos ideais podem não resolver plenamente problemas de sistemas
> reais, porque dados reais geralmente apresentam redundâncias, ausências
> de valores, erros, inconsistências etc. Processamento de dados
> geralmente requerem pré-processamento, pois a qualidade dos dados de
> entrada pode ter um impacto significativo sobre a etapa seguinte, a de
> Mineração de Dados.
> 
> O que se espera com a Mineração de Dados é obter conhecimento, ou uma
> representação de conhecimento na forma de regras ou de estruturas
> equivalentes, que oriente uma decisão. Além disso, quando aplicado de
> modo inteligente, esse conhecimento alarga horizontes, permitindo fazer
> previsões (ou modelagem preditiva), descobrir novas associações (ou
> modelagem descritiva), refinar agrupamentos efetuados por critério de
> semelhança ou certificar-se de anomalias de comportamento.
> 
> E, com a representação do conhecimento em mãos, há a necessidade de um
> pós-processamento para interpretar e validar os resultados obtidos.
> Considere o caso de Sistemas Inteligentes conhecidos como Sistemas
> Especialistas, utilizados por exemplo para diagnóstico médico, que
> precisam expor de forma inteligível a um especialista todas as etapas do
> encadeamento lógico de inferências que levaram àquele resultado. Caso
> contrário, o médico poderá não se sentir seguro para acolher o
> diagnóstico produzido pelo sistema.
> 
> A Figura 1.2 ilustra as principais etapas do processo de Descoberta de
> Conhecimento em Bases de Dados. O propósito do ***Pré-processamento*** é
> eliminar eventuais problemas nos dados brutos e colocá-los num formato
> apropriado para a etapa seguinte, a da ***Mineração de Dados***, visando
> com isso melhorar significativamente a eficiência dos algoritmos que
> serão usados. Os dados originais podem ter sido coletados e reunidos por
> diferentes departamentos, apresentando valores espúrios ou ausentes, ou
> contendo redundâncias.
581,589c709,750
< Para as grandes empresas, em que geralmente há múltiplas fontes de bases de dados fisicamente separadas, é comum introduzir uma etapa intermediária de pré-processamento. As principais transformações nos dados envolvem limpeza e fusão dos dados brutos, eliminação de ruídos e redundâncias, diminuição do número de variáveis e otimização da forma de acesso.
< 
< Essas transformações podem ser feitas reunindo todos os dados num grande "depósito" ou repositório de dados, conhecido como ***Data Warehouse***, que normalmente permite a pesquisa por assunto, por período de tempo, por cliente, entre outras. Dependendo da quantidade de dados envolvidos, esta etapa pode se tornar a mais demorada e trabalhosa das três etapas.
< 
< Na etapa de ***Mineração de Dados***, o objetivo é descobrir de forma automatizada relações ou padrões implícitos em grandes quantidades de dados, ou comprovar alguma hipótese a partir de informações até então não facilmente perceptíveis nos dados. Antes do desenvolvimento da Mineração de Dados, a Estatística já oferecia várias técnicas para análise de dados, porém isso era feito de forma manual, restringindo sua aplicação a bases de dados relativamente pequenas. A Mineração de Dados evoluiu com a disseminação generalizada de sistemas computacionais, que quando associados a técnicas de Inteligência Artificial, por exemplo aplicadas na área de Banco de Dados, permitiriam a geração automática de conhecimentos implícitos nos dados.
< 
< Finalmente, na etapa de ***Pós-processamento***, é possível visualizar e interpretar as regras ou os padrões obtidos com a Mineração de Dados, e eliminar os resultados equivocados ou pouco representativos. Nesta fase é bem comum a aplicação de testes estatísticos para validação dos resultados. Dependendo dos valores obtidos, o processo de Descoberta de Conhecimento pode sugerir uma nova iteração, com uma volta à etapa de Mineração de Dados, quando então o processo é repetido com valores de parâmetros modificados ou com a utilização de novos algoritmos.
< 
< Como se vê, a etapa em que efetivamente se dá a descoberta de conhecimento é a da **Mineração de Dados**. Muitas ferramentas originalmente implementadas apenas para a etapa de Mineração de Dados atualmente permitem fazer também o pré e o pós-processamento. Por isso, na prática, vários autores consideram os termos Descoberta de Conhecimento e Mineração de Dados como equivalentes. A seguir, vamos focar de modo mais detalhado as principais tarefas da Mineração de Dados.
---
> Para as grandes empresas, em que geralmente há múltiplas fontes de bases
> de dados fisicamente separadas, é comum introduzir uma etapa
> intermediária de pré-processamento. As principais transformações nos
> dados envolvem limpeza e fusão dos dados brutos, eliminação de ruídos e
> redundâncias, diminuição do número de variáveis e otimização da forma de
> acesso.
> 
> Essas transformações podem ser feitas reunindo todos os dados num grande
> "depósito" ou repositório de dados, conhecido como ***Data Warehouse***,
> que normalmente permite a pesquisa por assunto, por período de tempo,
> por cliente, entre outras. Dependendo da quantidade de dados envolvidos,
> esta etapa pode se tornar a mais demorada e trabalhosa das três etapas.
> 
> Na etapa de ***Mineração de Dados***, o objetivo é descobrir de forma
> automatizada relações ou padrões implícitos em grandes quantidades de
> dados, ou comprovar alguma hipótese a partir de informações até então
> não facilmente perceptíveis nos dados. Antes do desenvolvimento da
> Mineração de Dados, a Estatística já possuía várias técnicas para
> análise de dados, porém isso era feito de forma manual, restringindo sua
> aplicação a bases de dados relativamente pequenas. A Mineração de Dados
> evoluiu com a disseminação generalizada de sistemas computacionais, que
> quando associados a técnicas de Inteligência Artificial, por exemplo
> aplicadas na área de Banco de Dados, permitiam a geração automática de
> conhecimentos implícitos nos dados.
> 
> Finalmente, na etapa de ***Pós-processamento***, é possível visualizar e
> interpretar as regras ou os padrões obtidos com a Mineração de Dados, e
> eliminar os resultados equivocados ou pouco representativos. Nesta fase
> é bem comum a aplicação de testes estatísticos para validação dos
> resultados. Dependendo dos valores obtidos, o processo de Descoberta de
> Conhecimento pode sugerir uma nova iteração, com uma volta à etapa de
> Mineração de Dados, quando então o processo é repetido com valores de
> parâmetros modificados ou com a utilização de novos algoritmos.
> 
> Como se vê, a etapa em que efetivamente se dá a descoberta de
> conhecimento é a da **Mineração de Dados**. Muitas ferramentas
> originalmente implementadas apenas para a etapa de Mineração de Dados
> atualmente permitem fazer também o pré e o pós-processamento. Por isso,
> na prática, vários autores consideram os termos Descoberta de
> Conhecimento e Mineração de Dados como equivalentes. A seguir, vamos
> focar de modo mais detalhado as principais tarefas da Mineração de
> Dados.
594,610c755,834
< O crescimento exponencial de dados gerados em praticamente quase todas as áreas de atividade humana, seja ela científica, comercial, lazer, industrial, entre outras, acabou tornando inviável, a certa altura, a análise sistemática baseada em técnicas estatísticas manuais de grandes bases de dados. É nesse contexto que pesquisadores da área de Inteligência Artificial, combinando técnicas da Estatística e de programação avançada, começaram a desenvolver programas para extração e sumarização automática de informação útil de grandes Bases de Dados e criaram uma nova disciplina chamada *Mineração de Dados*.
< 
< Na Mineração de Dados, dependendo do objetivo a ser atingido, ou seja, do tipo de conhecimento a ser gerado, diferentes tarefas poderão ser executadas sobre a Base de Dados. As principais tarefas da Mineração de Dados são:
< 
< **Associação** -- na tarefa de Associação, partindo de um conjunto de itens o objetivo é encontrar **Regras de Associação** entre itens que ocorrem simultaneamente. Um conjunto de itens pode ser uma cesta de artigos com código de barras vendidos num supermercado ou numa livraria on-line, e o fato de dois artigos serem frequentemente comprados conjuntamente é de grande interesse para o proprietário. Note que a ocorrência simultânea de dois ou mais itens não implica necessariamente relação de causalidade. Note também que na prática o número de regras de associação de uma cesta pequena de artigos pode ser proibitivamente elevado. Isso nos obriga a lançar mão de medidas de qualidade ou de desempenho para eliminar as inúmeras regras que se aplicam a poucas transações desses artigos, e selecionar apenas as Regras de Associação que tenham uma grande abrangência ou cobertura sobre o total de transações.
< 
< **Classificação** -- na tarefa de Classificação, a partir de uma série de exemplos previamente rotulados em duas ou mais classes, o objetivo é aprender a classificar um novo exemplo, cuja classe é desconhecida. As classes apresentam resultados discretos, como sim/não, ou baixo, médio e alto risco etc. Por exemplo, para as classes remédio e vitamina, com base nas características de determinado item X, interessa saber qual a classe este item melhor se encaixa. Quando os resultados esperados não pertencerem a classes discretas, ou seja, quando a variável de predição for real, a classificação recebe o nome de **Regressão**.
< 
< **Clusterização** -- na tarefa de Clusterização ou Agrupamento, um grupo de registros diversos de uma Base de Dados deve ser segmentado em subgrupos contendo registros similares. Ao contrário da Classificação, na Clusterização não há classes previamente definidas. O critério de agrupamento entre registros é a similaridade dos atributos ou das características dos registros.
< 
< **Detecção de Anomalias** -- na tarefa de Detecção de Anomalias, o objetivo é detectar desvios de um comportamento considerado normal, e caracterizar uma situação como anormal ou não. Empresas de cartão de crédito utilizam os registros de movimentação de um cartão para impedir que um fraudador decidido a fazer muitas compras em pouco tempo se passe pelo proprietário legítimo do cartão.
< 
< Em linhas gerais, as tarefas da Mineração de Dados são de natureza ***descritiva*** ou ***preditiva***. Numa rede de supermercados pode ser extremamente valioso descobrir quais produtos são comprados juntos. Por exemplo, ao se descobrir que os produtos A, G e M são quase sempre comprados juntos, a simples alteração da posição das gôndolas desses produtos pode aumentar as vendas. Em situações desse tipo, em que o conhecimento extraído auxilia na interpretação da massa de dados, os padrões de associação descobertos nos produtos oferecidos têm um caráter **essencialmente descritivo**.
< 
< Já em certos ramos empresariais, pode ser muito importante descobrir qual o comportamento típico de clientes que estão prestes a mudar de fornecedor, e, com base em suas características, construir um *modelo* que auxilie na previsão de comportamentos futuros. Geralmente vale mais a pena usar técnicas de fidelização para reter um cliente bom e antigo do que investir na busca de novos clientes, cuja fidelidade ainda é incerta. Usando o modelo de comportamento previamente desenvolvido, juntamente com o histórico de compras de um cliente, é possível fazer algumas inferências e prever qual será o possível desfecho. Tarefas que procuram predizer se um item pertence a uma classe ou não, são **essencialmente preditivas**.
< 
< A Figura 1.3 ilustra a classificação das principais tarefas de Mineração de Dados em Atividades Descritivas ou Preditivas. Vale ressaltar que, dependendo de como for implementada a "Detecção de Anomalia", esta tarefa poderá ser mais bem caracterizada como de natureza descritiva.
---
> O crescimento exponencial de dados gerados em praticamente quase todas
> as áreas de atividade humana, seja ela científica, comercial, lazer,
> industrial, entre outras, acabou tornando inviável, a certa altura, a
> análise sistemática baseada em técnicas estatísticas manuais de grandes
> bases de dados. É nesse contexto que pesquisadores da área de
> Inteligência Artificial, combinando técnicas da Estatística e de
> programação avançada, começaram a desenvolver programas para extração e
> sumarização automática de informação útil de grandes Bases de Dados e
> criaram uma nova disciplina chamada *Mineração de Dados*.
> 
> Na Mineração de Dados, dependendo do objetivo a ser atingido, ou seja,
> do tipo de conhecimento a ser gerado, diferentes tarefas poderão ser
> executadas sobre a Base de Dados. As principais tarefas da Mineração de
> Dados são:
> 
> **Associação** -- na tarefa de Associação, partindo de um conjunto de
> itens o objetivo é encontrar **Regras de Associação** entre itens que
> ocorrem simultaneamente. Um conjunto de itens pode ser uma cesta de
> artigos com código de barras vendidos num supermercado ou numa livraria
> on-line, e o fato de dois artigos serem frequentemente comprados
> conjuntamente é de grande interesse para o proprietário. Note que a
> ocorrência simultânea de dois ou mais itens não implica necessariamente
> relação de causalidade. Note também que na prática o número de regras de
> associação de uma cesta pequena de artigos pode ser proibitivamente
> elevado. Isso nos obriga a lançar mão de medidas de qualidade ou de
> desempenho para eliminar as inúmeras regras que se aplicam a poucas
> transações desses artigos, e selecionar apenas as Regras de Associação
> que tenham uma grande abrangência ou cobertura sobre o total de
> transações.
> 
> **Classificação** -- na tarefa de Classificação, a partir de uma série
> de exemplos previamente rotulados em duas ou mais classes, o objetivo é
> aprender a classificar um novo exemplo, cuja classe é desconhecida. As
> classes apresentam resultados discretos, como sim/não, ou baixo, médio e
> alto risco etc. Por exemplo, para as classes remédio e vitamina, com
> base nas características de determinado item X, interessa saber qual a
> classe este item melhor se encaixa. Quando os resultados esperados não
> pertencerem a classes discretas, ou seja, quando a variável de predição
> for real, a classificação recebe o nome de **Regressão**.
> 
> **Clusterização** -- na tarefa de Clusterização ou Agrupamento, um grupo
> de registros diversos de uma Base de Dados deve ser segmentado em
> subgrupos contendo registros similares. Ao contrário da Classificação,
> na Clusterização não há classes previamente definidas. O critério de
> agrupamento entre registros é a similaridade dos atributos ou das
> características dos registros.
> 
> **Detecção de Anomalias** -- na tarefa de Detecção de Anomalias, o
> objetivo é detectar desvios de um comportamento considerado normal, e
> caracterizar uma situação como anormal ou não. Empresas de cartão de
> crédito utilizam os registros de movimentação de um cartão para impedir
> que um fraudador decidido a fazer muitas compras em pouco tempo se passe
> pelo proprietário legítimo do cartão.
> 
> Em linhas gerais, as tarefas da Mineração de Dados são de natureza
> ***descritiva*** ou ***preditiva***. Numa rede de supermercados pode ser
> extremamente valioso descobrir quais produtos são comprados juntos. Por
> exemplo, ao se descobrir que os produtos A, G e M são quase sempre
> comprados juntos, a simples alteração da posição das gôndolas desses
> produtos pode aumentar as vendas. Em situações desse tipo, em que o
> conhecimento extraído auxilia na interpretação da massa de dados, os
> padrões de associação descobertos nos produtos oferecidos têm um caráter
> **essencialmente descritivo**.
> 
> Já em certos ramos empresariais, pode ser muito importante descobrir
> qual o comportamento típico de clientes que estão prestes a mudar de
> fornecedor, e, com base em suas características, construir um *modelo*
> que auxilie na previsão de comportamentos futuros. Geralmente vale mais
> a pena usar técnicas de fidelização para reter um cliente bom e antigo
> do que investir na busca de novos clientes, cuja fidelidade ainda é
> incerta. Usando o modelo de comportamento previamente desenvolvido,
> juntamente com o histórico de compras de um cliente, é possível fazer
> algumas inferências e prever qual será o possível desfecho. Tarefas que
> procuram predizer se um item pertence a uma classe ou não, são
> **essencialmente preditivas**.
> 
> A Figura 1.3 ilustra a classificação das principais tarefas de Mineração
> de Dados em Atividades Descritivas ou Preditivas. Vale ressaltar que,
> dependendo de como for implementada a "Detecção de Anomalia", esta
> tarefa poderá ser mais bem caracterizada como de natureza descritiva.
615c839,845
< Como o uso de dados pessoais na Mineração de Dados pode afetar a privacidade de pessoas ou discriminar grupos socialmente fragilizados, suas implicações éticas têm sido amplamente discutidas na imprensa, na academia, nos meios jurídicos e no mundo corporativo. Quando se pensa na política das companhias de seguro, por exemplo, argumenta-se que um cliente é geralmente julgado mais pelos atributos do grupo ao qual ele se enquadra e nem tanto pelas suas próprias características.
---
> Como o uso de dados pessoais na Mineração de Dados pode afetar a
> privacidade de pessoas ou discriminar grupos socialmente fragilizados,
> suas implicações éticas têm sido amplamente discutidas na imprensa, na
> academia, nos meios jurídicos e no mundo corporativo. Quando se pensa na
> política das companhias de seguro, por ex., argumenta-se que um cliente
> é geralmente julgado mais pelos atributos do grupo ao qual ele se
> enquadra e nem tanto pelas suas próprias características.
619,623c849,874
< Os dados sobre pagamentos feitos com cartão de crédito podem expor as preferências religiosas de seu dono. Seus hábitos de compras de livros podem revelar suas preferências políticas, ou gastos elevados podem colocá-lo inadvertidamente no grupo de clientes de alto risco para empréstimo bancário. O CEP de um candidato pode apontar que ele vive em uma região considerada problemática ou num bairro nobre, seus dados médicos podem lhe custar uma vaga numa grande empresa.
< 
< Por outro lado, as estatísticas sobre determinada modalidade de crime podem ajudar as autoridades policiais a adotar medidas preventivas. O levantamento estatístico de regiões carentes frequentemente serve de orientação aos formuladores de políticas públicas na hora de conceber ações compensatórias localizadas. A análise dos dados de gasto do governo pode ajudar a corrigir distorções ou denunciar mazelas. O conhecimento prévio de que algumas doenças e problemas de saúde parecem estar mais fortemente associados a uma etnia que a outra auxilia o médico na hora de solicitar exames médicos, mesmo que o paciente não apresente nenhum sintoma.
< 
< Como se vê, não é nada simples traçar uma linha divisória que condene ou justifique o uso ético ou legal de dados armazenados. E se os dados tiverem sido coletados sem o conhecimento do usuário, a questão torna-se ainda mais controversa. Por esta razão, e por se tratar de uma tecnologia relativamente jovem, recomenda-se que a Mineração de Dados seja empregada com cautela e, se possível, com a anuência prévia das pessoas cujos dados foram coletados.
---
> Os dados sobre pagamentos feitos com cartão de crédito podem expor as
> preferências religiosas de seu dono, assim como seus hábitos de compras
> de livros podem revelar suas preferências políticas, ou gastos elevados
> podem colocá-lo inadvertidamente no grupo de clientes de alto risco para
> empréstimo bancário. O CEP de um candidato pode apontar que ele vive em
> uma região considerada problemática ou num bairro nobre, seus dados
> médicos podem lhe custar uma vaga numa grande empresa.
> 
> Por outro lado, as estatísticas sobre determinada modalidade de crime
> podem ajudar as autoridades policiais a adotar medidas preventivas. O
> levantamento estatístico de regiões carentes frequentemente serve de
> orientação aos formuladores de políticas públicas na hora de conceber
> ações compensatórias localizadas. A análise dos dados de gasto do
> governo pode ajudar a corrigir distorções ou denunciar mazelas. O
> conhecimento prévio de que algumas doenças e problemas de saúde parecem
> estar mais fortemente associados a uma etnia que a outra auxilia o
> médico na hora de solicitar exames médicos, mesmo que o paciente não
> apresente nenhum sintoma.
> 
> Como se vê, não é nada simples traçar uma linha divisória que condene ou
> justifique o uso ético ou legal de dados armazenados. E se os dados
> tiverem sido coletados sem o conhecimento do usuário, a questão torna-se
> ainda mais controversa. Por esta razão, e por se tratar de uma
> tecnologia relativamente jovem, recomenda-se que a Mineração de Dados
> seja empregada com cautela e, se possível, com a anuência prévia das
> pessoas cujos dados foram coletados.
628c879,880
< 1\. Defina com suas próprias palavras e exemplos o que é **Dado**, **Informação** e **Conhecimento**.
---
> 1\. (20%) Defina com suas próprias palavras e exemplos o que é **Dado**,
> **Informação** e **Conhecimento**.
630,634c882,905
< 2\. Considerando a **definição meramente operacional** de que **aprender é mudar o comportamento com base em sua própria experiência de forma a melhorar o desempenho futuro**, justifique se um sapato amaciado pode ter aprendido alguma coisa (WITTEN, I. H. & FRANK, E., 2005).
< 
< 3\. Qual a diferença entre **Mineração de Dados** e **Recuperação de Dados *(Data Retrieval)***?
< 
< 4\. Explique com suas próprias palavras as **principais tarefas da Mineração de Dados**.
---
> 2\. (30%) Considerando a **definição meramente operacional** de que
> **aprender é mudar o comportamento com base em sua própria experiência
> de forma a melhorar o desempenho futuro**, justifique se um sapato
> amaciado pode ter aprendido alguma coisa.
> 
> 3\. (20%) Qual a diferença entre **Mineração de Dados** e **Recuperação
> de Dados *(Data Retrieval)***?
> 
> 4\. (30%) Explique com suas próprias palavras as **principais tarefas da
> Mineração de Dados**.
> 
> **PS1** -- Como pode ser visto, não há uma "resposta correta" para as
> perguntas formuladas. Seu trabalho vai ser avaliado considerando muito
> mais a coerência da argumentação, e a riqueza dos exemplos, do que a
> concordância ou não com os conceitos passados. Procure ser conciso,
> porque normalmente textos prolixos só dificultam a compreensão do
> argumento, mas evite a linguagem telegráfica, porque você precisa deixar
> bem claro seu ponto de vista.
> 
> **PS2** -- Há um ditado popular, segundo o qual "uma figura fala mais do
> que mil palavras". Nem sempre este ditado é verdadeiro: por exemplo,
> tente expressar este mesmo ditado com uma figura! Mas, em inúmeras
> situações ele é muito útil. Se você achar que um desenho e/ou uma figura
> pode(m) ajudar suas respostas, lance mão desse recurso!
639,653c910,911
< FOROUZAN, B. & MOSHARRAF, F. **Fundamentos da Ciência da Computação.** São Paulo: Cengage Learning, 2011.
< 
< GOLDSCHMIDT, R. & PASSOS, E. **Data Mining: Um Guia Prático**. Rio de Janeiro: Elsevier, 2005.
< 
< HAN, J. & KAMBER, M. **Data Mining: Concepts and Techniques.** San Francisco: Morgan Kaufmann Publishers, 2008.
< 
< PADHY, N. P. **Artificial Intelligence and Intelligent Systems.** New Delhi: Oxford University Press, 2010.
< 
< PINHEIRO, C. A. R. **Inteligência Analítica: Mineração de Dados e Descoberta de Conhecimento.** Rio de Janeiro: Editora Ciência Moderna Ltda., 2008.
< 
< REZENDE, S. O. (Organizadora). **Sistemas Inteligentes: Fundamentos e Aplicações.** Barueri: Editora Manole Ltda, 2005.
< 
< RUSSEL, S. & NORVIG, P. **Inteligência Artificial.** Rio de Janeiro: Elsevier, 2004.
< 
< TAN, P.N.; STEINBACH, M. & KUMAR, V. **Introdução ao Data Mining Mineração de Dados.** Rio de Janeiro: Editora Ciência Moderna Ltda., 2009.
---
> FOROUZAN, B. & MOSHARRAF, F. **Fundamentos da Ciência da Computação.**
> São Paulo: Cengage Learning, 2011.
655c913,914
< WITTEN, I. H. & FRANK, E. **Data Mining: Practical Machine Learning Tools and Techniques.** Second Edition. Amsterdam: Morgan Kaufmann Publishers, 2005.
---
> GOLDSCHMIDT, R. & PASSOS, E. **Data Mining: Um Guia Prático**. Rio de
> Janeiro: Elsevier, 2005.
657,658c916,917
< 2.  Mineração de Dados e Regras de Associação
<     =========================================
---
> HAN, J. & KAMBER, M. **Data Mining: Concepts and Techniques.** San
> Francisco: Morgan Kaufmann Publishers, 2008.
660,663c919,953
<     1.  Introdução
<         ----------
< 
< A Mineração de Dados é uma disciplina tão vasta que qualquer publicação sobre o tema obriga o autor a selecionar alguns tópicos em detrimento de outros não menos importantes. A atividade de **Regras de Associação** foi o tópico escolhido para iniciarmos a apresentação das principais tarefas da Mineração de Dados por envolver ideias bem intuitivas. A analogia entre Regras de Associação e Cesta de Compras facilita o entendimento de como descobrir padrões de associação entre itens de um conjunto qualquer.
---
> PADHY, N. P. **Artificial Intelligence and Intelligent Systems.** New
> Delhi: Oxford University Press, 2010.
> 
> PINHEIRO, C. A. R. **Inteligência Analítica: Mineração de Dados e
> Descoberta de Conhecimento.** Rio de Janeiro: Editora Ciência Moderna
> Ltda., 2008.
> 
> REZENDE, S. O. (Organizadora). **Sistemas Inteligentes: Fundamentos e
> Aplicações.** Barueri: Editora Manole Ltda, 2005.
> 
> RUSSEL, S. & NORVIG, P. **Inteligência Artificial.** Rio de Janeiro:
> Elsevier, 2004.
> 
> TAN, P.N.; STEINBACH, M. & KUMAR, V. **Introdução ao Data Mining
> Mineração de Dados.** Rio de Janeiro: Editora Ciência Moderna Ltda.,
> 2009.
> 
> WITTEN, I. H. & FRANK, E. **Data Mining: Practical Machine Learning
> Tools and Techniques.** Second Edition. Amsterdam: Morgan Kaufmann
> Publishers, 2005.
> 
> Mineração de Dados e Regras de Associação
> =========================================
> 
> Introdução
> ----------
> 
> A Mineração de Dados é uma disciplina tão vasta que qualquer publicação
> sobre o tema obriga o autor a selecionar alguns tópicos em detrimento de
> outros não menos importantes. A atividade de **Regras de Associação**
> foi o tópico escolhido para iniciarmos a apresentação das principais
> atividades da Mineração de Dados por envolver ideias bem intuitivas. A
> analogia entre Regras de Associação e Cesta de Compras facilita o
> entendimento de como descobrir padrões de associação entre itens de um
> conjunto qualquer.
668,674c958,992
< Durante o processo de **Descoberta de Conhecimento em Bases de Dados**, **KDD**, é na etapa de **Mineração de Dados** que efetivamente são encontrados os padrões de associação implícitos nos dados. A análise automatizada dessa massa de dados visa detectar regularidades, ou quebra de regularidade, que constitui informação implícita, porém supostamente desconhecida, e útil para determinado fim.
< 
< A Mineração de Dados pode ser vista como a sistematização de teorias, técnicas e algoritmos desenvolvidos em outras disciplinas já consagradas, como a Estatística, a Inteligência Artificial, o Aprendizado de Máquina, a Base de Dados etc. (Figura 2.1). O propósito da Mineração de Dados é detectar automaticamente padrões de associação úteis e não óbvios em grandes quantidades de dados.
< 
< No dia a dia, uma quantidade incalculável de dados é gerada na forma de registros de vendas, textos brutos, imagens, sons, gráficos etc., tanto por sistemas computacionais como por seres humanos, constituindo uma espécie de informação não estruturada. Embora esta forma de registro de dados seja adequada para o ser humano, quando se trata de analisar grandes quantidades de dados de forma automatizada, é comum e conveniente que se introduza alguma **estrutura** que facilite o acesso e o processamento sistemático.
< 
< Figura .-- A Relação da Mineração de Dados com Algumas Disciplinas Correlatas.
---
> Durante o processo de **Descoberta de Conhecimento em Bases de Dados**,
> **KDD**, é na etapa de **Mineração de Dados** que efetivamente são
> encontrados os padrões de associação implícitos nos dados. A análise
> automatizada dessa massa de dados visa detectar regularidades, ou quebra
> de regularidade, que constitui informação implícita, porém desconhecida,
> e útil para determinado fim.
> 
> A Mineração de Dados pode ser vista como a sistematização de teorias,
> técnicas e algoritmos desenvolvidos em outras disciplinas já
> consagradas, como a Estatística, a Inteligência Artificial, o
> Aprendizado de Máquina, a Base de Dados etc. O propósito da Mineração de
> Dados é detectar automaticamente padrões de associação úteis e não
> óbvios em grandes quantidades de dados, veja Figura 2.1.
> 
> No dia a dia, uma quantidade incalculável de dados é gerada na forma de
> registros de vendas, textos brutos, imagens, sons, gráficos etc., tanto
> por sistemas computacionais como por seres humanos, constituindo uma
> espécie de informação não estruturada. Embora esta forma de registro de
> dados seja adequada para o ser humano, quando se trata de analisar
> grandes quantidades de dados de forma automatizada, é comum e
> conveniente que se introduza alguma **estrutura** que facilite o acesso
> e o processamento sistemático.
> 
> Figura .-- A Relação da Mineração de Dados com algumas Disciplinas
> Correlatas.
> 
> Para que parte de toda essa informação não estruturada possa ser
> utilizada na Mineração de Dados, geralmente é feita uma seleção e um
> pré-processamento visando transformar dados brutos em coleções
> estruturadas de dados. Em termos práticos, para nossas considerações
> iniciais, a estrutura de representação de uma Base de Dados pode ser
> semelhante a uma tabela de dados, sendo cada linha dessa tabela uma
> **transação** ou um **exemplo**. Cada **transação** é composta por um ou
> mais **itens** ou, visto de outra forma, cada **exemplo** é
> caracterizado por seus **atributos**.
676,678c994,995
< Para que parte de toda essa informação não estruturada possa ser utilizada na Mineração de Dados, geralmente é feita uma seleção e um pré-processamento visando transformar dados brutos em coleções estruturadas de dados. Em termos práticos, para nossas considerações iniciais, a estrutura de representação de uma Base de Dados pode ser semelhante a uma tabela de dados, sendo cada linha dessa tabela uma **transação** ou um **exemplo**. Cada **transação** é composta por um ou mais **itens** ou, visto de outra forma, cada **exemplo** é caracterizado por seus **atributos**.
< 
< As Tabelas 2.1, 2.2 e 2.3 ilustram formas de dados estruturados convenientes para a Mineração de Dados.
---
> As Tabelas 2.1, 2.2 e 2.3 ilustram formas de dados estruturados
> convenientes para a Mineração de Dados.
690c1007,1011
< Na Tabela 2.1 cada uma das Transações possui uma IDentificação (TID), e seus itens representam artigos vendidos em um supermercado. Se a tabela de itens for muito extensa, como costuma ser em casos reais, pode ser ainda mais conveniente representar cada um de seus itens na forma de um atributo associado a um valor booleano, como mostra a Tabela 2.2.
---
> Na Tabela 2.1 cada uma das Transações possui uma IDentificação (TID), e
> seus itens representam artigos vendidos em um supermercado. Se a tabela
> de itens for muito extensa, como costuma ser em casos reais, pode ser
> ainda mais conveniente representar cada um de seus itens na forma de um
> atributo associado a um valor booleano, como mostra a Tabela 2.2.
702c1023,1032
< Um exemplo clássico de uma Base de Dados usada em artigos sobre Mineração de Dados é apresentada na Tabela 2.3 (QUINLAN, 1986, *apud* WITTEN & FRANK, 2005), composta por dados fictícios sobre as condições de tempo para que ocorra ou não a partida de um esporte não especificado. A tabela é composta por 14 exemplos (linhas), cada um com cinco atributos (colunas): Dia, Temperatura, Umidade, Vento e Partida. A tabela pode também ser interpretada de outra forma, como sendo composta por quatro atributos (Dia, Temperatura, Umidade e Vento) e uma classe (Partida), que representa o resultado da combinação dos quatro atributos.
---
> Um exemplo clássico de uma Base de Dados usada em artigos sobre
> Mineração de Dados é apresentada na Tabela 2.3 (Quinlan, 1986, apud
> Witten & Frank, 2005), composta por dados fictícios sobre as condições
> de tempo para que ocorra ou não a partida de um esporte não
> especificado. A tabela é composta por 14 exemplos (linhas), cada um com
> cinco atributos (colunas): Dia, Temperatura, Umidade, Vento e Partida. A
> tabela pode também ser interpretada de outra forma, como sendo composta
> por quatro atributos (Dia, Temperatura, Umidade e Vento) e uma classe
> (Partida), que representa o resultado da combinação dos quatro
> atributos.
723c1053,1055
< Uma análise mais atenta dos exemplos das Tabelas 2.1 e 2.3 mostra que alguns desses atributos sempre aparecem juntos e que, portanto, várias **Regras de Associação** podem ser extraídas dessas tabelas.
---
> Uma análise mais atenta dos exemplos das Tabelas 2.1 e 2.3 mostra que
> alguns desses atributos sempre aparecem juntos e que, portanto, várias
> **Regras de Associação** podem ser extraídas dessas tabelas.
728,732c1060,1081
< A representação do conhecimento através de regras, também conhecidas como regras *IF-THEN* ou Regras de Produção, é largamente utilizada porque, entre outras vantagens sobre formas alternativas de representação do conhecimento, regras são facilmente compreendidas pelo ser humano, fáceis de serem alteradas, validadas e verificadas, e de baixo custo para a criação de sistemas baseados em regras (PADHY, N. P., 2010).
< 
< **Regras de Associação** são uma forma específica de representação de conhecimento que descrevem padrões de associação implícitos entre um conjunto de atributos ou itens de uma Base de Dados, e que podem ajudar a predizer com alta probabilidade a presença, ou não, de outro conjunto de atributos ou itens.
< 
< Dito de forma equivalente, uma Regra de Associação revela que a presença de um conjunto **X** de itens numa transação implica outro conjunto **Y** de itens, i.e., **X** = {a, b, \...} **⇒** **Y** = {p, \..., z}. Note que o fato de um conjunto de itens **X** (antecedente) estar sempre associado a outro **Y** (consequente) não significa obrigatoriamente que um seja a causa de outro, i.e., não há necessariamente relação de causalidade entre antecedente e consequente e sim mera ocorrência simultânea de itens com certa probabilidade.
---
> A representação do conhecimento através de regras, também conhecidas
> como regras *IF-THEN* ou Regras de Produção, é largamente utilizada
> porque, entre outras vantagens sobre formas alternativas de
> representação do conhecimento, são facilmente compreendidas pelo ser
> humano, fáceis de serem alteradas, validadas e verificadas, e de baixo
> custo para a criação de sistemas baseados em regras (Padhy, N. P.,
> 2010).
> 
> **Regras de Associação** são uma forma específica de representação de
> conhecimento que descrevem padrões de associação implícitos entre um
> conjunto de atributos ou itens de uma Base de Dados, e que podem ajudar
> a predizer com alta probabilidade a presença, ou não, de outro conjunto
> de atributos ou itens.
> 
> Dito de forma equivalente, uma Regra de Associação revela que a presença
> de um conjunto **X** de itens numa transação implica outro conjunto
> **Y** de itens, i.e., **X** = {a, b, \...} **⇒** **Y** = {p, \..., z}.
> Note que o fato de um conjunto de itens **X** (antecedente) estar sempre
> associado a outro **Y** (consequente) não significa obrigatoriamente que
> um seja a causa de outro, i.e., não há necessariamente relação de
> causalidade entre antecedente e consequente e sim mera ocorrência
> simultânea de itens com certa probabilidade.
736c1085,1086
< ***If*** (Conjunto **X** de Itens) ***then*** (Conjunto **Y** de Itens), sendo **X∩Y=∅**.
---
> ***If*** (Conjunto **X** de Itens) ***then*** (Conjunto **Y** de Itens),
> sendo **X∩Y=∅**.
738c1088,1089
< Com base na Figura 2.3, várias Regras de Associação podem ser formuladas:
---
> Com base na Figura 2.3, várias Regras de Associação podem ser
> formuladas:
742c1093,1094
< ***If*** (Umidade**=**Normal) ***and*** (Vento**=**Falso) ***then*** (Partida**=**Sim) (2.2)
---
> ***If*** (Umidade**=**Normal) ***and*** (Vento**=**Falso) ***then***
> (Partida**=**Sim) (2.2)
744c1096,1097
< ***If*** (Dia**=**Ensolarado) ***and*** (Partida**=**Não) ***then*** (Umidade**=**Alta) (2.3)
---
> ***If*** (Dia**=**Ensolarado) ***and*** (Partida**=**Não) ***then***
> (Umidade**=**Alta) (2.3)
746c1099,1100
< ***If*** (Vento**=**Falso) ***and*** (Partida**=**Não) ***then*** (Temperatura**=**Elevada) ***and*** (Umidade**=**Alta) (2.4)
---
> ***If*** (Vento**=**Falso) ***and*** (Partida**=**Não) ***then***
> (Temperatura**=**Elevada) ***and*** (Umidade**=**Alta) (2.4)
748,750c1102,1113
< Estas são apenas algumas das muitas Regras de Associação que podem ser formuladas com base na Tabela 2.3. Para selecionar as Regras de Associação mais representativas, i.e., aquelas que se apliquem a um grande número de exemplos com alta probabilidade de acerto, precisaremos de métricas para avaliar o alcance ou a força de cada regra. Dois dos mais conhecidos indicadores são **Suporte** e **Confiança**.
< 
< **Suporte** -- para cada regra do tipo **X ⇒ Y**, este parâmetro indica a quantos exemplos da tabela esta regra satisfaz (i.e., contém) tanto ao conjunto de itens de **X** quanto ao de **Y**, ou seja, indica sua **cobertura** com relação ao número total ***N*** de exemplos da tabela. Portanto,
---
> Estas são apenas algumas das muitas Regras de Associação que podem ser
> formuladas com base na Tabela 2.3. Para selecionar as Regras de
> Associação mais representativas, i.e., aquelas que se apliquem a um
> grande número de exemplos com alta probabilidade de acerto, precisaremos
> de métricas para avaliar o alcance ou a força de cada regra. Dois dos
> mais conhecidos indicadores são **Suporte** e **Confiança**.
> 
> **Suporte** -- para cada regra do tipo **X ⇒ Y**, este parâmetro indica
> a quantos exemplos da tabela esta regra satisfaz (i.e., contém) tanto ao
> conjunto de itens de **X** quanto ao de **Y**, ou seja, indica sua
> **cobertura** com relação ao número total ***N*** de exemplos da tabela.
> Portanto,
754c1117,1118
< Por exemplo, com relação à primeira regra (2.1) há quatro exemplos na Tabela 2.3 em que {**X ∪ Y**} = {Temperatura=Baixa, Umidade=Normal}. Portanto,
---
> Por ex., com relação à primeira regra (2.1) há quatro exemplos na Tabela
> 2.3 em que {**X ∪ Y**} = {Temperatura=Baixa, Umidade=Normal}. Portanto,
758,760c1122,1132
< A Regra 2.2 também tem *Sup(Regra 2.2) = 4/14*, a terceira regra tem *Sup(Regra 2.3) = 3/14*, enquanto que a quarta regra tem *Sup(Regra 2.4) = 1/14*.
< 
< **Confiança** -- a confiança de uma regra reflete o número de exemplos que contêm **Y** dentre todos aqueles que contêm **X** (veja bem, além de **X** **⇒** **Y,** podem existir regras do tipo **X** **⇒** **Z**, **X** **⇒** **W** etc.). Em outras palavras, o parâmetro Confiança determina quantos são os exemplos em que **X** implica **Y**, comparado com aqueles exemplos em que **X** pode ou não implicar **Y**. A este parâmetro costuma-se também dar o nome de **Acurácia**.
---
> A Regra 2.2 também tem *Sup(Regra 2.2) = 4/14*, a terceira regra tem
> *Sup(Regra 2.3) = 3/14*, enquanto que a quarta regra tem *Sup(Regra 2.4)
> = 1/14*.
> 
> **Confiança** -- a confiança de uma regra reflete o número de exemplos
> que contêm **Y** dentre todos aqueles que contêm **X** (veja bem, além
> de **X** **⇒** **Y,** podem existir regras do tipo **X** **⇒** **Z**,
> **X** **⇒** **W** etc.). Em outras palavras, o parâmetro Confiança
> determina quantos são os exemplos em que **X** implica **Y**, comparado
> com aqueles exemplos em que **X** pode ou não implicar **Y**. A este
> parâmetro costuma-se também dar o nome de **Acurácia**.
764c1136,1139
< Por exemplo, com relação à primeira Regra (2.1) há quatro exemplos na Tabela 2.3 em que {**X ∪ Y**} = {Temperatura=Baixa, Umidade=Normal} e, coincidentemente, quatro exemplos em que {**X**} = {Temperatura=Baixa). Portanto,
---
> Por ex., com relação à primeira Regra (2.1) há quatro exemplos na Tabela
> 2.3 em que {**X ∪ Y**} = {Temperatura=Baixa, Umidade=Normal} e,
> coincidentemente, quatro exemplos em que {**X**} = {Temperatura=Baixa).
> Portanto,
768,770c1143,1208
< A Regra 2.2 também tem *Conf(Regra 2.2) = 4/4*, a terceira regra tem *Conf(regra 2.3) = 3/3*, enquanto que a quarta regra tem *Conf(Regra 2.4) = 1/2*.
< 
< Regras de Associação são particularmente úteis para analisar o comportamento de clientes e propor "vendas casadas". A informação de que clientes que compram o item A geralmente compram o item B pode aumentar significativamente as vendas de uma loja ou livraria, já que toda vez que um cliente manifestar a intenção de comprar o item A, a loja pode também lhe oferecer o item B.
---
> A Regra 2.2 também tem *Conf(Regra 2.2) = 4/4*, a terceira regra tem
> *Conf(regra 2.3) = 3/3*, enquanto que a quarta regra tem *Conf(Regra
> 2.4) = 1/2*.
> 
> Regras de Associação são particularmente úteis para analisar o
> comportamento de clientes e propor "vendas casadas". A informação de que
> clientes que compram o item A geralmente compram o item B pode aumentar
> significativamente as vendas de uma loja ou livraria, já que toda vez
> que um cliente manifestar a intenção de comprar o item A, a loja pode
> também lhe oferecer o item B.
> 
> Mas o fato de um simples conjunto de itens poder gerar muitas regras de
> associação faz com que o número de regras associadas a uma base de dados
> seja tão grande a ponto de a maioria dessas regras não ter qualquer
> interesse prático. Para contornar esta situação, antes de começar a
> gerar as regras de associação, é comum que sejam estabelecidos um valor
> de Suporte Mínimo (**SupMin**) e de Confiança Mínima (**ConfMin**).
> Regras com suporte muito baixo podem ser resultado de compras feitas ao
> acaso e, portanto, não fornecem informações de interesse. Por outro
> lado, regras com confiança muito baixa podem indicar que seu poder de
> predição é baixo e, portanto, não é muito aconselhável assumir que **X**
> implica **Y** com base nessas regras.
> 
> Agrawal (Agrawal *et al*., 1993) ao introduzir o conceito de Regras de
> Associação propôs um algoritmo denominado **Apriori** no qual Regras de
> Associação são geradas em duas etapas:
> 
> -   Dado um conjunto de transações **T**, primeiramente são criados
>     > conjuntos de itens frequentes, chamados de **Conjuntos
>     > Frequentes**, que devem satisfazer o limite de **SupMin**;
> 
> -   a partir desses Conjuntos Frequentes são geradas **Regras de
>     > Associação** com confiança maior ou igual **ConfMin**.
> 
> Etapa 1: Geração de Conjuntos Frequentes com Suporte ≥ SupMin
> -------------------------------------------------------------
> 
> As Tabelas 2.4 e 2.5 mostram versões simplificadas da Tabela 2.2, aqui
> adaptada para que cada item possa ser representado por apenas uma letra.
> 
> +----------------------------------+----------------------------------+
> | Tabela . -- Versão simplificada  | Tabela . -- Versão alternativa   |
> | da Tabela 2.2.                   | da Tabela 2.2.                   |
> +==================================+==================================+
> |                                  |   TID   Itens                    |
> |  TID   A   B   C   D   E   F   G |   ----- --------------           |
> |   -                              |   1     {A, B, D}                |
> | ---- --- --- --- --- --- --- --- |   2     {F, G}                   |
> |                                  |   3     {A, B, C, D}             |
> |  1     1   1   0   1   0   0   0 |   4     {A, E, F, G}             |
> |                                  |   5     {A, B, C, D}             |
> |  2     0   0   0   0   0   1   1 |                                  |
> |                                  |                                  |
> |  3     1   1   1   1   0   0   0 |                                  |
> |                                  |                                  |
> |  4     1   0   0   0   1   1   1 |                                  |
> |                                  |                                  |
> |  5     1   1   1   1   0   0   0 |                                  |
> +----------------------------------+----------------------------------+
> 
> De acordo com o algoritmo Apriori, para se obter os possíveis Conjuntos
> Frequentes relacionados a um conjunto de transações, inicialmente devem
> ser criados Conjuntos Frequentes com 1 item apenas e que satisfaçam o
> critério de Suporte Mínimo. A seguir são criados recursivamente
> Conjuntos Frequentes com 2 itens, depois com 3 itens, e assim
> sucessivamente.
772,799c1210,1211
< Mas o fato de um simples conjunto de itens poder gerar muitas regras de associação faz com que o número de regras associadas a uma base de dados seja tão grande a ponto de a maioria dessas regras não ter qualquer interesse prático. Para contornar esta situação, antes de começar a gerar as regras de associação, é comum que sejam estabelecidos um valor de Suporte Mínimo (**SupMin**) e de Confiança Mínima (**ConfMin**). Regras com suporte muito baixo podem ser resultado de compras feitas ao acaso e, portanto, não fornecem informações de interesse. Por outro lado, regras com confiança muito baixa podem indicar que seu poder de predição é baixo e, portanto, não é muito aconselhável assumir que **X** implica **Y** com base nessas regras.
< 
< Agrawal (AGRAWAL *et al*., 1993) ao introduzir o conceito de Regras de Associação propôs um algoritmo denominado **Apriori** no qual Regras de Associação são geradas em duas etapas:
< 
< -   Dado um conjunto de transações **T**, primeiramente são criados conjuntos de itens frequentes, chamados de **Conjuntos Frequentes**, que devem satisfazer o limite de **SupMin**;
< 
< -   a partir desses Conjuntos Frequentes são geradas **Regras de Associação** com confiança maior ou igual **ConfMin**.
< 
<     1.  Etapa 1: Geração de Conjuntos Frequentes com Suporte ≥ SupMin
<         -------------------------------------------------------------
< 
< As Tabelas 2.4 e 2.5 mostram versões simplificadas da Tabela 2.2, aqui adaptada para que cada item possa ser representado por apenas uma letra.
< 
< +------------------------------------------------+-----------------------------------------------+
< | Tabela . -- Versão Simplificada da Tabela 2.2. | Tabela . -- Versão Alternativa da Tabela 2.2. |
< +================================================+===============================================+
< |   TID   A   B   C   D   E   F   G              |   TID   Itens                                 |
< |   ----- --- --- --- --- --- --- ---            |   ----- --------------                        |
< |   1     1   1   0   1   0   0   0              |   1     {A, B, D}                             |
< |   2     0   0   0   0   0   1   1              |   2     {F, G}                                |
< |   3     1   1   1   1   0   0   0              |   3     {A, B, C, D}                          |
< |   4     1   0   0   0   1   1   1              |   4     {A, E, F, G}                          |
< |   5     1   1   1   1   0   0   0              |   5     {A, B, C, D}                          |
< +------------------------------------------------+-----------------------------------------------+
< 
< De acordo com o algoritmo Apriori, para se obter os possíveis Conjuntos Frequentes relacionados a um conjunto de transações, inicialmente devem ser criados Conjuntos Frequentes com 1 item apenas e que satisfaçam o critério de Suporte Mínimo. A seguir são criados recursivamente Conjuntos Frequentes com 2 itens, depois com 3 itens, e assim sucessivamente.
< 
< Os possíveis Conjuntos Frequentes com 1 item apenas, e seus respectivos valores de Suporte, estão representados na Tabela 2.6.
---
> Os possíveis Conjuntos Frequentes com 1 item apenas, e seus respectivos
> valores de Suporte, estão representados na Tabela 2.6.
813,815c1225,1236
< Suponhamos que o **SupMin** tenha sido definido como 2/5, ou seja, 40%. De acordo com este critério, o conjunto {E} não satisfaz **SupMin** e deve ser eliminado. Portanto os Conjuntos Frequentes com 1 Item que satisfazem o critério de **SupMin** maior ou igual a 2/5 estão representados na Tabela 2.7.
< 
< Ao adotar o procedimento de poda dos candidatos a Conjunto Frequente que não satisfazem o critério de SupMim, o número total de Conjuntos Frequentes gerados pode cair significativamente. Em princípio, dada uma Base de Dados com *k* itens, o número de possíveis Conjuntos Frequentes é \|CF\| = 2^k^-1 (excluindo o conjunto vazio). Como em nossa Tabela 2.4 há 7 itens, \|CF\| = 2^7^-1 = 127.
---
> Suponhamos que o **SupMin** tenha sido definido como 2/5, ou seja, 40%.
> De acordo com este critério, o conjunto {E} não satisfaz **SupMin** e
> deve ser eliminado. Portanto os Conjuntos Frequentes com 1 Item que
> satisfazem o critério de **SupMin** maior ou igual a 2/5 estão
> representados na Tabela 2.7.
> 
> Ao adotar o procedimento de poda dos candidatos a Conjunto Frequente que
> não satisfazem o critério de SupMim, o número total de Conjuntos
> Frequentes gerados pode cair significativamente. Em princípio, dada uma
> Base de Dados com *k* itens, o número de possíveis Conjuntos Frequentes
> é \|CF\| = 2^k^-1 (excluindo o conjunto vazio). Como em nossa Tabela 2.4
> há 7 itens, \|CF\| = 2^7^-1 = 127.
828,836c1249,1279
< A seguir devem ser formados novos Conjuntos Frequentes com 2 Itens, partindo-se dos Conjuntos Frequentes com 1 Item. Note que o Suporte de um Conjunto Frequente com 2 Itens pode ter no máximo o menor valor de Suporte de cada um de seus subconjuntos, i. e., dos respectivos Conjuntos Frequentes com 1 Item. De acordo com esta mesma propriedade, conhecida como **Princípio Apriori** ou antimonotônico, qualquer subconjunto de um Conjunto Frequente também será um Conjunto Frequente. Por exemplo, se {A, B} for um Conjunto Frequente, então {A} e {B} também são Conjuntos Frequentes e têm Suporte ≥ SupMin.
< 
< A Tabela 2.8 mostra os possíveis Conjuntos Frequentes com 2 Itens e os respectivos valores de Suporte.
< 
< Os conjuntos de 2 itens foram obtidos por combinação dos conjuntos de 1 item, enquanto que os valores de Suporte foram obtidos inspecionando-se as Tabelas 2.4 e 2.5.
< 
< Note que os detalhes de como os conjuntos de itens são efetivamente gerados dependem da forma como o algoritmo Apriori foi implementado, e diferem um pouco da exposição simplificada que se adotou aqui por razões didáticas.
< 
< Para calcular o Suporte dos Conjuntos Frequentes foi necessário ler a Base de Dados, que em nosso caso é pequena e está representada pela Tabela 2.4. Em uma implementação computacional é altamente desejável que toda a Base de Dados possa ser lida na memória principal do computador. Porém, se a Base de Dados for muito grande ela provavelmente terá de ser lida no disco rígido. Para minimizar o número de vezes que a Base de Dados é consultada, muitos candidatos a Conjuntos Frequentes podem ser inicialmente criados e depois eliminados, obtendo-se assim significativos ganhos de tempo.
---
> A seguir devem ser formados novos Conjuntos Frequentes com 2 Itens,
> partindo-se dos Conjuntos Frequentes com 1 Item. Note que o Suporte de
> um Conjunto Frequente com 2 Itens pode ter no máximo o menor valor de
> Suporte de cada um de seus subconjuntos, i. e., dos respectivos
> Conjuntos Frequentes com 1 Item. De acordo com esta mesma propriedade,
> conhecida como **Princípio Apriori** ou antimonotônico, qualquer
> subconjunto de um Conjunto Frequente também será um Conjunto Frequente.
> Por exemplo, se {A, B} for um Conjunto Frequente, então {A} e {B} também
> são Conjuntos Frequentes e têm Suporte ≥ SupMin.
> 
> A Tabela 2.8 mostra os possíveis Conjuntos Frequentes com 2 Itens e os
> respectivos valores de Suporte.
> 
> Os conjuntos de 2 itens foram obtidos por combinação dos conjuntos de 1
> item, enquanto que os valores de Suporte foram obtidos inspecionando-se
> as Tabelas 2.4 e 2.5.
> 
> Note que os detalhes de como os conjuntos de itens são efetivamente
> gerados dependem da forma como o algoritmo Apriori foi implementado, e
> diferem um pouco da exposição simplificada que se adotou aqui por razões
> didáticas.
> 
> Para calcular o Suporte dos Conjuntos Frequentes foi necessário ler a
> Base de Dados, que em nosso caso é pequena e está representada pela
> Tabela 2.4. Em uma implementação computacional é altamente desejável que
> toda a Base de Dados possa ser lida na memória principal do computador.
> Porém, se a Base de Dados for muito grande ela provavelmente terá de ser
> lida no disco rígido. Para minimizar o número de vezes que a Base de
> Dados é consultada, muitos candidatos a Conjuntos Frequentes podem ser
> inicialmente criados e depois eliminados, obtendo-se assim
> significativos ganhos de tempo.
858c1301,1303
< Para nós, neste momento, o importante é compreender como os Conjuntos Frequentes com ***k*** Itens podem ser gerados de forma relativamente simples pela combinação de Conjuntos Frequentes com ***k-1*** Itens.
---
> Para nós, neste momento, o importante é compreender como os Conjuntos
> Frequentes com ***k*** Itens podem ser gerados de forma relativamente
> simples pela combinação de Conjuntos Frequentes com ***k-1*** Itens.
860c1305,1306
< Aplicando-se novamente o critério de **SupMin ≥ 2/5**, restam apenas os Conjuntos Frequentes com 2 Itens apresentados na Tabela 2.9.
---
> Aplicando-se novamente o critério de **SupMin ≥ 2/5**, restam apenas os
> Conjuntos Frequentes com 2 Itens apresentados na Tabela 2.9.
874c1320,1322
< O próximo passo agora consiste em criar novos Conjuntos Frequentes com 3 Itens, partindo-se dos Conjuntos Frequentes com 2 Itens, cujo resultado é mostrado na Tabela 2.10.
---
> O próximo passo agora consiste em criar novos Conjuntos Frequentes com 3
> Itens, partindo-se dos Conjuntos Frequentes com 2 Itens, cujo resultado
> é mostrado na Tabela 2.10.
889c1337,1339
< Neste caso, novamente, alguns Conjuntos Frequentes não satisfazem o critério do **SupMin ≥ 2/5**, havendo a necessidade de poda para que estes conjuntos não participem da etapa seguinte.
---
> Neste caso, novamente, alguns Conjuntos Frequentes não satisfazem o
> critério do **SupMin ≥ 2/5**, havendo a necessidade de poda para que
> estes conjuntos não participem da etapa seguinte.
900c1350,1352
< Vamos agora gerar novos Conjuntos Frequentes com 4 Itens, partindo-se dos Conjuntos Frequentes com 3 Itens (Tabela 2.11), cujo resultado é mostrado na Tabela 2.12.
---
> Vamos agora gerar novos Conjuntos Frequentes com 4 Itens, partindo-se
> dos Conjuntos Frequentes com 3 Itens (Tabela 2.11), cujo resultado é
> mostrado na Tabela 2.12.
908c1360,1363
< Se houvesse ao menos dois Conjuntos Frequentes com 4 Itens poderíamos ainda tentar gerar Conjuntos Frequentes com 5 Itens. Mas como há apenas um Conjunto Frequente com 4 Itens, esta primeira etapa do algoritmo Apriori termina aqui.
---
> Se houvesse ao menos dois Conjuntos Frequentes com 4 Itens poderíamos
> ainda tentar gerar Conjuntos Frequentes com 5 Itens. Mas como há apenas
> um Conjunto Frequente com 4 Itens, esta primeira etapa do algoritmo
> Apriori termina aqui.
913c1368,1372
< Uma vez obtidos os Conjuntos Frequentes com Suporte ≥ SupMin, é possível extrair de cada Conjunto Frequente com *k* itens 2^k^-2 Regras de Associação (excluindo o conjunto vazio na posição de antecedente (∅⇒CF) ou de consequente(CF⇒∅)). Na Etapa 1 foram gerados os seguintes Conjuntos Frequentes:
---
> Uma vez obtidos os Conjuntos Frequentes com Suporte ≥ SupMin, é possível
> extrair de cada Conjunto Frequente com *k* itens 2^k^-2 Regras de
> Associação (excluindo o conjunto vazio na posição de antecedente (∅⇒CF)
> ou de consequente(CF⇒∅)). Na Etapa 1 foram gerados os seguintes
> Conjuntos Frequentes:
931,933c1390,1399
< Para extrair as Regras de Associação de um Conjunto Frequente é necessário primeiramente gerar todos os subconjuntos não-vazios desse Conjunto Frequente **CF**, e para cada subconjunto **S** de CF produzir uma Regra de Associação do tipo **S ⇒ (CF - S)** que satisfaça o critério de Confiança ≥ ConfMin.
< 
< Por exemplo, dado o CF = {A, B, C}, seus subconjuntos não-vazios possíveis são S = {{A}, {B}, {C}, {A, B}, {A, C}, {B, C}. Portanto, é possível extrair seis Regras de Associação do CF = {A, B, C} que envolvam os três itens:
---
> Para extrair as Regras de Associação de um Conjunto Frequente é
> necessário primeiramente gerar todos os subconjuntos não-vazios desse
> Conjunto Frequente **CF**, e para cada subconjunto **S** de CF produzir
> uma Regra de Associação do tipo **S ⇒ (CF - S)** que satisfaça o
> critério de Confiança ≥ ConfMin.
> 
> Por exemplo, dado o CF = {A, B, C}, seus subconjuntos não-vazios
> possíveis são S = {{A}, {B}, {C}, {A, B}, {A, C}, {B, C}. Portanto, é
> possível extrair seis Regras de Associação do CF = {A, B, C} que
> envolvam os três itens:
947c1413,1416
< Como o Suporte de todos os subconjuntos já terá sido calculado na Etapa 1, não será necessário percorrer novamente a Base de Dados para calcular a Confiança de cada Regra de Associação. Basta reutilizar estes valores calculados, pois
---
> Como o Suporte de todos os subconjuntos já terá sido calculado na Etapa
> 1, não será necessário percorrer novamente a Base de Dados para calcular
> a Confiança de cada Regra de Associação. Basta reutilizar estes valores
> calculados, pois
951c1420,1421
< Voltando ao exemplo inicial da Tabela 2.5, como o Suporte de CF = {A, B, C} é 2/5 (veja Tabela 2.11), e com os Suportes de seus subconjuntos
---
> Voltando ao exemplo inicial da Tabela 2.5, como o Suporte de CF = {A, B,
> C} é 2/5 (veja Tabela 2.11), e com os Suportes de seus subconjuntos
979c1449,1451
< Suponha que para o problema em questão tenha sido adotado **SupMin = 40%** e **ConfMin = 90%**, então apenas três das regras acimas seriam aproveitadas:
---
> Suponha que para o problema em questão tenha sido adotado **SupMin =
> 40%** e **ConfMin = 90%**, então apenas três das regras acimas seriam
> aproveitadas:
987c1459,1463
< Aplicando-se o procedimento explicado acima para todos os 18 CFs obtidos na Etapa 1, seriam geradas aproximadamente 30 Regras de Associação com SupMin = 40% e ConfMin = 90% (na realidade, chegamos ao número 30 através de simulação no Weka, como será mostrado na Atividade Prática com o Weka).
---
> Aplicando-se o procedimento explicado acima para todos os 18 CFs obtidos
> na Etapa 1, seriam geradas aproximadamente 30 Regras de Associação com
> SupMin = 40% e ConfMin = 90% (na realidade, chegamos ao número 30
> através de simulação no Weka, como será mostrado na Atividade Prática
> com o Weka).
992,996c1468,1484
< Nesta seção será apresentado um pequeno tutorial sobre a geração de Regras de Associação usando o algoritmo "Apriori" implementado na ferramenta de Aprendizado de Máquina para tarefas de Mineração de Dados Weka (Weka, 2013). A versão utilizada é a 3.6.7. Para fazer uma simulação no Weka, a Base de Dados terá de ser escrita ou no formato CSV *(Comma-Separated Value)* (".csv") ou no formato "ARFF" *(Attribute-Relation File Format)*, um formato bastante simples e intuitivo dessa ferramenta. Com o arquivo ".arff" carregado, podemos ajustar os parâmetros Suporte e Confiança e rodar o algoritmo Apriori.
< 
< **Passo 1** - Vamos supor que nossa Base de Dados tenha sido retirada de uma planilha eletrônica (".xls") e salva no formato ".csv", como mostra a Figura 2.2.
< 
< ![](./media/image1.png){width="1.6819444444444445in" height="1.613888888888889in"}![](./media/image2.png){width="3.372916666666667in" height="1.4909722222222221in"}
---
> Nesta seção será apresentado um pequeno tutorial sobre a geração de
> Regras de Associação usando o algoritmo "Apriori" implementado na
> ferramenta de Aprendizado de Máquina para tarefas de Mineração de Dados
> Weka (Weka, 2013). A versão utilizada é a 3.6.7. Para fazer uma
> simulação no Weka, a Base de Dados terá de ser escrita ou no formato CSV
> *(Comma-Separated Value)* (".csv") ou no formato "ARFF"
> *(Attribute-Relation File Format)*, um formato bastante simples e
> intuitivo dessa ferramenta. Com o arquivo ".arff" carregado, podemos
> ajustar os parâmetros Suporte e Confiança e rodar o algoritmo Apriori.
> 
> **Passo 1** - Vamos supor que nossa Base de Dados tenha sido retirada de
> uma planilha eletrônica (".xls") e salva no formato ".csv", como mostra
> a Figura 2.2.
> 
> ![](media/image1.png){width="1.6819444444444445in"
> height="1.613888888888889in"}![](media/image2.png){width="3.372916666666667in"
> height="1.4909722222222221in"}
1000,1006c1488,1489
< Figura . -- A Base de Dados Transacoes_1 na Forma (a) Planilha ".xls" e (b) ".csv".
< 
< Como o Weka tem um conversor interno do formato ".csv" para ".arff", vamos primeiramente usar este recurso. Depois vamos mostrar como transformar manualmente o arquivo ".csv" para ".arff".
< 
< Obs.: Certifique-se que em seu arquivo ".csv" o separador de células seja efetivamente a vírgula "," e não ";". Se o arquivo ".csv" gerado pela sua planilha utilizar ";", faça a substituição para ", ". Caso contrário, ocorrerá um erro de leitura no Weka e o arquivo será interpretado de forma completamente diferente do esperado.
< 
< **Passo 2** -- Dispare o Weka ("GUI Chooser") e tome a opção "Explorer", que corresponde à versão com recursos gráficos e ícones (em vez de linha de comando). Veja Figura 2.3.
---
> Figura . -- A Base de Dados Transacoes_1 na Forma (a) Planilha ".xls" e
> (b) ".csv".
1008c1491,1507
< ![](./media/image3.png){width="2.115384951881015in" height="1.2625382764654418in"} ![](./media/image4.png){width="3.0in" height="2.475in"}
---
> Como o Weka tem um conversor interno do formato ".csv" para ".arff",
> vamos primeiramente usar este recurso. Depois vamos mostrar como
> transformar manualmente o arquivo ".csv" para ".arff".
> 
> Obs.: Certifique-se que em seu arquivo ".csv" o separador de células
> seja efetivamente a vírgula "," e não ";". Se o arquivo ".csv" gerado
> pela sua planilha utilizar ";", faça a substituição para ", ". Caso
> contrário, ocorrerá um erro de leitura no Weka e o arquivo será
> interpretado de forma completamente diferente do esperado.
> 
> **Passo 2** -- Dispare o Weka ("GUI Chooser") e tome a opção "Explorer",
> que corresponde à versão com recursos gráficos e ícones (em vez de linha
> de comando). Veja Figura 2.3.
> 
> ![](media/image3.png){width="2.115384951881015in"
> height="1.2625382764654418in"} ![](media/image4.png){width="3.0in"
> height="2.475in"}
1017c1516,1519
< **Passo 3 --** Com a aba superior "Preprocess" escolhida, dê um clique em "Open file\...". Uma janela denominada "Open" deve se abrir. Ajuste a opção de "File Format:" para ".csv", e escolha o arquivo "Transacoes_1.csv", conforme mostra a Figura 2.4.
---
> **Passo 3 --** Com a aba superior "Preprocess" escolhida, dê um clique
> em "Open file\...". Uma janela denominada "Open" deve se abrir. Ajuste a
> opção de "File Format:" para ".csv", e escolha o arquivo
> "Transacoes_1.csv", conforme mostra a Figura 2.4.
1019c1521
< ![](./media/image5.png){width="3.35in" height="2.763888888888889in"}
---
> ![](media/image5.png){width="3.35in" height="2.763888888888889in"}
1023c1525,1526
< **Passo 4** -- A tela do Weka Explorer deve apresentar os sete atributos do arquivo "Transacoes_1", como mostra a Figura 2.5.
---
> **Passo 4** -- A tela do Weka Explorer deve apresentar os sete atributo
> do arquivo "Transacoes_1", como mostra a Figura 2.5.
1025c1528,1529
< ![](./media/image7.png){width="3.861111111111111in" height="2.892361111111111in"}
---
> ![](media/image7.png){width="3.861111111111111in"
> height="2.892361111111111in"}
1029c1533,1534
< **Passo 5** -- Como nossa "Base de Dados" é muito pequena, a conversão manual do arquivo ".csv" para ".arff" pode ser feita muito rapidamente.
---
> **Passo 5** -- Como nossa "Base de Dados" é muito pequena, a conversão
> manual do arquivo ".csv" para ".arff" pode ser feita muito rapidamente.
1031,1041c1536,1566
< Digite no arquivo "Transacoes_1.csv" as palavras-chave "\@relation", "\@attribute" e "\@data", de acordo com a Figura 2.6, salve e feche o arquivo ".csv". Mude a terminação do arquivo de ".csv" para ".arff". Há ainda outras alternativas: Crie um arquivo "Transacoes_1.txt" com o conteúdo mostrado abaixo na Figura 2.6 (certifique-se de que se trata efetivamente de arquivo tipo ".txt" e não, por exemplo, "Transacoes_1.txt.doc" ou "Transacoes_1.txt.rtf"). Feche o arquivo e mude a terminação para ".arff", ou seja, para "Transacoes_1.arff".
< 
< ![](./media/image8.png){width="3.997916666666667in" height="3.8465277777777778in"}
< 
< Figura . -- Arquivo ARFF (Transacoes_1.arff), com Itens Ausentes Representados por "n".
< 
< ![](./media/image12.png){width="4.245833333333334in" height="2.9298611111111112in"}**Passo 6** -- Com o arquivo "Transacoes_1.arff" pronto, disparar o Weka, selecionar a aba "Preprocess", depois clicar na opção "Open file\..." e escolher o arquivo "Transacoes1\_.arff", conforme mostra a Figura 2.7.
< 
< Figura . -- Aba "Preprocess" + "Open file\..." para Escolha do Arquivo ARFF.
< 
< ![](./media/image13.png){width="3.8930555555555557in" height="2.682638888888889in"}**Passo 7** -- Depois de abrir o arquivo "Transacoes_1.arff", ainda com a aba "Preprocess" selecionada, escolha "No class" (ao lado de "Visualize all"), conforme ilustra a Figura 2.8. (Como vamos gerar Regras de Associação, qualquer um dos atributos pode funcionar como "classe". Este conceito vai ser melhor explicado quando formos estudar Regras de Classificação.).
---
> Digite no arquivo "Transacoes_1.csv" as palavras-chave "\@relation",
> "\@attribute" e "\@data", de acordo com a Figura 2.6, salve e feche o
> arquivo ".csv". Mude a terminação do arquivo de ".csv" para ".arff". Há
> ainda outras alternativas: Crie um arquivo "Transacoes_1.txt" com o
> conteúdo mostrado abaixo na Figura 2.6 (certifique-se de que se trata
> efetivamente de arquivo tipo ".txt" e não, por ex.,
> "Transacoes_1.txt.doc" ou "Transacoes_1.txt.rtf"). Feche o arquivo e
> mude a terminação para ".arff", ou seja, para "Transacoes_1.arff".
> 
> ![](media/image8.png){width="3.997916666666667in"
> height="3.8465277777777778in"}
> 
> Figura . -- Arquivo ARFF (Transacoes_1.arff), com Itens Ausentes
> Representados por "n".
> 
> ![](media/image12.png){width="4.245833333333334in"
> height="2.9298611111111112in"}**Passo 6** -- Com o arquivo
> "Transacoes_1.arff" pronto, disparar o Weka, selecionar a aba
> "Preprocess", depois clicar na opção "Open file\..." e escolher o
> arquivo "Transacoes1\_.arff", conforme mostra a Figura 2.7.
> 
> Figura . -- Aba "Preprocess" + "Open file\..." para Escolha do Arquivo
> ARFF.
> 
> ![](media/image13.png){width="3.8930555555555557in"
> height="2.682638888888889in"}**Passo 7** -- Depois de abrir o arquivo
> "Transacoes_1.arff", ainda com a aba "Preprocess" selecionada, escolha
> "No class" (ao lado de "Visualize all"), conforme ilustra a Figura 2.8.
> (Como vamos gerar Regras de Associação, qualquer um dos atributos pode
> funcionar como "classe". Este conceito vai ser melhor explicado quando
> formos estudar Regras de Classificação.).
1045c1570,1572
< ![](./media/image15.png){width="4.7125in" height="3.0in"}**Passo 8** -- Na aba superior do Weka, escolher "Associate" e ao lado de "Choose" clicar duas vezes sobre o algoritmo "Apriori", conforme mostra a Figura 2.9.
---
> ![](media/image15.png){width="4.7125in" height="3.0in"}**Passo 8** -- Na
> aba superior do Weka, escolher "Associate" e ao lado de "Choose" clicar
> duas vezes sobre o algoritmo "Apriori", conforme mostra a Figura 2.9.
1049c1576,1579
< **Passo 9 --** Na janela que se abre, ajustar o SupMin (lowerBoundMinSupport) para 0.4, a ConfMin (minMetric) para 0.9 e o número de regras mostradas (numRules) para 1000, conforme mostra a Figura 2.10. Clicar em "OK".
---
> **Passo 9 --** Na janela que se abre, ajustar o SupMin
> (lowerBoundMinSupport) para 0.4, a ConfMin (minMetric) para 0.9 e o
> número de regras mostradas (numRules) para 1000, conforme mostra a
> Figura 2.10.Clicar em "OK".
1051c1581,1582
< ![](./media/image17.png){width="2.7534722222222223in" height="3.082638888888889in"}
---
> ![](media/image17.png){width="2.7534722222222223in"
> height="3.082638888888889in"}
1055,1075c1586,1630
< **Passo 10** -- Ao clicar em "Start" centenas de Regras de Associação serão geradas, a maioria delas sem qualquer interesse, conforme ilustra a Figura 2.11. Um dos riscos da geração de Regras de Associação é que muitas delas podem não ter qualquer significado prático. Para contornar este tipo de problema, é possível introduzir pequenas mudanças na forma como os atributos são declarados e reduzir significativamente o número de regras geradas.
< 
< ![](./media/image19.png){width="2.9965277777777777in" height="3.277083333333333in"}
< 
< Figura . -- Algumas Regras de Associação Geradas com o Arquivo "Transacoes_1.arff".
< 
< **Passo 11** -- Uma forma de diminuir o número de regras é substituir os valores ausentes de atributo "n" por "?". Crie um arquivo "Transacoes_2.arff" conforme mostra a Figura 2.12.
< 
< ![](./media/image20.png){width="2.2534722222222223in" height="3.1569444444444446in"}
< 
< Figura . -- Arquivo "Transacoes_2.arff" com Itens Ausentes Representados por "?".
< 
< Isso vai evitar que o Weka crie regras sem qualquer significado prático envolvendo itens ausentes, como por exemplo, {F=n} ⇒ {G=n} (Regra 20 na Figura 2.11). Embora a regra {F=y} ⇒ {G=y} (i.e., "quem compra queijo também costuma comprar vinho") possa ser de interesse, a regra de que "quem não compra queijo também não compra vinho") dificilmente trará alguma informação prática. Numa Base de Dados muito grande, regras desse tipo podem aparecer em quantidades proibitivamente grandes.
< 
< Com o arquivo "Transacoes_2.arff" foram geradas 30 Regras de Associação (Figura 2.13), sendo que as regras ilustrativas do texto de teoria do Capítulo 2 envolvendo o CF = {A, B, C} aparecem na Figura 2.13 como as regras 15, 16 e 17.
< 
< ![](./media/image21.png){width="3.50625in" height="6.653472222222222in"}
< 
< Figura . -- As 30 Regras de Associação Geradas com o Arquivo "Transacoes_2.arff".
< 
< Há outras formas de melhorar a qualidade dos resultados e controlar o número de regras geradas, por exemplo, através do parâmetro ***Lift***, cujo significado fica como lição de casa.
---
> **Passo 10** -- Ao clicar em "Start" centenas de Regras de Associação
> serão geradas, a maioria delas sem qualquer interesse, conforme ilustra
> a Figura 2.11. Um dos riscos da geração de Regras de Associação é que
> muitas delas podem não ter qualquer significado prático. Para contornar
> este tipo de problema, é possível introduzir pequenas mudanças na forma
> como os atributos são declarados e reduzir significativamente o número
> de regras geradas.
> 
> ![](media/image19.png){width="2.9965277777777777in"
> height="3.277083333333333in"}
> 
> Figura . -- Algumas Regras de Associação Geradas com o Arquivo
> "Transacoes_1.arff".
> 
> **Passo 11** -- Uma forma de diminuir o número de regras é substituir os
> valores ausentes de atributo "n" por "?". Crie um arquivo
> "Transacoes_2.arff" conforme mostra a Figura 2.12.
> 
> ![](media/image20.png){width="2.2534722222222223in"
> height="3.1569444444444446in"}
> 
> Figura . -- Arquivo "Transacoes_2.arff" com Itens Ausentes Representados
> por "?".
> 
> Isso vai evitar que o Weka crie regras sem qualquer significado prático
> envolvendo itens ausentes, como por exemplo, {F=n} ⇒ {G=n} (Regra 20 na
> Figura 2.11). Embora a regra {F=y} ⇒ {G=y} (i.e., "quem compra queijo
> também costuma comprar vinho") possa ser de interesse, a regra de que
> "quem não compra queijo também não compra vinho") dificilmente trará
> alguma informação prática. Numa Base de Dados muito grande, regras desse
> tipo podem aparecer em quantidades proibitivamente grandes.
> 
> Com o arquivo "Transacoes_2.arff" foram geradas 30 Regras de Associação
> (Figura 2.13), sendo que as regras ilustrativas do texto de teoria do
> Capítulo 2 envolvendo o CF = {A, B, C} aparecem na Figura 2.13 como as
> regras 15, 16 e 17.
> 
> ![](media/image21.png){width="3.50625in" height="6.653472222222222in"}
> 
> Figura . -- As 30 Regras de Associação Geradas com o Arquivo
> "Transacoes_2.arff".
> 
> Há outras formas de melhorar a qualidade dos resultados e controlar o
> número de regras geradas, por exemplo, através do parâmetro ***Lift***,
> cujo significado fica como lição de casa.
1080,1088c1635,1689
< Um conjunto de Regras de Associação constitui uma forma de conhecimento extraído de uma Base de Dados, sendo esta representação do conhecimento geralmente um tipo de aprendizado muito útil para aplicações práticas, como o aumento de vendas de uma rede de supermercados, o projeto de catálogos de novos produtos ou o lançamento de campanhas promocionais baseadas em vendas casadas. Geralmente quando fazemos busca na Web, ao digitarmos uma palavra de busca é comum que outras palavras sejam sugeridas. Isso ocorre porque a ferramenta de busca está usando Regras de Associação e tem em sua Base de Dados registros de que pessoas que buscam a Palavra_1 geralmente buscam também a Palavra_2, a Palavra_3, e assim por diante.
< 
< Nesta primeira abordagem da extração de conhecimento a partir de uma Base de Dados foi suficiente apenas um procedimento algoritmo, sem necessidade de inferências. Nos próximos capítulos vamos mostrar que na prática é comum nos depararmos com situações para as quais não se conhece um algoritmo que produza o conhecimento necessário para uma tomada de decisão. Para estes casos, será necessário pensar num mecanismo de inferência que nos permita chegar à conclusão mais plausível para determinada situação. Esse é o caso de sistemas conhecidos como Sistemas Especialistas, que auxiliam por exemplo um médico a fazer diagnóstico a partir dos sintomas do paciente. Como nem sempre os sintomas declarados pelo paciente são compatíveis com determinada doença, ou então porque o paciente omite determinados sintomas importantes para o diagnóstico correto, o sistema precisa fazer inferências comparando sua Base \[permanente\] de Conhecimento com os sintomas declarados.
< 
< Regras de Associação frequentemente usam atributos nominais (por exemplo, temperatura elevada, amena, baixa) e mais raramente atributos numéricos (por exemplo 40**°**C, 23**°**C, 4**°**C), porque algoritmos para extração de Regras de Associação com atributos numéricos não costumam apresentar bom desempenho em grandes Bases de Dados. Além disso, ao não levar em conta por exemplo o preço de um artigo ou a quantidade de itens vendidos em cada transação, as Regras de Associação geralmente se transformam numa forma simplista de representação do conhecimento extraído da Base de Dados.
< 
< No exemplo da Cesta de Artigos mostramos como gerar Regras de Associação que indiquem venda casada dos artigos mais comum. Mas, frequentemente, os especialistas em vendas não estão muito interessados nestes itens porque a associação entre eles já é conhecida. Na realidade, estes especialistas buscam pares de itens dos quais um deles é um produto barato e o outro tem alta taxa de lucro. Nestes casos, lançar uma superpromoção do produto barato faz com que as vendas do produto com alta taxa de lucro aumentem.
< 
< Em nossa Cesta de Artigos está implícito o padrão de associação entre Queijo e Vinho. Talvez aí, numa campanha de inverno, cadeias de supermercados possam fazer promoções de queijos com o único propósito de vender mais vinhos. Mas como as vendas de ambos eram relativamente baixas, esta regra não satisfez os critérios estabelecidos de ***SupMin*** e ***ConfMin***. E, no entanto, é possivelmente este tipo de informação a mais procurada. O que fazer para conseguir minerar as pérolas de informação?
---
> Um conjunto de Regras de Associação constitui uma forma de conhecimento
> extraído de uma Base de Dados, sendo esta representação do conhecimento
> geralmente um tipo de aprendizado muito útil para aplicações práticas,
> como o aumento de vendas de uma rede de supermercados, o projeto de
> catálogos de novos produtos ou o lançamento de campanhas promocionais
> baseadas em vendas casadas. Geralmente quando fazemos busca na Web, ao
> digitarmos uma palavra de busca é comum que outras palavras sejam
> sugeridas. Isso ocorre porque a ferramenta de busca está usando Regras
> de Associação e tem em sua Base de Dados registros de que pessoas que
> buscam a Palavra_1 geralmente buscam também a Palavra_2, a Palavra_3, e
> assim por diante.
> 
> Nesta primeira abordagem da extração de conhecimento a partir de uma
> Base de Dados foi suficiente apenas um procedimento algoritmo, sem
> necessidade de inferências. Nos próximos capítulos vamos mostrar que na
> prática é comum nos depararmos com situações para as quais não se
> conhece um algoritmo que produza o conhecimento necessário para uma
> tomada de decisão. Para estes casos, será necessário pensar num
> mecanismo de inferência que nos permita chegar à conclusão mais
> plausível para determinada situação. Esse é o caso de sistemas
> conhecidos como Sistemas Especialistas, que auxiliam por exemplo um
> médico a fazer diagnóstico a partir dos sintomas do paciente. Como nem
> sempre os sintomas declarados pelo paciente são compatíveis com
> determinada doença, ou então porque o paciente omite determinados
> sintomas importantes para o diagnóstico correto, o sistema precisa fazer
> inferências comparando sua Base \[permanente\] de Conhecimento com os
> sintomas declarados.
> 
> Regras de Associação frequentemente usam atributos nominais (por ex.,
> temperatura elevada, amena, baixa) e mais raramente atributos numéricos
> (por ex. 40 **°**C, 23 **°**C, 4 **°**C), porque algoritmos para
> extração de Regras de Associação com atributos numéricos não costumam
> apresentar bom desempenho em grandes Bases de Dados. Além disso, ao não
> levar em conta por exemplo o preço de um artigo ou a quantidade de itens
> vendidos em cada transação, as Regras de Associação geralmente se
> transformam numa forma simplista de representação do conhecimento
> extraído da Base de Dados.
> 
> No exemplo da Cesta de Artigos mostramos como gerar Regras de Associação
> que indiquem venda casada dos artigos mais comum. Mas, frequentemente,
> os especialistas em vendas não estão muito interessados nestes itens
> porque a associação entre eles já é conhecida. Na realidade, estes
> especialistas buscam pares de itens dos quais um deles é um produto
> barato e o outro tem alta taxa de lucro. Nestes casos, lançar uma
> superpromoção do produto barato faz com que as vendas do produto com
> alta taxa de lucro aumente.
> 
> Em nossa Cesta de Artigos está implícito o padrão de associação entre
> Queijo e Vinho. Talvez aí, numa campanha de inverno, cadeias de
> supermercados possam fazer promoções de queijos com o único propósito de
> vender mais vinhos. Mas como as vendas de ambos eram relativamente
> baixas, esta regra não satisfez os critérios estabelecidos de
> ***SupMin*** e ***ConfMin***. E, no entanto, é possivelmente este tipo
> de informação a mais procurada. O que fazer para conseguir minerar as
> pérolas de informação?
1093,1097c1694,1705
< 1\. Explique com suas próprias palavras a importância do **Suporte Mínimo (SupMin)** e **Confiança Mínima (ConfMin)** para a geração de **Regras de Associação**.
< 
< 2\. Explique com suas próprias palavras o que é **Conjunto Frequente** no contexto das **Regras de Associação**.
< 
< 3\. Crie uma pequena **Cesta de Compras** (± 5 Exemplos) com itens relacionados ao seu ambiente de trabalho, ou à área de seu TCC, ou a qualquer outra área de seu interesse, e gere as **Regras de Associação** no Weka. Anexe o respectivo arquivo ".arff", e um pequeno relatório sobre a simulação.
---
> 1\. (20%) Explique com suas próprias palavras a importância do **Suporte
> Mínimo (SupMin)** e **Confiança Mínima (ConfMin)** para a geração de
> **Regras de Associação**.
> 
> 2\. (30%) Explique com suas próprias palavras o que é **Conjunto
> Frequente** no contexto das **Regras de Associação**.
> 
> 3\. (50%) Crie uma pequena **Cesta de Compras** (± 5 Exemplos) com itens
> relacionados ao seu ambiente de trabalho, ou à área de seu TCC, ou a
> qualquer outra área de seu interesse, e gere as **Regras de Associação**
> no Weka. Anexe o respectivo arquivo ".arff", e um pequeno relatório
> sobre a simulação.
1102,1128c1710,1765
< AGRAWAL, R.; IMIELINSKI, T. & SWAMI, A. **Mining Association Rules Between Sets of Items in Large Databases**. Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data, Washington, DC. New York: ACM, 1993.
< 
< PADHY, N. P. **Artificial Intelligence and Intelligent Systems.** New Delhi: Oxford University Press, 2010.
< 
< QUINLAN, J. R. **Induction of Decision Trees**. Machine Learning, Vol. 1, No. 1, pp. 81-106. Boston: Kluwer Academic Publishers, 1986.
< 
< ROCHA, M.; CORTEZ, P. & NEVES, J. M. **Análise Inteligente de Dados: Algoritmos e Implementação em Java.** Lisboa: FCA -- Editora de Informática, 2008.
< 
< TAN, P. N.; STEINBACH, M. & KUMAR, V. **Introdução ao Data Mining Mineração de Dados.** Rio de Janeiro: Editora Ciência Moderna Ltda., 2009.
< 
< WITTEN, I. H. & FRANK, E. **Data Mining: Practical Machine Learning Tools and Techniques.** Second Edition. Amsterdam: Morgan Kaufmann Publishers, 2005.
< 
< Weka. The Waikato University. In http://www.cs.waikato.ac.nz/ml/weka. Acessado em 03.03.13.
< 
< WITTEN, I. H. & FRANK, E. **Data Mining: Practical Machine Learning Tools and Techniques.** Second Edition. Amsterdam: Morgan Kaufmann Publishers, 2005.
< 
< 3.  Classificação e Árvores de Decisão
<     ==================================
< 
<     1.  Introdução
<         ----------
< 
< É de grande interesse, em muitas situações, conseguir classificar antecipadamente o tipo de problema apresentado por um paciente com base nos sintomas relatados e tomar medidas para combater determinada doença em seu estágio inicial. Em muitos casos reais isso tem sido possível graças à análise minuciosa de Bases de Dados contendo anotações médicas de outros pacientes com soluções bem sucedidas previamente documentadas.
< 
< Em instituições financeiras, para um gerente de banco nem sempre é algo simples fazer uma avaliação de risco sobre a concessão de empréstimos de alto valor. Com base em dados de transações anteriores e nas características específicas de cada cliente, quase sempre é possível extrair automaticamente informações não óbvias que ajudam a classificar um correntista como bom ou mau pagador.
< 
< Estes são apenas alguns casos em que se verifica que há sempre informações úteis e não evidentes em grandes Bases de Dados. Estas informações podem ser automaticamente extraídas com Mineração de Dados e interpretadas de modo a constituir conhecimento especializado e útil para a tomada de decisão. A representação do conhecimento através de Árvores de Decisão vai ser o tema deste capítulo.
---
> AGRAWAL, R.; IMIELINSKI, T. & SWAMI, A. **Mining Association Rules
> Between Sets of Items in Large Databases**. Proceedings of the 1993 ACM
> SIGMOD International Conference on Management of Data, Washington, DC.
> New York: ACM, 1993.
> 
> PADHY, N. P. **Artificial Intelligence and Intelligent Systems.** New
> Delhi: Oxford University Press, 2010.
> 
> QUINLAN, J. R. **Induction of Decision Trees**. Machine Learning, Vol.
> 1, No. 1, pp. 81-106. Boston: Kluwer Academic Publishers, 1986.
> 
> ROCHA, M.; CORTEZ, P. & NEVES, J. M. **Análise Inteligente de Dados:
> Algoritmos e Implementação em Java.** Lisboa: FCA -- Editora de
> Informática, 2008.
> 
> TAN, P.N.; STEINBACH, M. & KUMAR, V. **Introdução ao Data Mining
> Mineração de Dados.** Rio de Janeiro: Editora Ciência Moderna Ltda.,
> 2009.
> 
> WITTEN, I. H. & FRANK, E. **Data Mining: Practical Machine Learning
> Tools and Techniques.** Second Edition. Amsterdam: Morgan Kaufmann
> Publishers, 2005.
> 
> Weka. The Waikato University. In <http://www.cs.waikato.ac.nz/ml/weka/>
> . Acessado em 03.03.13.
> 
> WITTEN, I. H. & FRANK, E. **Data Mining: Practical Machine Learning
> Tools and Techniques.** Second Edition. Amsterdam: Morgan Kaufmann
> Publishers, 2005.
> 
> Classificação e Árvores de Decisão
> ==================================
> 
> Introdução
> ----------
> 
> É de grande interesse, em muitas situações, conseguir classificar
> antecipadamente o tipo de problema apresentado por um paciente com base
> nos sintomas relatados e tomar medidas para combater determinada doença
> em seu estágio inicial. Em muitos casos reais isso tem sido possível
> graças à análise minuciosa de Bases de Dados contendo anotações médicas
> de outros pacientes com soluções bem sucedidas previamente documentados.
> 
> Em instituições financeiras, para um gerente de banco nem sempre é algo
> simples fazer uma avaliação de risco sobre a concessão de empréstimos de
> alto valor. Com base em dados de transações anteriores e nas
> características específicas de cada cliente, quase sempre é possível
> extrair automaticamente informações não óbvias que ajudam a classificar
> um correntista como bom ou mau pagador.
> 
> Estes são apenas alguns casos em que se verifica que há sempre
> informações úteis e não evidentes em grandes Bases de Dados. Estas
> informações podem ser automaticamente extraídas com Mineração de Dados e
> interpretadas de modo a constituir conhecimento especializado e útil
> para a tomada de decisão. A representação do conhecimento através de
> Árvores de Decisão vai ser o tema deste capítulo.
1133,1157c1770,1864
< Classificação é uma forma de **modelagem preditiva**, isto é, com base nos **atributos de entrada** de um objeto é possível predizer o **atributo de saída** desse objeto. Na prática, os Exemplos de uma Base de Dados estão previamente rotulados em duas ou mais classes para serem utilizados num processo de treinamento, cujo fim é criar uma estrutura de representação do conhecimento contido nessa Base de Dados.
< 
< Quando se fala em Exemplos previamente rotulados geralmente se subentende que eles serão usados em Aprendizado Supervisionado de Máquina. Os rótulos ou classes dos Exemplos orientam o processo de treinamento, ao final do qual se obtém um Modelo que sintetiza todo o conhecimento contido nas variáveis ou nos atributos. Este Modelo pode então ser usado para prever o valor da variável alvo ou do atributo de saída de novos Exemplos desconhecidos.
< 
< O objetivo então da Classificação é predizer em que classe um novo Exemplo, não pertencente ao Conjunto de Treinamento, deve ser colocado. Para que esta tarefa possa ser adequadamente desempenhada é necessário extrair da Base de Dados uma estrutura de conhecimento, tal como Árvores de Decisão ou Regras de Classificação.
< 
< Em outras palavras, o Modelo induzido por inferência é equivalente a uma função que mapeia valores de entrada, geralmente denominados variáveis independentes ou explicativas, a um único valor de saída, geralmente denominado variável dependente ou alvo. Na **Classificação**, a variável de saída, via de regra, é discreta (ou categórica), enquanto que na **Regressão** a variável de saída é contínua.
< 
< A Figura 3.1 ilustra simplificadamente um estudo clássico introduzido por (FISHER, 1936), cujo artigo original apresenta três conjuntos com 50 amostras (ou Exemplos), totalizando 150 medidas do comprimento e da largura de uma pequena flor conhecida como Flor de Lis ou Íris. De acordo com os atributos de entrada "Comprimento" e "Largura" da pétala, cada Exemplo dessa flor pode ser classificado em uma das três classes: Setosa, Versicolor ou Virgínica.
< 
< As linhas tracejadas no gráfico ajudam a entender por que a classificação da Íris do tipo Setosa pode ser mais simples que a dos tipos Versicolor e Virgínica. Como a Íris do tipo Setosa apresenta largura e comprimento da pétala bem menor que as outras duas, basta considerar apenas um dos atributos, digamos Comprimento \< 2,5 cm, para poder classificá-la corretamente. No caso dos tipos Versicolor e Virgínica, tanto o atributo Comprimento quanto Largura se sobrepõem em algumas regiões do gráfico e, portanto, poderá haver erro associado à classificação destes tipos de Íris.
< 
< ![](./media/image22.png){width="5.33125in" height="3.58125in"}
< 
< Figura . -- Representação do Estudo da Flor Íris com Dois Atributos. [^1][^2][^3]
< 
< Em muitas aplicações práticas é perfeitamente aceitável a utilização de algoritmos relativamente simples que produzam um modelo claro de representação do conhecimento, mesmo que isso implique uma certa taxa de erro na classificação. Modelos facilmente compreensíveis de representação de conhecimento, como Árvores de Decisão e Regras de Classificação, permitem que um especialista avalie o modelo e detecte problemas em sua estrutura. Tanto para o médico quanto para o gerente de banco que se utilizam de um modelo de classificação para auxiliar em sua decisão, é importante que eles consigam interpretar todos os passos lógicos utilizados pelo sistema para chegar àquela classificação e avaliá-los à luz da respectiva experiência profissional.
< 
< Por outro lado, em muitas aplicações o mais importante é otimizar a taxa de acerto ou a precisão do modelo, mesmo que isso implique certa perda de clareza, de simplicidade ou de desempenho do modelo. Redes Neurais e Máquinas de Vetor de Suporte são duas ilustrações de técnicas que podem oferecer alta precisão, mas que utilizam modelos de classificação difíceis de entender. É comum o uso dessas duas técnicas na área de aplicações financeiras, porque investidores geralmente estão mais interessados no ganho obtido diariamente na aplicação mais bem classificada do que no modelo matemático explicativo. Por esta razão, a decisão de usar um **modelo orientado ao conhecimento** ou um **modelo tipo caixa-preta** deve ser feita caso a caso.
< 
< Para a tarefa de Classificação, os dois modelos orientados ao conhecimento mais comuns de representação são Árvores de Decisão e Regras de Classificação. Ambos são logicamente equivalentes e permitem que a partir de uma Árvore de Decisão seja possível obter as correspondentes Regras de Classificação, e vice-versa, embora a obtenção de Árvores a partir de Regras seja um processo mais complexo. Há, porém, vantagens e desvantagens observadas durante a geração desses modelos, que serão discutidas mais a frente.
< 
< A Figura 3.2 apresenta modelos simplificados de uma **Árvore de Decisão** e das correspondentes **Regras de Classificação** para o caso da flor Íris. Com estes modelos simplificados, os erros de classificação ilustrados na Figura 3.1 novamente se repetiram aqui. Para reduzir a taxa de erros, veremos que será necessário usar métodos de aprendizado mais refinados ou complexos.
< 
< Dependendo da representação desejada, diferentes métodos de inferência serão usados sobre os dados. Mesmo que um modelo faça classificação com erros, é importante observar que cada Exemplo sempre pertencerá a uma única classe.
---
> Classificação é uma forma de **modelagem preditiva**, isto é, com base
> nos **atributos de entrada** de um objeto é possível predizer o
> **atributo de saída** desse objeto. Na prática, os Exemplos de uma Base
> de Dados estão previamente rotulados em duas ou mais classes para serem
> utilizados num processo de treinamento, cujo fim é criar uma estrutura
> de representação do conhecimento contido nessa Base de Dados.
> 
> Quando se fala em Exemplos previamente rotulados geralmente se
> subentende que eles serão usados em Aprendizado Supervisionado de
> Máquina. Os rótulos ou classes dos Exemplos orientam o processo de
> treinamento, ao final do qual se obtém um Modelo que sintetiza todo o
> conhecimento contido nas variáveis ou atributos. Este Modelo pode então
> ser usado para prever o valor da variável alvo de novos Exemplos
> desconhecidos.
> 
> O objetivo então da Classificação é predizer em que classe um novo
> Exemplo, não pertencente ao Conjunto de Treinamento, deve ser colocado.
> Para que esta tarefa possa ser adequadamente desempenhada é necessário
> extrair da Base de Dados uma estrutura de conhecimento, tal como Árvores
> de Decisão ou Regras de Classificação.
> 
> Em outras palavras, o Modelo induzido por inferência é equivalente a uma
> função que mapeia valores de entrada, geralmente denominados variáveis
> independentes ou explicativas, a um único valor de saída, geralmente
> denominado variável dependente ou alvo. Na **Classificação**, a variável
> de saída, via de regra, é discreta (ou categórica), enquanto que na
> **Regressão** a variável de saída é contínua.
> 
> A Figura 3.1 ilustra simplificadamente um estudo clássico introduzido
> por (Fisher, 1936), cujo artigo original apresenta três conjuntos com 50
> amostras (ou Exemplos), totalizando 150 medidas do comprimento e da
> largura de uma pequena flor conhecida como Flor de Lis ou Íris. De
> acordo com os atributos de entrada "Comprimento" e "Largura" da pétala,
> cada Exemplo dessa flor pode ser classificado em uma das três classes:
> Setosa, Versicolor e Virgínica.
> 
> As linhas tracejadas no gráfico ajudam a entender por que a
> classificação da Íris do tipo Setosa pode ser mais simples que a dos
> tipos Versicolor e Virgínica. Como a Íris do tipo Setosa apresenta
> largura e comprimento da pétala bem menor que as outras duas, basta
> considerar apenas um dos atributos, digamos Comprimento \< 2,5 cm, para
> poder classificá-la corretamente. No caso dos tipos Versicolor e
> Virgínica, tanto o atributo Comprimento quanto Largura se sobrepõem em
> algumas regiões do gráfico e, portanto, poderá haver erro associado à
> classificação destes tipos de Íris.
> 
> ![](media/image22.png){width="5.20625in" height="3.58125in"}
> 
> Figura . -- Representação do Estudo da Flor Íris com Dois Atributos.
> [^1][^2][^3]
> 
> Em muitas aplicações práticas é perfeitamente aceitável a utilização de
> algoritmos relativamente simples que produzam um modelo claro de
> representação do conhecimento, mesmo que isso implique uma certa taxa de
> erro na classificação. Modelos facilmente compreensíveis de
> representação de conhecimento, como Árvores de Decisão e Regras de
> Classificação, permitem que um especialista avalie o modelo e detecte
> problemas em sua estrutura. Tanto para o médico quanto para o gerente de
> banco que se utilizam de um modelo de classificação para auxiliar em sua
> decisão, é importante que eles consigam interpretar todos os passos
> lógicos utilizados pelo sistema para chegar àquela classificação e
> avaliá-los à luz da respectiva experiência profissional.
> 
> Por outro lado, em muitas aplicações o mais importante é otimizar a taxa
> de acerto ou a precisão do modelo, mesmo que isso implique certa perda
> de clareza, de simplicidade ou de desempenho do modelo. Redes Neurais e
> Máquinas de Vetor de Suporte são duas ilustrações de técnicas que podem
> oferecer alta precisão, mas que utilizam modelos de classificação
> difíceis de entender. É comum o uso dessas duas técnicas na área de
> aplicações financeiras, porque investidores geralmente estão mais
> interessados no ganho obtido diariamente na aplicação mais bem
> classificada do que no modelo matemático explicativo. Por esta razão, a
> decisão de usar um **modelo orientado ao conhecimento** ou um **modelo
> tipo caixa-preta** deve ser feita caso a caso.
> 
> Para a tarefa de Classificação, os dois modelos orientados ao
> conhecimento mais comuns de representação são Árvores de Decisão e
> Regras de Classificação. Ambos são logicamente equivalentes e permitem
> que a partir de uma Árvore de Decisão seja possível obter as
> correspondentes Regras de Classificação, e vice-versa, embora a obtenção
> de Árvores a partir de Regras seja um processo mais complexo. Há, porém,
> vantagens e desvantagens observadas durante a geração desses modelos,
> que serão discutidas mais a frente.
> 
> A Figura 3.2 apresenta modelos simplificados de uma **Árvore de
> Decisão** e das correspondentes **Regras de Classificação** para o caso
> da flor Íris. Com estes modelos simplificados, os erros de classificação
> ilustrados na Figura 3.1 novamente se repetiriam aqui. Para reduzir a
> taxa de erros, veremos que será necessário usar métodos de aprendizado
> mais refinados ou complexos.
> 
> Dependendo da representação desejada, diferentes métodos de inferência
> serão usados sobre os dados. Mesmo que um modelo faça classificação com
> erros, é importante observar que cada Exemplo sempre pertencerá a uma
> única classe.
1162c1869,1877
< Numa Árvore de Decisão cada **atributo** é representado por um **nó de decisão**, cuja função é testar o valor desse atributo. Uma **classe** é representada por um **nó folha**, que reúne todos os Exemplos que chegarem a ele depois de satisfazerem os testes dos nós de decisão intermediários. Portanto, numa Árvore de Decisão, a classificação de um Exemplo desconhecido implica percorrer toda a árvore a partir de um **nó raiz**, testando atributos em sucessivos **nós internos** até chegar a um **nó folha**, que lhe atribuirá uma **classe**. O objetivo de uma Árvore de Decisão é retornar uma classe para um Exemplo desconhecido.
---
> Numa Árvore de Decisão cada **atributo** é representado por um **nó de
> decisão**, cuja função é testar o valor desse atributo. Uma **classe** é
> representada por um **nó folha**, que reúne todos os Exemplos que
> chegarem a ele depois de satisfazerem os testes dos nós de decisão
> intermediários. Portanto, numa Árvore de Decisão, a classificação de um
> Exemplo desconhecido implica percorrer toda a árvore a partir de um **nó
> raiz**, testando atributos em sucessivos **nós internos** até chegar a
> um **nó folha**, que lhe atribuirá uma **classe**. O objetivo de uma
> Árvore de Decisão é retornar uma classe para um Exemplo desconhecido.
1168c1883,1884
< Figura . -- Modelos Equivalentes: (a) Árvore de Decisão e (b) Regras de Classificação.
---
> Figura . -- Modelos Equivalentes: (a) Árvore de Decisão e (b) Regras de
> Classificação.
1173,1177c1889,1914
< Uma Árvore de Decisão pode ser construída de forma recursiva, dividindo sucessivamente o conjunto de atributos em subconjuntos. Primeiramente escolhemos um elemento do conjunto de atributos para ser o nó raiz e adicionamos uma aresta para cada um dos possíveis valores que este atributo pode assumir. A seguir, repetimos o processo recursivamente em cada uma das arestas com os atributos restantes até que todos os Exemplos daquele subconjunto pertençam à mesma classe.
< 
< Gerar uma Árvore de Decisão com escolha aleatória da sequência de atributos não é difícil, porém dependendo da ordem desses atributos, diferentes árvores serão geradas. Isso significa que uma mesma Base de Dados pode produzir muitas Árvores de Decisão funcionalmente equivalentes, mas com tamanhos distintos. Como estamos interessados nos modelos mais compactos, é interessante encontrar critérios que ajudem a decidir sobre a ordem em que os atributos devem aparecer na Árvore de Decisão.
< 
< Para ilustrar esta questão, vamos utilizar como caso de estudo novamente a clássica Tabela do Tempo (Tabela 3.1), introduzida por (QUINLAN, 1986), tendo como atributos de entrada "Dia", "Temperatura", "Umidade" e \"Vento", e como atributo de saída (ou classe) "Partida". Para ser mais preciso, na realidade temos duas classes "Sim" e "Não", e queremos construir uma Árvore de Decisão que represente de forma compacta os Exemplos contidos nessa tabela. A seguir, com a Árvore de Decisão obtida, dado um novo Exemplo, vamos tentar predizer se vai ou não haver "Partida" num determinado dia, sendo a resposta a combinação linear dos atributos de entrada.
---
> Uma Árvore de Decisão pode ser construída de forma recursiva, dividindo
> sucessivamente o conjunto de atributos em subconjuntos. Primeiramente
> escolhemos um elemento do conjunto de atributos para ser o nó raiz e
> adicionamos uma aresta para cada um dos possíveis valores que este
> atributo pode assumir. A seguir, repetimos o processo em cada uma das
> arestas com os atributos restantes até que todos os Exemplos
> considerados pertençam à mesma classe.
> 
> Gerar uma Árvore de Decisão com escolha aleatória dos atributos não é
> difícil, porém dependendo da ordem dos atributos, diferentes árvores
> serão geradas. Isso significa que uma mesma Base de Dados pode produzir
> muitas Árvores de Decisão funcionalmente equivalentes, mas com tamanhos
> distintos. Como estamos interessados nos modelos mais compactos, é
> interessante encontrar critérios que ajudem a decidir sobre a ordem em
> que os atributos devem aparecer na Árvore de Decisão.
> 
> Para ilustrar esta questão, vamos utilizar como caso de estudo novamente
> a clássica Tabela do Tempo (Tabela 3.1), introduzida por (Quinlan,
> 1986), tendo como atributos de entrada "Dia", "Temperatura", "Umidade" e
> \"Vento", e como atributo de saída (ou classe) "Partida". Para ser mais
> preciso, na realidade temos duas classes "Sim" e "Não", e queremos
> construir uma Árvore de Decisão que represente de forma compacta os
> Exemplos contidos nessa tabela. A seguir, com a Árvore de Decisão
> obtida, dado um novo Exemplo, vamos tentar predizer se vai ou não haver
> "Partida" num determinado dia, sendo a resposta a combinação linear dos
> atributos de entrada.
1198,1261c1935,2060
< Inicialmente vamos considerar separadamente para o nó raiz cada um dos quatro atributos possíveis e ver como o atributo de saída "Partida" se divide em "Sim" e "Não". Na Tabela 3.2 é ressaltado o atributo "Dia", na Tabela 3.3, "Temperatura", na Tabela 3.4, "Umidade", e na Tabela 3.5, "Vento".
< 
< Como estamos interessados em construir uma árvore compacta, dentre os quatro atributos candidatos para nó raiz, o atributo "Dia" parece o mais promissor porque dentre as três arestas que teremos de colocar neste nó ("Ensolarado", "Nublado" e "Chuvoso"), a aresta para "Nublado" tem **todos** seus elementos pertencentes à mesma classe "Sim" e, portanto, esta aresta da Árvore de Decisão termina aqui com um nó folha "Sim".
< 
< +--------------------------+---------------------------+-----------------------+--------------------------+
< | Tabela . - Dia.          | Tabela . - Temperatura.   | Tabela . - Umidade.   | Tabela . - Vento.        |
< +==========================+===========================+=======================+==========================+
< |   Dia          Partida   |   Temperatura   Partida   |   Umidade   Partida   |   Vento        Partida   |
< |   ------------ --------- |   ------------- --------- |   --------- --------- |   ------------ --------- |
< |   Ensolarado   **Sim**   |   Elevada       **Sim**   |   Alta      **Sim**   |   Falso        **Sim**   |
< |   Ensolarado   **Sim**   |   Elevada       **Sim**   |   Alta      **Sim**   |   Falso        **Sim**   |
< |   Ensolarado   **Não**   |   Elevada       **Não**   |   Alta      **Sim**   |   Falso        **Sim**   |
< |   Ensolarado   **Não**   |   Elevada       **Não**   |   Alta      **Não**   |   Falso        **Sim**   |
< |   Ensolarado   **Não**   |   Amena         **Sim**   |   Alta      **Não**   |   Falso        **Sim**   |
< |   Nublado      **Sim**   |   Amena         **Sim**   |   Alta      **Não**   |   Falso        **Sim**   |
< |   Nublado      **Sim**   |   Amena         **Sim**   |   Alta      **Não**   |   Falso        **Não**   |
< |   Nublado      **Sim**   |   Amena         **Sim**   |   Normal    **Sim**   |   Falso        **Não**   |
< |   Nublado      **Sim**   |   Amena         **Não**   |   Normal    **Sim**   |   Verdadeiro   **Sim**   |
< |   Chuvoso      **Sim**   |   Amena         **Não**   |   Normal    **Sim**   |   Verdadeiro   **Sim**   |
< |   Chuvoso      **Sim**   |   Baixa         **Sim**   |   Normal    **Sim**   |   Verdadeiro   **Sim**   |
< |   Chuvoso      **Sim**   |   Baixa         **Sim**   |   Normal    **Sim**   |   Verdadeiro   **Não**   |
< |   Chuvoso      **Não**   |   Baixa         **Sim**   |   Normal    **Sim**   |   Verdadeiro   **Não**   |
< |   Chuvoso      **Não**   |   Baixa         **Não**   |   Normal    **Não**   |   Verdadeiro   **Não**   |
< +--------------------------+---------------------------+-----------------------+--------------------------+
< 
< A Figura 3.3 ilustra esta primeira iteração na construção de uma Árvore de Decisão compacta.
< 
< Figura . -- Nó Raiz para os Dados do Tempo.
< 
< Como nas arestas "Ensolarado" e "Chuvoso" há elementos tanto da classe "Sim" como da classe "Não" (veja Tabela 3.2), outro atributo deve ser escolhido para cada aresta, e assim sucessivamente até que todos os elementos de um ramo pertençam a uma mesma classe. Como restam os atributos "Temperatura", "Umidade" e "Vento", analisando a Tabela 3.1, vamos testar cada um deles em combinação com a aresta "Ensolarado".
< 
< As Tabelas 3.6, 3.7 e 3.8.mostram as combinações possíveis de "Dia=Ensolarado" com "Temperatura", "Umidade" e "Vento". Aqui também percebemos que "Umidade" parece ser a escolha mais promissora porque todos os elementos de "Umidade=Alta" correspondem à classe "Não" e todos os elementos com "Umidade=Normal" pertencem à classe "Sim". Portanto, temos mais dois nós folhas aqui, favorecendo a construção de uma árvore mais compacta.
< 
< +------------------------------------+---------------------------------------+------------------------------------+
< | Tabela . -- Temperatura.           | Tabela . -- Umidade.                  | Tabela . -- Vento.                 |
< +====================================+=======================================+====================================+
< |   Dia          Temp.     Partida   |   Dia          Umidade      Partida   |   Dia          Vento     Partida   |
< |   ------------ --------- --------- |   ------------ ------------ --------- |   ------------ --------- --------- |
< |   Ensolarado   Elevada   **Não**   |   Ensolarado   **Alta**     **Não**   |   Ensolarado   Falso     **Sim**   |
< |   Ensolarado   Elevada   **Não**   |   Ensolarado   **Alta**     **Não**   |   Ensolarado   Falso     **Não**   |
< |   Ensolarado   Amena     **Sim**   |   Ensolarado   **Alta**     **Não**   |   Ensolarado   Falso     **Não**   |
< |   Ensolarado   Amena     **Não**   |   Ensolarado   **Normal**   **Sim**   |   Ensolarado   Verdade   **Sim**   |
< |   Ensolarado   Baixa     **Sim**   |   Ensolarado   **Normal**   **Sim**   |   Ensolarado   Verdade   **Não**   |
< +------------------------------------+---------------------------------------+------------------------------------+
< 
< A Figura 3.4 ilustra a segunda iteração do algoritmo com mais dois nós folhas, dando por completa esta região da Árvore de Decisão.
< 
< Figura . -- O Atributo "Umidade" Combinado com "Dia".
< 
< Para a terceira aresta, ou seja, "Dia=Chuvoso", restam duas alternativas agora: "Temperatura" e "Vento". Vamos construir as tabelas de combinação para descobrir a mais interessante. As Tabela 3.9 e Tabela 3.10 ilustram as possíveis combinações.
< 
< +-------------------------------------+----------------------------------------+
< | Tabela . -- Dia e Temperatura.      | Tabela . -- Dia e Vento.               |
< +=====================================+========================================+
< |   Dia       Temperatura   Partida   |   Dia       Vento            Partida   |
< |   --------- ------------- --------- |   --------- ---------------- --------- |
< |   Chuvoso   Baixa         **Não**   |   Chuvoso   **Falso**        **Sim**   |
< |   Chuvoso   Baixa         **Sim**   |   Chuvoso   **Falso**        **Sim**   |
< |   Chuvoso   Amena         **Sim**   |   Chuvoso   **Falso**        **Sim**   |
< |   Chuvoso   Amena         **Sim**   |   Chuvoso   **Verdadeiro**   **Não**   |
< |   Chuvoso   Amena         **Não**   |   Chuvoso   **Verdadeiro**   **Não**   |
< +-------------------------------------+----------------------------------------+
< 
< Comparando as duas tabelas, nota-se que o atributo "Vento" é o mais indicado para esta iteração porque todos os elementos de "Vento=Falso" estão classificados como "Sim" e todos os elementos de "Vento=Verdadeiro" estão classificados como "Não". Portanto estas duas arestas da Árvore de Decisão terminam com um nó folha cada. A Figura 3.5 ilustra a nova situação.
---
> Inicialmente vamos considerar separadamente para o nó raiz cada um dos
> quatro atributos possíveis e ver como o atributo de saída "Partida" se
> divide em "Sim" e "Não". Na Tabela 3.2 é ressaltado o atributo "Dia", na
> Tabela 3.3, "Temperatura", na Tabela 3.4, "Umidade", e na Tabela 3.5,
> "Vento".
> 
> Como estamos interessados em construir uma árvore compacta, dentre os
> quatro atributos candidatos para nó raiz, o atributo "Dia" parece o mais
> promissor porque dentre as três arestas que teremos de colocar neste nó
> ("Ensolarado", "Nublado" e "Chuvoso"), a aresta para "Nublado" tem
> **todos** seus elementos pertencentes à mesma classe "Sim" e, portanto,
> esta aresta da Árvore de Decisão termina aqui com um nó folha "Sim".
> 
> +----------------+----------------+----------------+----------------+
> | Tabela . -     | Tabela . -     | Tabela . -     | Tabela . -     |
> | Dia.           | Temperatura.   | Umidade.       | Vento.         |
> +================+================+================+================+
> |   Dia          |   Tempera      |   Umi          |   Vento        |
> |        Partida | tura   Partida | dade   Partida |        Partida |
> |   --------     |   ---------    |   -----        |   --------     |
> | ---- --------- | ---- --------- | ---- --------- | ---- --------- |
> |   Ensola       |   Elevada      |   Alt          |   Falso        |
> | rado   **Sim** |        **Sim** | a      **Sim** |        **Sim** |
> |   Ensola       |   Elevada      |   Alt          |   Falso        |
> | rado   **Sim** |        **Sim** | a      **Sim** |        **Sim** |
> |   Ensola       |   Elevada      |   Alt          |   Falso        |
> | rado   **Não** |        **Não** | a      **Sim** |        **Sim** |
> |   Ensola       |   Elevada      |   Alt          |   Falso        |
> | rado   **Não** |        **Não** | a      **Não** |        **Sim** |
> |   Ensola       |   Amena        |   Alt          |   Falso        |
> | rado   **Não** |        **Sim** | a      **Não** |        **Sim** |
> |   Nublad       |   Amena        |   Alt          |   Falso        |
> | o      **Sim** |        **Sim** | a      **Não** |        **Sim** |
> |   Nublad       |   Amena        |   Alt          |   Falso        |
> | o      **Sim** |        **Sim** | a      **Não** |        **Não** |
> |   Nublad       |   Amena        |   Nor          |   Falso        |
> | o      **Sim** |        **Sim** | mal    **Sim** |        **Não** |
> |   Nublad       |   Amena        |   Nor          |   Verdad       |
> | o      **Sim** |        **Não** | mal    **Sim** | eiro   **Sim** |
> |   Chuvos       |   Amena        |   Nor          |   Verdad       |
> | o      **Sim** |        **Não** | mal    **Sim** | eiro   **Sim** |
> |   Chuvos       |   Baixa        |   Nor          |   Verdad       |
> | o      **Sim** |        **Sim** | mal    **Sim** | eiro   **Sim** |
> |   Chuvos       |   Baixa        |   Nor          |   Verdad       |
> | o      **Sim** |        **Sim** | mal    **Sim** | eiro   **Não** |
> |   Chuvos       |   Baixa        |   Nor          |   Verdad       |
> | o      **Não** |        **Sim** | mal    **Sim** | eiro   **Não** |
> |   Chuvos       |   Baixa        |   Nor          |   Verdad       |
> | o      **Não** |        **Não** | mal    **Não** | eiro   **Não** |
> +----------------+----------------+----------------+----------------+
> 
> A Figura 3.3 ilustra esta primeira iteração na construção de uma Árvore
> de Decisão compacta.
> 
> Figura . -- Nó raiz para os dados do Tempo.
> 
> Como nas arestas "Ensolarado" e "Chuvoso" há elementos tanto da classe
> "Sim" como da classe "Não" (veja Tabela 3.2), outro atributo deve ser
> escolhido para cada aresta, e assim sucessivamente até que todos os
> elementos de um ramo pertençam a uma mesma classe. Como restam os
> atributos "Temperatura", "Umidade" e "Vento", analisando a Tabela 3.1,
> vamos testar cada um deles em combinação com a aresta "Ensolarado".
> 
> As Tabelas 3.6, 3.7 e 3.8.mostram as combinações possíveis de
> "Dia=Ensolarado" com "Temperatura", "Umidade" e "Vento". Aqui também
> percebemos que "Umidade" parece ser a escolha mais promissora porque
> todos os elementos de "Umidade=Alta" correspondem à classe "Não" e todos
> os elementos com "Umidade=Normal" pertencem à classe "Sim". Portanto,
> temos mais dois nós folhas aqui, favorecendo a construção de uma árvore
> mais compacta.
> 
> +----------------------+----------------------+----------------------+
> | Tabela . --          | Tabela . -- Umidade. | Tabela . -- Vento.   |
> | Temperatura.         |                      |                      |
> +======================+======================+======================+
> |   Dia                |   Dia                |   Dia                |
> |    Temp.     Partida | Umidade      Partida |    Vento     Partida |
> |   ------------       |   ------------ --    |   ------------       |
> |  --------- --------- | ---------- --------- |  --------- --------- |
> |   Ensolarado         |   Ensolarado         |   Ensolarado         |
> |    Elevada   **Não** | **Alta**     **Não** |    Falso     **Sim** |
> |   Ensolarado         |   Ensolarado         |   Ensolarado         |
> |    Elevada   **Não** | **Alta**     **Não** |    Falso     **Não** |
> |   Ensolarado         |   Ensolarado         |   Ensolarado         |
> |    Amena     **Sim** | **Alta**     **Não** |    Falso     **Não** |
> |   Ensolarado         |   Ensolarado         |   Ensolarado         |
> |    Amena     **Não** | **Normal**   **Sim** |    Verdade   **Sim** |
> |   Ensolarado         |   Ensolarado         |   Ensolarado         |
> |    Baixa     **Sim** | **Normal**   **Sim** |    Verdade   **Não** |
> +----------------------+----------------------+----------------------+
> 
> A Figura 3.4 ilustra a segunda iteração do algoritmo com mais dois nós
> folhas, dando por completa esta região da Árvore de Decisão.
> 
> Figura . -- O atributo "Umidade" combinado com "Dia".
> 
> Para a terceira aresta, ou seja, "Dia=Chuvoso", restam duas alternativas
> agora: "Temperatura" e "Vento". Vamos construir as tabelas de combinação
> para descobrir a mais interessante. As Tabela 3.9 e Tabela 3.10 ilustram
> as possíveis combinações.
> 
> +----------------------------------+----------------------------------+
> | Tabela . -- Dia e Temperatura.   | Tabela . -- Dia e Vento.         |
> +==================================+==================================+
> |                                  |   Di                             |
> |  Dia       Temperatura   Partida | a       Vento            Partida |
> |   -                              |   ----                           |
> | -------- ------------- --------- | ----- ---------------- --------- |
> |                                  |   Ch                             |
> |  Chuvoso   Baixa         **Não** | uvoso   **Falso**        **Sim** |
> |                                  |   Ch                             |
> |  Chuvoso   Baixa         **Sim** | uvoso   **Falso**        **Sim** |
> |                                  |   Ch                             |
> |  Chuvoso   Amena         **Sim** | uvoso   **Falso**        **Sim** |
> |                                  |   Ch                             |
> |  Chuvoso   Amena         **Sim** | uvoso   **Verdadeiro**   **Não** |
> |                                  |   Ch                             |
> |  Chuvoso   Amena         **Não** | uvoso   **Verdadeiro**   **Não** |
> +----------------------------------+----------------------------------+
> 
> Comparando as duas tabelas, nota-se que o atributo "Vento" é o mais
> indicado para esta iteração porque todos os elementos de "Vento=Falso"
> estão classificados como "Sim" e todos os elementos de
> "Vento=Verdadeiro" estão classificados como "Não". Portanto estas duas
> arestas da Árvore de Decisão terminam com um nó folha cada. A Figura 3.5
> ilustra a nova situação.
1265,1269c2064,2085
< Nesta iteração o algoritmo termina, pois todos os Exemplos da tabela foram avaliados e classificados em suas respectivas classes. Porém algumas considerações podem ser feitas.
< 
< Por trás do critério de seleção de atributos aqui apresentado de forma intuitiva, há uma sólida justificativa matemática introduzida por (QUINLAN, 1986), baseada na Teoria da Informação de Claude Shannon, capaz de avaliar a quantidade de informação do melhor atributo dentre os candidatos para teste em um determinado nó.
< 
< O critério de escolha do melhor atributo para cada iteração no algoritmo ID3, criado por (QUINLAN, 1986), é medido pela significância estatística, que em nosso caso se expressa pela proporção de "Sim"s e "Não"s no atributo de saída "Partida". Como foi ilustrado anteriormente, é mais promissor escolher um atributo que tenha associado a ele respostas compostas unicamente por "Sim"s ou "Não"s porque neste caso podemos colocar um nó folha correspondente e terminar com as subdivisões. Em outras palavras, quanto mais compacta uma árvore, menos testes serão necessários para classificar um Exemplo. Por outro lado, se o conjunto de respostas é composto por uma mescla de "Sim"s e "Não"s, então faz-se necessário colocar mais um nó interno, com um novo atributo sendo testado, implicando um crescimento da Árvore de Decisão.
---
> Nesta iteração o algoritmo termina, pois todos os Exemplos da tabela
> foram avaliados e classificados em suas respectivas classes. Porém
> algumas considerações podem ser feitas.
> 
> Por trás do critério de seleção de atributos aqui apresentado de forma
> intuitiva, há uma sólida justificativa matemática introduzida por
> (Quinlan, 1986), baseada na Teoria da Informação de Claude Shannon,
> capaz de avaliar a quantidade de informação do melhor atributo dentre os
> candidatos para teste em um determinado nó.
> 
> O critério de escolha do melhor atributo para cada iteração no algoritmo
> ID3, criado por (Quinlan, 1986), é medido pela significância
> estatística, que em nosso caso se expressa pela proporção de "Sim"s e
> "Não"s no atributo de saída "Partida". Como foi ilustrado anteriormente,
> é mais promissor escolher um atributo que tenha associado a ele
> respostas compostas unicamente por "Sim"s ou "Não"s porque neste caso
> podemos colocar um nó folha correspondente e terminar com as
> subdivisões. Em outras palavras, quanto mais compacta uma árvore, menos
> testes serão necessários para classificar um Exemplo. Por outro lado, se
> o conjunto de respostas é composto por uma mescla de "Sim"s e "Não"s,
> então faz-se necessário colocar mais um nó interno, com um novo atributo
> sendo testado, implicando um crescimento da Árvore de Decisão.
1273c2089,2094
< sendo *p~i~* a proporção de "Sim"s e "Não"s associados a um atributo (a quantidade de informação ou entropia é medida em bits, ou frações de bits!). Por exemplo, na Tabela 3.1 temos apenas duas classes ("Sim" e "Não"), sendo que dos 14 Exemplos, 9 pertencem à classe "Sim" e 5 à classe "Não". Portanto, a quantidade de informação associada a esta tabela pode ser calculada da seguinte forma,
---
> sendo *p~i~* a proporção de "Sim"s e "Não"s associados a um atributo (a
> quantidade de informação ou entropia é medida em bits, ou frações de
> bits!). Por ex., na Tabela 3.1 temos apenas duas classes ("Sim" e
> "Não"), sendo que dos 14 Exemplos, 9 pertencem à classe "Sim" e 5 à
> classe "Não". Portanto, a quantidade de informação associada a esta
> tabela pode ser calculada da seguinte forma,
1277c2098,2102
< Uma forma alternativa de interpretar estes números é pensar que estamos interessados em medir o grau de "impureza" de um conjunto de respostas. Se todas as respostas forem apenas "Sim" ou apenas "Não", então o grau de impureza do conjunto é 0. Por outro lado, se tivermos 10% de "Sim"s e 90% de "Não"s, então o grau de impureza seria,
---
> Uma forma alternativa de interpretar estes números, é pensar que estamos
> interessados em medir o grau de "impureza" de um conjunto de respostas.
> Se todas as respostas forem apenas "Sim" ou apenas "Não", então o grau
> de impureza do conjunto é 0. Por outro lado, se tivermos 10% de "Sim"s e
> 90% de "Não"s, então o grau de impureza seria,
1281,1283c2106,2116
< De acordo com este raciocínio, o grau de impureza máxima é representado pela proporção 50% de "Sim"s e 50% de "Não"s, sendo Info(Tab\_(50/50) = 1 *bit*).
< 
< Voltando ao nosso problema original de escolha do atributo mais promissor em cada iteração do algoritmo, vamos calcular o grau de impureza da Tabela 3.2, que se refere ao atributo "Dia". Esse atributo se subdivide em três alternativas possíveis, com as seguintes proporções de "Sim"s e "Não"s: "Ensolarado" (2"Sim"/3"Não)", "Nublado" (4"Sim"/0"Não) e "Chuvoso" (3"Sim"/2"Não"). Portanto, seu grau de impureza é,
---
> De acordo com este raciocínio, o grau de impureza máxima é representado
> pela proporção 50% de "Sim"s e 50% de "Não"s, sendo Info(Tab\_(50/50) =
> 1 *bit*).
> 
> Voltando ao nosso problema original de escolha do atributo mais
> promissor em cada iteração do algoritmo, vamos calcular o grau de
> impureza da Tabela 3.2, que se refere ao atributo "Dia". Esse atributo
> se subdivide em três alternativa possíveis, com as seguintes proporções
> de "Sim"s e "Não"s: "Ensolarado" (2"Sim"/3"Não)", "Nublado"
> (4"Sim"/0"Não) e "Chuvoso" (3"Sim"/2"Não"). Portanto, seu grau de
> impureza é,
1291c2124,2125
< Fazendo a soma ponderada de cada uma dessas alternativas sobre os 14 Exemplos, resulta,
---
> Fazendo a soma ponderada de cada uma dessas alternativas sobre os 14
> Exemplos, resulta,
1295c2129,2130
< Aplicando-se raciocínio semelhante para os atributos "Temperatura", "Umidade" e "Vento" obtêm-se os seguintes valores,
---
> Aplicando-se raciocínio semelhante para os atributos "Temperatura",
> "Umidade" e "Vento" obtêm-se os seguintes valores,
1303,1305c2138,2149
< Portanto, dos quatro atributos possíveis na primeira iteração, o atributo "Dia" é o que tem o grau mais baixo de impureza, e , portanto, é o mais promissor para construir uma Árvore de Decisão Compacta. Continuando este procedimento recursivamente, chega-se a Árvore de Decisão apresentada na Figura 3.5.
< 
< Há mais sutilezas matemáticas envolvidas que não foram mencionadas, e outros detalhes importantes do algoritmo ID3 precisariam ser abordados se nossa intenção fosse explicar seu funcionamento. Porém, o que pretendemos aqui é apenas dar uma ideia de seu embasamento teórico para que ao nos depararmos com uma ferramenta que implemente este algoritmo seja possível entender o resultado de seus cálculos.
---
> Portanto, dos quatro atributos possíveis na primeira iteração, o
> atributo "Dia" é o que tem o grau mais baixo de impureza, e , portanto,
> é o mais promissor para construir uma Árvore de Decisão Compacta.
> Continuando este procedimento recursivamente, chega-se a Árvore de
> Decisão apresentada na Figura 3.5.
> 
> Há mais sutilezas matemáticas envolvidas que não foram mencionadas, e
> outros detalhes importantes do algoritmo ID3 precisariam ser abordados
> se nossa intenção fosse explicar seu funcionamento. Porém, o que
> pretendemos aqui é apenas dar uma ideia de seu embasamento teórico para
> que ao nos depararmos com uma ferramenta que implemente este algoritmo
> seja possível entender o resultado de seus cálculos.
1310c2154,2159
< Para efeito comparativo, vamos supor que algum critério arbitrário de escolha da ordem dos atributos tenha sido utilizado e que o nó raiz contenha o atributo "Umidade". A Tabela 3.11 mostra que este atributo possui Exemplos misturados pertencentes a classes distintas, portanto é necessário um novo teste, i.e., escolher um novo atributo para teste. A Figura 3.6 mostra o resultado dessa escolha arbitrária.
---
> Para efeito comparativo, vamos supor que algum critério arbitrário de
> escolha da ordem dos atributos tenha sido utilizado e que o nó raiz
> contenha o atributo "Umidade". A Tabela 3.11 mostra que este atributo
> possui Exemplos misturados pertencentes a classes distintas, portanto é
> necessário um novo teste, i.e., escolher um novo atributo para teste. A
> Figura 3.6 mostra o resultado dessa escolha arbitrária.
1312c2161
< Tabela . - Umidade (Escolha Arbitrária).
---
> Tabela . - Umidade (arbitrária).
1333c2182,2185
< O atributo escolhido arbitrariamente agora foi "Dia" e as combinações possíveis com "Umidade" são mostradas na Tabela 3.12. A segunda iteração do algoritmo para a construção da Árvore de Decisão Alternativa é mostrada na Figura 3.7.
---
> O atributo escolhido arbitrariamente agora foi "Dia" e as combinações
> possíveis com "Umidade" são mostradas na Tabela 3.12. A segunda iteração
> do algoritmo para a construção da Árvore de Decisão Alternativa é
> mostrada na Figura 3.7.
1349c2201,2206
< Embora as arestas de "Dia=Ensolarado" e "Dia=Nublado" terminem em nó folha, a aresta para "Dia=Chuvoso" exige um novo teste já que há duas respostas distintas possíveis. O próximo atributo escolhido arbitrariamente foi "Vento", como mostra a Tabela 3.13. A ilustração da Figura 3.8 ajuda a entender como a falta de uma rotina de otimização produz árvores desnecessariamente grandes.
---
> Embora as arestas de "Dia=Ensolarado" e "Dia=Nublado" terminem em nó
> folha, a aresta para "Dia=Chuvoso" exige um novo teste já que há duas
> respostas distintas possíveis. O próximo atributo escolhido
> arbitrariamente foi "Vento", como mostra a Tabela 3.13. A ilustração da
> Figura 3.8 ajuda a entender como a falta de uma rotina de otimização
> produz árvores desnecessariamente grandes.
1360c2217,2221
< A Tabela 3.13 mostra que esta região da Árvore de Decisão está encerrada, com dois novos nós folhas. Vamos agora considerar a aresta correspondente a "Umidade=Normal" (Tabela 3.14) e supor que o novo teste escolhido será o atributo "Dia". O resultado da escolha do atributo "Dia" para a aresta de "Umidade=Normal" é mostrado na Figura 3.9.
---
> A Tabela 3.13 mostra que esta região da Árvore de Decisão está
> encerrada, com dois novos nós folhas. Vamos agora considerar a aresta
> correspondente a "Umidade=Normal" (Tabela 3.14) e supor que o novo teste
> escolhido será o atributo "Dia". O resultado da escolha do atributo
> "Dia" para a aresta de "Umidade=Normal" é mostrado na Figura 3.9.
1374c2235
< Figura . -- Atributo "Dia" Usado em Duas Posições Diferentes.
---
> Figura . -- Atributo "Dia" Usados em Duas Posições Diferentes.
1376c2237,2240
< Como a opção de "Dia=Chuvoso" exige um novo teste, vamos supor que o atributo escolhido tenha sido "Vento", produzindo o resultado mostrado na Tabela 3.15. O resultado final da Árvore de Decisão Não-Compacta é mostrado na Figura 3.10.
---
> Como a opção de "Dia=Chuvoso" exige um novo teste, vamos supor que o
> atributo escolhido tenha sido "Vento", produzindo o resultado mostrado
> na Tabela 3.15. O resultado final da Árvore de Decisão Não-Compacta é
> mostrado na Figura 3.10.
1388,1390c2252,2259
< Com este teste, o algoritmo se encerra já que todos os Exemplos foram devidamente considerados e se encaixaram num dos caminhos possíveis da Árvore de Decisão.
< 
< Tanto a árvore da Figura 3.5 quanto a da Figura 3.10 classificam corretamente todos os Exemplos da Tabela do Tempo representada pela Tabela 3.1. Mas, como a Tabela 3.5 é mais compacta, ela deve ser preferida.
---
> Com este teste, o algoritmo se encerra já que todos os Exemplos foram
> devidamente considerados e se encaixaram num dos caminhos possíveis da
> Árvore de Decisão.
> 
> Tanto a árvore da Figura 3.5 quanto a da Figura 3.10 classificam
> corretamente todos os Exemplos da Tabela do Tempo representada pela
> Tabela 3.1. Mas, como a Tabela 3.5 é mais compacta, ela deve ser
> preferida.
1395,1399c2264,2291
< Comparando-se as Árvores de Decisão das Figura 3.5 e Figura 3.10, percebe-se que em nenhuma das duas aparece o atributo "Temperatura" e, no entanto, ambas classificam corretamente todos os Exemplos. Considerando que essas Árvores de Decisão representam as relações relevantes entre os valores dos atributos e os respectivos rótulos de classe, isso significa que "Temperatura" não é essencial para a determinação de classe do atributo de saída "Partida". O conjunto de Exemplos da Tabela do Tempo mostra que a combinação dos outros atributos é que determina se vai ou não haver uma partida, independentemente da "Temperatura" (porque possivelmente a partida se dará em ambiente fechado).
< 
< Ao fazer este tipo de análise para explicar um padrão de relacionamento entre atributos, estamos usando uma Árvore de Decisão como um modelo descritivo, e não preditivo. Isso ilustra outra aplicação interessante das Árvores de Decisão na qual o objetivo é adquirir um melhor entendimento sobre os dados coletados e, dessa forma, formular hipóteses explicativas para um fenômeno em estudo.
< 
< Considere, por exemplo, a pesquisa sobre determinada doença, para a qual foram coletados dados médicos de pacientes portadores ou não dessa doença. A descoberta de quais fatores podem desencadeá-la, e de quais fatores são irrelevantes, é da maior importância para a pesquisa médica. Em outras áreas, a modelagem descritiva pode ser igualmente interessante. Pense, por exemplo, na importância em entender o comportamento dos frequentadores de determinado estabelecimento comercial, ou no aumento de lucro que alguém pode obter ao traçar o perfil de consumo de um segmento social.
---
> Comparando-se as Árvores de Decisão das Figura 3.5 e Figura 3.10,
> percebe-se que em nenhuma das duas aparece o atributo "Temperatura" e,
> no entanto, ambas classificam corretamente todos os Exemplos.
> Considerando que essas Árvores de Decisão representam as relações
> relevantes entre os valores dos atributos e os respectivos rótulos de
> classe, isso significa que "Temperatura" não é essencial para a
> determinação de classe do atributo de saída "Partida". O conjunto de
> Exemplos da Tabela do Tempo mostra que a combinação dos outros atributos
> é que determina se vai ou não haver uma partida, independentemente da
> "Temperatura" (porque possivelmente a partida se dará em ambiente
> fechado).
> 
> Ao fazer este tipo de análise para explicar um padrão de relacionamento
> entre atributos, estamos usando uma Árvore de Decisão como um modelo
> descritivo, e não preditivo. Isso ilustra outra aplicação interessante
> das Árvores de Decisão na qual o objetivo é adquirir um melhor
> entendimento sobre os dados coletados e, dessa forma, formular hipóteses
> explicativas para um fenômeno em estudo.
> 
> Considere, por ex., a pesquisa sobre determinada doença, para a qual
> foram coletados dados médicos de pacientes portadores ou não dessa
> doença. A descoberta de quais fatores podem desencadeá-la, e de quais
> fatores são irrelevantes, é da maior importância para a pesquisa médica.
> Em outras áreas, a modelagem descritiva pode ser igualmente
> interessante. Pense, por ex., na importância em entender o comportamento
> dos frequentadores de determinado estabelecimento comercial, ou no
> aumento de lucro que alguém pode obter ao traçar o perfil consumista de
> um segmento social.
1404,1406c2296,2304
< A geração de Regras de Classificação a partir de uma Árvore de Decisão é feita percorrendo desde o nó raiz até um nó folha, anotando a conjunção de condições representadas pelos nós internos. A cada classe da Árvore de Decisão corresponde uma Regra de Classificação, sendo ambas logicamente equivalentes.
< 
< Vamos reproduzir a Árvore de Decisão da Figura 3.5 para ilustrar esse processo de geração de Regras de Classificação a partir de uma Árvore de Decisão.
---
> A geração de Regras de Classificação a partir de uma Árvore de Decisão é
> feita percorrendo desde o nó raiz até um nó folha, anotando a conjunção
> de condições representadas pelos nós internos. A cada classe da Árvore
> de Decisão corresponde uma Regra de Classificação, sendo ambas
> logicamente equivalentes.
> 
> Vamos reproduzir a Árvore de Decisão da Figura 3.5 para ilustrar esse
> processo de geração de Regras de Classificação a partir de uma Árvore de
> Decisão.
1410,1424c2308,2341
< Partindo-se do nó raiz "Dia", seguindo pela aresta correspondente à condição "Ensolarado", passando pelo nó interno "Umidade" e, finalmente, tomando a aresta "Alta", chega-se ao nó folha "Não". Dessa forma, podemos gerar a primeira regra relativa à classe "Não", como ilustra a Regra 3.1:
< 
< ***IF*** (Dia **=** Ensolarado) ***AND*** (Umidade **=** Alta) ***THEN*** (Partida ***=*** Não) (3.1)
< 
< Esta regra foi construída como uma conjunção lógica ("*AND*") de duas condições lógicas. Por inspeção na Árvore de Decisão da Figura 3.5 verifica-se que há outro caminho terminando na classe "Não", que pode ser representado pela Regra 3.2:
< 
< ***IF*** (Dia **=** Chuvoso) ***AND*** (Vento **=** Verdadeiro) ***THEN*** (Partida **=** Não) (3.2)
< 
< As duas Regras 3.1 e 3.2, formadas por conjunções ("*AND*"), podem ser fundidas numa única regra utilizando-se uma disjunção lógica ("*OR*"), como mostra a Regra 3.3:
< 
< ***IF*** \[(Dia **=** Ensolarado) ***AND*** (Umidade **=** Alta)\] ***OR*** \[(Dia **=** Chuvoso) ***AND*** (Vento **=** Verdadeiro)\] ***THEN*** (Partida ***=*** Não) (3.3)
< 
< Regras com estrutura lógica semelhante à Regra 3.3 são conhecidas como regras na forma disjunção de conjunções. Aplicando-se o mesmo procedimento descrito para os casos restantes, obtém-se a Regra de Classificação correspondente à classe "Sim", representada pela Regra 3.4:
< 
< ***IF*** \[(Dia **=** Ensolarado) ***AND*** (Umidade **=** Normal)\] ***OR*** \[(Dia **=** Nublado)\] ***OR*** \[(Dia **=** Chuvoso) ***AND*** (Vento **=** Falso)\] ***THEN*** (Partida **=** Sim) (3.4)
---
> Partindo-se do nó raiz "Dia", seguindo pela aresta correspondente à
> condição "Ensolarado", passando pelo nó interno "Umidade" e, finalmente,
> tomando a aresta "Alta", chega-se ao nó folha "Não". Dessa forma,
> podemos gerar a primeira regra relativa à classe "Não", como ilustra a
> Regra 3.1:
> 
> ***IF*** (Dia **=** Ensolarado) ***AND*** (Umidade **=** Alta)
> ***THEN*** (Partida ***=*** Não) (3.1)
> 
> Esta regra foi construída como uma conjunção lógica ("*AND*") de duas
> condições lógicas. Por inspeção na Árvore de Decisão da Figura 3.5
> verifica-se que há outro caminho que pode levar à classe "Não", que pode
> ser representada pela Regra 3.2:
> 
> ***IF*** (Dia **=** Chuvoso) ***AND*** (Vento **=** Verdadeiro)
> ***THEN*** (Partida **=** Não) (3.2)
> 
> As duas Regras 3.1 e 3.2, formadas por conjunções ("*AND*"), podem ser
> fundidas numa única regra utilizando-se uma disjunção lógica ("*OR*"),
> como mostra a Regra 3.3:
> 
> ***IF*** \[(Dia **=** Ensolarado) ***AND*** (Umidade **=** Alta)\]
> ***OR*** \[(Dia **=** Chuvoso) ***AND*** (Vento **=** Verdadeiro)\]
> ***THEN*** (Partida ***=*** Não) (3.3)
> 
> Regras com estrutura lógica semelhante à Regra 3.3 são conhecidas como
> regras na forma disjunção de conjunções. Aplicando-se o mesmo
> procedimento descrito para os casos restantes, obtém-se a Regra de
> Classificação correspondente à classe "Sim", representada pela Regra
> 3.4:
> 
> ***IF*** \[(Dia **=** Ensolarado) ***AND*** (Umidade **=** Normal)\]
> ***OR*** \[(Dia **=** Nublado)\] ***OR*** \[(Dia **=** Chuvoso)
> ***AND*** (Vento **=** Falso)\] ***THEN*** (Partida **=** Sim) (3.4)
1429,1439c2346,2396
< Recapitulando o que foi feito até aqui, inicialmente consideramos a existência de uma Base de Dados codificada na forma de uma tabela com vários atributos. A seguir, apresentamos um algoritmo capaz de construir uma Árvore de Decisão a partir desses dados estruturados. Como cada Exemplo da Base de Dados era composto por alguns atributos e um rótulo de classe (ou atributo de saída), nós podemos entender todo este processo de construção de Árvores de Decisão como sendo um processo de **Aprendizado Supervisionado** por meio de **Treinamento**.
< 
< Diz-se que o **Aprendizado** é **Supervisionado** quando cada **Exemplo** usado no **Treinamento** possui um **rótulo de classe** que orienta (ou otimiza) um mecanismo de reforço ou penalização, ou seja, quando já se sabe antecipadamente a qual classe determinado elemento pertence. Muitas vezes os Exemplos não trazem o rótulo de classe e ainda assim é possível ocorrer aprendizado, porém, nestes casos diz-se que o Aprendizado é Não-Supervisionado. Por exemplo, com um conjunto de Exemplos sem rótulos de classe é possível agrupá-los de acordo com algum critério, como o critério de afinidade.
< 
< A Árvore de Decisão resultante representa o Modelo gerado ou o Conceito aprendido. Note que para cada Base de Dados será construída uma Árvore de Decisão que lhe corresponde. Ou seja, nós temos um algoritmo que em princípio gera árvores genéricas, que refletem a estrutura dos dados utilizados no treinamento. Como a Árvore de Decisão gerada poderá ser usada para diagnosticar doenças, classificar produtos comerciais, ou explicar a correlação de fatores de um fenômeno, podemos dizer que o Sistema Inteligente que emprega este tipo de algoritmo de aprendizado melhora seu desempenho a partir de sua própria experiência (ou treinamento). A Figura 3.11 ilustra as três fases de um Sistema Inteligente Classificatório.
< 
< Figura . -- Treinamento, Aprendizado e Classificação em um Sistema Inteligente Simples.
< 
< O Treinamento viabiliza o Aprendizado de um Conceito pelo Sistema Inteligente, e a aquisição de um Conceito pelo sistema elimina a necessidade de um aprendizado constante. O processo de Aprendizado pode ser demorado, mas uma vez aprendido um Conceito, o processo de Classificação é bem mais rápido. A Figura 3.11 não mostra outros caminhos ou fluxos de trabalho do sistema para a obtenção do Modelo desejado de Árvore de Decisão. É comum que após a geração do primeiro modelo de árvore, os resultados obtidos não sejam satisfatórios. Nesse caso, uma nova rodada de treinamento se inicia, com novos parâmetros e ajustes adicionais, até a geração de um segundo modelo. Este processo se repete de forma iterativa e interativa até que se chegue a uma Árvore de Decisão com as características buscadas.
< 
< Tendo descrito o processo de criação ou indução de uma Árvore de Decisão, vamos ver agora que resultados de classificação podemos obter com esta árvore. A Tabela 3.16 apresenta alguns novos Exemplos que usaremos para teste.
---
> Recapitulando o que foi feito até aqui, inicialmente consideramos a
> existência de uma Base de Dados codificada na forma de uma tabela com
> vários atributos. A seguir, apresentamos um algoritmo capaz de construir
> uma Árvore de Decisão a partir desses dados estruturados. Como cada
> Exemplo da Base de Dados era composto por alguns atributos e um rótulo
> de classe (ou atributo de saída), nós podemos entender todo este
> processo de construção de Árvores de Decisão como sendo um processo de
> **Aprendizado Supervisionado** por meio de **Treinamento**.
> 
> Diz-se que o **Aprendizado** é **Supervisionado** quando cada
> **Exemplo** usado no **Treinamento** possui um **rótulo de classe** que
> orienta (ou otimiza) um mecanismo de reforço ou penalização, ou seja,
> quando já se sabe antecipadamente a qual classe determinado elemento
> pertence. Muitas vezes os Exemplos não trazem o rótulo de classe e ainda
> assim é possível ocorrer aprendizado, porém, nestes casos diz-se que o
> Aprendizado é Não-Supervisionado. Por ex., com um conjunto de Exemplos
> sem rótulos de classe é possível agrupá-los de acordo com algum
> critério, como o critério de afinidade.
> 
> A Árvore de Decisão resultante representa o Modelo gerado ou o Conceito
> aprendido. Note que para cada Base de Dados será construída uma Árvore
> de Decisão que lhe corresponde. Ou seja, nós temos um algoritmo que em
> princípio gera árvores genéricas, que refletem a estrutura dos dados
> utilizados no treinamento. Como a Árvore de Decisão gerada poderá ser
> usada para diagnosticar doenças, classificar produtos comerciais, ou
> explicar a correlação de fatores de um fenômeno, podemos dizer que o
> Sistema Inteligente que emprega este tipo de algoritmo de aprendizado
> melhora seu desempenho a partir de sua própria experiência (ou
> treinamento). A Figura 3.11 ilustra as três fases de um Sistema
> Inteligente Classificatório.
> 
> Figura . -- Treinamento, Aprendizado e Classificação em um Sistema
> Inteligente Simples.
> 
> O Treinamento viabiliza o Aprendizado de um Conceito pelo Sistema
> Inteligente, e a aquisição de um Conceito pelo sistema elimina a
> necessidade de um aprendizado constante. O processo de Aprendizado pode
> ser demorado, mas uma vez aprendido um Conceito, o processo de
> Classificação é bem mais rápido. A Figura 3.11 não mostra outros
> caminhos ou fluxos de trabalho do sistema para a obtenção do Modelo
> desejado de Árvore de Decisão. É comum que após a geração do primeiro
> modelo de árvore, os resultados obtidos não sejam satisfatórios. Nesse
> caso, nova rodada de treinamento se inicia, com novos parâmetros e
> ajustes adicionais, até a geração de um segundo modelo. Este processo se
> repete de forma iterativa e interativa até que se chegue a uma Árvore de
> Decisão com as características buscadas.
> 
> Tendo descrito o processo de criação ou indução de uma Árvore de
> Decisão, vamos ver agora que resultados de classificação podemos obter
> com esta árvore. A Tabela 3.16 apresenta alguns novos Exemplos que
> usaremos para teste.
1465,1472c2422,2427
< Usando tanto a Árvore de Decisão da Figura 3.5 quanto a da Figura 3.10, o resultado para o primeiro Exemplo de Teste, aquele que se inicia com "Dia=Ensolarado" e "Temperatura=Amena", é "Sim", para o segundo Exemplo, com "Dia=Ensolarado" e "Temperatura=Baixa" , a resposta é "Não", para o terceiro Exemplo "Dia=Nublado", a resposta é "Sim" e finalmente para o quarto Exemplo, com "Dia=Chuvoso", a resposta é "Sim".
< 
< *Overfitting* e Poda
< --------------------
< 
< É possível que para alguns Exemplos de Teste os resultados produzidos por Árvores de Decisão compactas, como a da Figura 3.5, não sejam os mesmos de Árvores de Decisão não-compactas, como a da Figura 3.10, muito embora os resultados para todos os Exemplos de Treinamento tenham sido os mesmos. O que pode ocorrer com árvores não compactas é que algumas das arestas refletem um superajuste (*overfitting*) aos Exemplos de Treinamento. Se neste Conjunto de Treinamento houver ruído ou *outliers*, a estrutura resultante da Árvore de Decisão pode não refletir às relações essenciais entre os atributos da Base de Dados.
< 
< Para evitar o *overfitting*, muitos algoritmos se valem de uma técnica conhecida como "Poda", que consiste em eliminar algumas arestas da Árvore de Decisão com base em medidas estatísticas dos Exemplos. A Poda pode ocorrer sobre uma Árvore de Decisão concluída, com a eliminação de algumas arestas consideradas desnecessárias, ou durante a construção da Árvore de Decisão, com a introdução precoce de um nó folha em arestas com baixa importância estatística, por exemplo.
---
> Usando tanto a Árvore de Decisão da Figura 3.5 quanto a da Figura 3.10,
> o resultado para o primeiro Exemplo de Teste, aquele que se inicia com
> "Dia=Ensolarado" e "Temperatura=Amena", é "Sim", para o segundo Exemplo,
> com "Dia=Ensolarado" e "Temperatura=Baixa" , a resposta é "Não", para o
> terceiro Exemplo "Dia=Nublado", a resposta é "Sim" e finalmente para o
> quarto Exemplo, com "Dia=Chuvoso", a resposta é "Sim".
1474c2429,2430
< A Árvore de Decisão da Figura 3.10 poderia ter algumas de suas arestas removidas sem comprometer seriamente a taxa de erros na classificação. De fato, observando-se a Tabela 3.4, verifica-se que dos sete Exemplos que apresentam "Umidade=Normal", seis deles têm rótulo de classe "Sim". Por esta razão, o nó interno à direita da Figura 3.10, (reproduzida na Figura 3.12(a)), representando o atributo "Vento", poderia ser eliminado e substituído por um nó folha "Sim" já que a maioria dos Exemplos que chegam a este nó apresentam o rótulo de classe "Sim". A seguir, o nó interno "Dia" também pode ser eliminado pois todas seus nós terminais passaram a ser do tipo "Sim". A Figura 3.12 mostra o resultado desse processo de Poda.
---
> Overfitting e Poda
> ------------------
1476c2432,2465
< Para avaliar quantitativamente o desempenho de um modelo gerado, seja ele uma Árvore de Decisão ou um conjunto de Regras de Classificação, veremos que há técnicas e medidas de desempenho especialmente desenvolvidas para este fim.
---
> É possível que para alguns Exemplos de Teste os resultados produzidos
> por Árvores de Decisão compactas, como a da Figura 3.5, não sejam os
> mesmos de Árvores de Decisão não-compactas, como a da Figura 3.10, muito
> embora os resultados para todos os Exemplos de Treinamento tenham sido
> os mesmos. O que pode ocorrer com árvores não compactas é que algumas
> das arestas refletem um superajuste (*overfitting*) aos Exemplos de
> Treinamento. Se neste Conjunto de Treinamento houver ruído ou
> *outliers*, a estrutura resultante da Árvore de Decisão pode não
> refletir às relações essenciais entre os atributos da Base de Dados.
> 
> Para evitar o *overfitting*, muitos algoritmos se valem de uma técnica
> conhecida como "Poda", que consiste em eliminar algumas arestas da
> Árvore de Decisão com base em medidas estatísticas dos Exemplos. A Poda
> pode ocorrer sobre uma Árvore de Decisão concluída, com a eliminação de
> algumas arestas consideradas não necessárias, ou durante a construção da
> Árvore de Decisão, com a introdução precoce de um nó folha em arestas
> com baixa importância estatística, por ex..
> 
> A Árvore de Decisão da Figura 3.10 poderia ter algumas de suas arestas
> removidas sem comprometer seriamente a taxa de erros na classificação.
> De fato, observando-se a Tabela 3.4, verifica-se que dos sete Exemplos
> que apresentam "Umidade=Normal", seis deles têm rótulo de classe "Sim".
> Por esta razão, o nó interno à direita da Figura 3.10, (reproduzida na
> Figura 3.12(a)), representando o atributo "Vento", poderia ser eliminado
> e substituído por um nó folha "Sim" já que a maioria dos Exemplos que
> chegam a este nó apresentam o rótulo de classe "Sim". A seguir, o nó
> interno "Dia" também pode ser eliminado pois todas seus nós terminais
> passaram a ser do tipo "Sim". A Figura 3.12 mostra o resultado desse
> processo de Poda.
> 
> Para avaliar quantitativamente o desempenho de um modelo gerado, seja
> ele uma Árvore de Decisão ou um conjunto de Regras de Classificação,
> veremos que há técnicas e medidas de desempenho especialmente
> desenvolvidas para este fim.
1482c2471,2472
< Figura . -- Árvore de Decisão Não-Compacta (a) Antes e (b) Depois da Poda.
---
> Figura . -- Árvore de Decisão Não-Compacta (a) antes e (b) depois da
> Poda.
1487,1499c2477,2507
< Ao se gerar uma Árvore de Decisão o que se espera é que ela classifique corretamente Exemplos desconhecidos, mas na prática às vezes verifica-se a ocorrência de classificações equivocadas. Isso também ocorre com o diagnóstico de profissionais especializados. Quando um especialista deseja detectar a presença ou não de uma doença, ele solicita exames laboratoriais para auxiliá-lo a formular um diagnóstico positivo ou negativo sobre esta provável doença.
< 
< Se as respostas possíveis para um diagnóstico forem "Positivo" e "Negativo", quatro combinações de resultados previstos e resultados reais podem ocorrer:
< 
< 1.  Se o paciente for portador da doença e o médico acertar no diagnóstico, dizemos que este caso é um **Verdadeiro Positivo** ou **VP**;
< 
< 2.  Se o paciente não for portador da doença e o médico acertar no diagnóstico, dizemos que este caso é um **Verdadeiro Negativo** ou **VN**;
< 
< 3.  Se o paciente for portador da doença, e o médico errar no diagnóstico afirmando que ele está são, dizemos que este caso é um **Falso Negativo** ou **FN**;
< 
< 4.  Se o paciente não for portador da doença, e o médico errar no diagnóstico dizendo que ele está doente, dizemos que este caso é um **Falso Positivo** ou **FP**.
< 
< Essas quatro combinações de resultados costumam ser representadas por uma matriz que recebe o nome de "Matriz de Confusão", como mostra a Tabela 3.17.
---
> Ao se gerar uma Árvore de Decisão o que se espera é que ela classifique
> corretamente Exemplos desconhecidos, mas na prática às vezes verifica-se
> a ocorrência de classificações equivocadas. Isso também ocorre com o
> diagnóstico de profissionais. Quando um especialista deseja detectar a
> presença ou não de uma doença, ele solicita exames laboratoriais para
> auxiliá-lo a formular um diagnóstico positivo ou negativo sobre esta
> provável doença.
> 
> Se as respostas possíveis para um diagnóstico forem "Positivo" e
> "Negativo", quatro combinações de resultados previstos e resultados
> reais podem ocorrer:
> 
> 1.  Se o paciente for portador da doença e o médico acertar no
>     > diagnóstico, dizemos que este caso é um **Verdadeiro Positivo** ou
>     > **VP**;
> 
> 2.  Se o paciente não for portador da doença e o médico acertar no
>     > diagnóstico, dizemos que este caso é um **Verdadeiro Negativo** ou
>     > **VN**;
> 
> 3.  Se o paciente for portador da doença, e o médico errar no
>     > diagnóstico afirmando que ele está são, dizemos que este caso é um
>     > **Falso Negativo** ou **FN**;
> 
> 4.  Se o paciente não for portador da doença, e o médico errar no
>     > diagnóstico dizendo que ele está doente, dizemos que este caso é
>     > um **Falso Positivo** ou **FP**.
> 
> Essas quatro combinações de resultados costumam ser representadas por
> uma matriz que recebe o nome de "Matriz de Confusão", como mostra a
> Tabela 3.17.
1508,1510c2516,2527
< Os valores contidos numa Matriz de Confusão podem ser utilizados para avaliar o desempenho de uma Árvore de Decisão. O que se espera nos resultados é que os casos positivos sejam classificados como positivos e os negativos como negativos, ou seja, o desejável é que as taxas de sucesso para Verdadeiro Positivo e Verdadeiro Negativo sejam altas, e que as taxas de Falso Positivo e Falso Negativo sejam baixas.
< 
< Fazendo uma relação entre os Exemplos corretamente classificados, i.e., Verdadeiro Positivo (VP) mais Verdadeiro Negativo (VN), com o número total de classificações (VP+VN+FP+FN), podemos definir uma métrica de desempenho para a taxa de acertos ou sucesso, conhecida como Precisão ou Acurácia de uma Árvore de Decisão. Portanto,
---
> Os valores contidos numa Matriz de Confusão podem ser utilizados para
> avaliar o desempenho de uma Árvore de Decisão. O que se espera nos
> resultados é que os casos positivos sejam classificados como positivos e
> os negativos como negativos, ou seja, o desejável é que as taxas de
> sucesso para Verdadeiro Positivo e Verdadeiro Negativo sejam altas, e
> que as taxas de Falso Positivo e Falso Negativo sejam baixas.
> 
> Fazendo uma relação entre os Exemplos corretamente classificados, i.e.,
> Verdadeiro Positivo (VP) mais Verdadeiro Negativo (VN), com o número
> total de classificações (VP+VN+FP+FN), podemos definir uma métrica de
> desempenho para a taxa de acertos ou sucesso, conhecida como Precisão ou
> Acurácia de uma Árvore de Decisão. Portanto,
1517c2534,2545
< A ferramenta Weka (Weka, 2013) permite gerar Árvores de Decisão de forma automática ou interativa. Vamos mostrar a geração automática a partir de um arquivo de entrada.
---
> A ferramenta Weka (Weka, 2013) permite gerar Árvores de Decisão de forma
> automática ou interativa. Vamos mostrar a geração automática a partir de
> um arquivo de entrada.
> 
> **Passo 1** - Uma forma rápida de criar o arquivo de entrada tipo
> ".arff" a partir de uma planilha de dados ".xls" (Figura 1.1(a)) é
> salvá-la no formato ".csv" (Figura 3.13(b)), depois abrir este arquivo
> num editor de texto, acrescentar algumas palavras-chave e salvar
> novamente (Figura 3.14(a)). Saia do editor de texto e mude manualmente a
> extensão do arquivo de ".csv" para ".arff" (Figura 3.14(b)). Note que as
> Figura 3.14(a) e (b) são idênticas, mas a extensão dos arquivos é
> diferente.
1519c2547
< **Passo 1** - Uma forma rápida de criar o arquivo de entrada tipo ".arff" a partir de uma planilha de dados ".xls" (Figura 1.1(a)) é salvá-la no formato ".csv" (Figura 3.13(b)), depois abrir este arquivo num editor de texto, acrescentar algumas palavras-chave e salvar novamente (Figura 3.14(a)). Saia do editor de texto e mude manualmente a extensão do arquivo de ".csv" para ".arff" (Figura 3.14(b)). Note que as Figura 3.14(a) e (b) são idênticas, mas a extensão dos arquivos é diferente.
---
> ![](media/image28.png){width="2.6222222222222222in" height="3.36875in"}
1521,1523c2549,2550
< ![](./media/image28.png){width="2.6222222222222222in" height="3.36875in"}
< 
< ![](./media/image29.png){width="2.6666666666666665in" height="3.3481146106736657in"}
---
> ![](media/image29.png){width="2.6666666666666665in"
> height="3.3481146106736657in"}
1527c2554
< Figura . -- Tabela do Tempo (a) Formato ".xls" e (b) Formato ".csv".
---
> Figura . -- Tabela do Tempo (a) formato ".xls" e (b) formato ".csv".
1529c2556,2561
< Na unidade anterior, sobre como gerar Regras de Associação no Weka, foi explicado que o Weka aceita trabalhar diretamente o formato ".csv", sem a necessidade de acrescentar palavras-chaves. Mas, em alguns casos a criação do arquivo ".arff" se justifica. Em caso de dúvida sobre esta questão, consulte o ![](./media/image30.png){width="2.6222222222222222in" height="3.658333333333333in"}material da unidade anterior.
---
> Na unidade anterior, sobre como gerar Regras de Associação no Weka, foi
> explicado que o Weka aceita trabalhar diretamente o formato ".csv", sem
> a necessidade de acrescentar palavras-chaves. Mas, em alguns casos a
> criação do arquivo ".arff" se justifica. Em caso de dúvida sobre esta
> questão, consulte o ![](media/image30.png){width="2.6222222222222222in"
> height="3.658333333333333in"}material da unidade anterior.
1531c2563,2564
< ![](./media/image31.png){width="2.6664413823272093in" height="3.651686351706037in"}
---
> ![](media/image31.png){width="2.6664413823272093in"
> height="3.651686351706037in"}
1535c2568,2569
< Figura . -- Arquivo Tabela_do_Tempo (a) ".csv" com Palavras-Chave, e (b) Arquivo ".arff".
---
> Figura . -- Arquivo Tabela_do_Tempo (a) ".csv" com Palavras-Chave, e (b)
> Arquivo ".arff".
1540,1546c2574,2589
< **Passo 2** - Dando dois cliques sobre o ícone do arquivo "Tabela_do_Tempo.arff" ele se abrirá dentro do Weka, mostrando uma figura semelhante à Figura 3.15. Alternativamente, é possível primeiramente abrir o Weka Explorer, depois "Open file\..." e localizar o arquivo "Tabela_do_Tempo.arff".
< 
< ![](./media/image32.png){width="4.838462379702537in" height="3.636294838145232in"}
< 
< Figura . -- Arquivo "Tabela_do_Tempo.arff" Aberto no Weka.
< 
< Note que na seção "Attributes" aparecem os cinco atributos da Tabela do Tempo na ordem em que foram declarados. Na Figura 3.15 aparecem ainda os detalhes da composição de um dos atributos selecionados, neste caso "Dia", mas qualquer um dos quatro atributos restantes pode ser selecionado.
---
> **Passo 2** - Dando dois cliques sobre o ícone do arquivo
> "Tabela_do_Tempo.arff" ele se abrirá dentro do Weka, mostrando uma
> figura semelhante à Figura 3.15. Alternativamente, é possível
> primeiramente abrir o Weka Explorer, depois "Open file\..." e localizar
> o arquivo "Tabela_do_Tempo.arff".
> 
> ![](media/image32.png){width="4.838462379702537in"
> height="3.636294838145232in"}
> 
> Figura . -- Arquivo "Tabela_do_Tempo.arff" aberto no Weka.
> 
> Note que na seção "Attributes" aparecem os cinco atributos da Tabela do
> Tempo na ordem em que foram declarados. Na Figura 3.15 aparecem ainda os
> detalhes da composição de um dos atributos selecionados, neste caso
> "Dia", mas qualquer um dos quatro atributos restantes pode ser
> selecionado.
1551,1553c2594,2604
< **Passo 3** -- Com o arquivo "Tabela_do_Tempo.arff" aberto, clique na aba "Classify", localizada da parte superior esquerda da janela do Weka Explorer. A seguir, clique em "Choose" para escolher o algoritmo de classificação. Primeiro clique em "trees", depois em "J48" (Figura 3.16 ). O algoritmo "J48" é uma implementação mais recente do "ID3" e, além disso, tem também a vantagem de permitir, dentro do Weka, visualizar a Árvore de Decisão construída.
< 
< ![](./media/image33.png){width="1.4354166666666666in" height="2.654861111111111in"}![](./media/image34.png){width="3.56875in" height="2.678472222222222in"}
---
> **Passo 3** -- Com o arquivo "Tabela_do_Tempo.arff" aberto, clique na
> aba "Classify", localizada da parte superior esquerda da janela do Weka
> Explorer. A seguir, clique em "Choose" para escolher o algoritmo de
> classificação. Primeiro clique em "trees", depois em "J48" (Figura 3.16
> ). O algoritmo "J48" é uma implementação mais recente do "ID3" e, além
> disso, tem também a vantagem de permitir, dentro do Weka, visualizar a
> Árvore de Decisão construída.
> 
> ![](media/image33.png){width="1.4354166666666666in"
> height="2.654861111111111in"}![](media/image34.png){width="3.56875in"
> height="2.678472222222222in"}
1557c2608,2609
< Figura . -- Aba "Classify" com a Opcão (a) "Choose" para Escolher (b) o Menu de Algoritmos.
---
> Figura . -- Aba "Classify" com a Opcão (a) "Choose" para escolher (b) o
> menu de algoritmos.
1559c2611,2614
< Uma vez escolhido o algoritmo "J48" é possível conferir e alterar alguns parâmetros. Clicando com o botão esquerdo do mouse sobre "J48" abre-se um menu com todos os valores *default*. Inicialmente vamos trabalhar com estes valores.
---
> Uma vez escolhido o algoritmo "J48" é possível conferir e alterar alguns
> parâmetros. Clicando com o botão esquerdo do mouse sobre "J48" abre-se
> um menu com todos os valores *default*. Inicialmente vamos trabalhar com
> estes valores.
1564c2619,2627
< **Passo 4** -- Ainda dentro da aba "Classify", em "Test options" escolha "Use training set" e clique no botão "Start", um pouco abaixo. A opção "Use training set" significa que o mesmo **Conjunto de Treinamento** usado para gerar a Árvore de Decisão será usado para testar os resultados (veja Figura 3.17). Se o Conjunto de Exemplos da Base de Dados não for inconsistente, geralmente a taxa de acerto com esta opção deve ser de 100%. Mais adiante, na próxima unidade de estudo, veremos que há outras formas mais interessantes de testar a robustez e a qualidade do Modelo gerado.
---
> **Passo 4** -- Ainda dentro da aba "Classify", em "Test options" escolha
> "Use training set" e clique no botão "Start", um pouco abaixo. A opção
> "Use training set" significa que o mesmo **Conjunto de Treinamento**
> usado para gerar a Árvore de Decisão será usado para testar os
> resultados (veja Figura 3.17). Se o Conjunto de Exemplos da Base de
> Dados não for inconsistente, geralmente a taxa de acerto com esta opção
> deve ser de 100%. Mais adiante, na próxima unidade de estudo, veremos
> que há outras formas mais interessantes de testar a robustez e a
> qualidade do Modelo gerado.
1566c2629,2630
< ![](./media/image35.png){width="4.429861111111111in" height="3.3381944444444445in"}
---
> ![](media/image35.png){width="4.429861111111111in"
> height="3.3381944444444445in"}
1573,1579c2637,2653
< **Passo 5** -- Ao disparar o processo de treinamento com o algoritmo "J48" aparecem na região direita da tela ("Classifier output") os resultados desejados (Figura 3.18). A Árvore de Decisão aparece na forma textual, mas pode ser vista na forma gráfica. Na parte inferior da tela, aparecem o número e a porcentagem de exemplos classificados corretamente, a Acurácia (ou Precisão) por Classe e a Matriz de Confusão.
< 
< ![](./media/image36.png){width="4.5159722222222225in" height="3.4090277777777778in"}
< 
< Figura . -- Resultado do Processo de Treinamento e Indução da Árvore de Decisão.
< 
< Se você tiver interesse em saber como cada uma dos exemplos foi classificado, clique na aba "More options\..." e depois habilite "Output predictions". Clique em "Start" novamente.
---
> **Passo 5** -- Ao disparar o processo de treinamento com o algoritmo
> "J48" aparecem na região direita da tela ("Classifier output") os
> resultados desejados (Figura 3.18). A Árvore de Decisão aparece na forma
> textual, mas pode ser vista na forma gráfica. Na parte inferior da tela,
> aparecem o número e a porcentagem de exemplos classificados
> corretamente, a Acurácia (ou Precisão) por Classe e a Matriz de
> Confusão.
> 
> ![](media/image36.png){width="4.5159722222222225in"
> height="3.4090277777777778in"}
> 
> Figura . -- Resultado do Processo de Treinamento e Indução da Árvore de
> Decisão.
> 
> Se você tiver interesse em saber como cada uma dos exemplos foi
> classificado, clique na aba "More options\..." e depois habilite "Output
> predictions". Clique em "Start" novamente.
1584c2658,2661
< **Passo 6** -- Clicando com o botão direito do mouse na região inferior esquerda, onde se lê "Result list (right-click for options)", mais precisamente sobre a faixa azul "trees.J48", é possível visualizar graficamente o resultado, escolhendo "Visualize tree" (Figura 3.19).
---
> **Passo 6** -- Clicando com o botão direito do mouse na região inferior
> esquerda, onde se lê "Result list (right-click for options)", mais
> precisamente sobre a faixa azul "trees.J48", é possível visualizar
> graficamente o resultado, escolhendo "Visualize tree" (Figura 3.19).
1586c2663
< ![](./media/image37.png){width="5.420138888888889in" height="4.375in"}
---
> ![](media/image37.png){width="5.420138888888889in" height="4.375in"}
1590,1592c2667,2675
< Os números entre parênteses em cada nó folha da Figura 3.19 indicam quantos exemplos chegaram até esta folha. Somando-se estes números, verifica-se que 14 exemplos foram testados nesta simulação.
< 
< **Passo 7** -- Se você quiser saber exatamente quais Exemplos foram classificados em quais classes, primeiramente abra o arquivo "Tabela_do_Tempo.arff" no editor do Weka, que pode ser acessado pelo seguinte caminho: interface "Weka GUI Chooser", depois "Tools", e depois "ArffViewer" (Figura 3.20).
---
> Os números entre parênteses em cada nó folha da Figura 3.19 indicam
> quantos exemplos chegaram até esta folha. Somando-se estes números,
> verifica-se que 14 exemplos foram testados nesta simulação.
> 
> **Passo 7** -- Se você quiser saber exatamente quais Exemplos foram
> classificados em quais classes, primeiramente abra o arquivo
> "Tabela_do_Tempo.arff" no editor do Weka, que pode ser acessado pelo
> seguinte caminho: interface "Weka GUI Chooser", depois "Tools", e depois
> "ArffViewer" (Figura 3.20).
1594c2677
< ![](./media/image38.png){width="1.975in" height="1.1819444444444445in"}
---
> ![](media/image38.png){width="1.975in" height="1.1819444444444445in"}
1598c2681,2687
< Quando a janela "ARFF-Viewer" se abrir, localize o arquivo "Tabela_do_Tempo.arff" clicando primeiramente em "File" e depois em "Open\...".
---
> Quando a janela "ARFF-Viewer" se abrir, localize o arquivo
> "Tabela_do_Tempo.arff" clicando primeiramente em "File" e depois em
> "Open\...".
> 
> Com o editor do Weka aberto, clique no atributo "Umidade", ou qualquer
> outro atributo, para ordenar os Exemplos de acordo com os valores que
> este atributo pode assumir.
1600,1602c2689,2690
< Com o editor do Weka aberto, clique no atributo "Umidade", ou qualquer outro atributo, para ordenar os Exemplos de acordo com os valores que este atributo pode assumir.
< 
< ![](./media/image39.png){width="2.602777777777778in" height="2.4756944444444446in"}
---
> ![](media/image39.png){width="2.602777777777778in"
> height="2.4756944444444446in"}
1606c2694,2695
< Note que com este editor, é possível alterar os valores dos atributos, clicando sobre o campo a ser alterado.
---
> Note que com este editor, é possível alterar os valores dos atributos,
> clicando sobre o campo a ser alterado.
1608c2697,2698
< Obs.: O editor do Weka também pode ser acessado no "Weka Explorer", escolhendo a aba "Preprocess" e depois "Edit\...".**\
---
> Obs.: O editor do Weka também pode ser acessado no "Weka Explorer",
> escolhendo a aba "Preprocess" e depois "Edit\...".**\
1611,1617c2701,2721
< **Passo 8** -- Para testar novos Exemplos no Classificador sem sair da interface "Weka Explorer", há a opção "Supplied test set". Vamos supor que os quatro novos Exemplos da Tabela 3.16 de nosso material de Teoria devam ser testados no "Weka Explorer".
< 
< Primeiramente crie um arquivo ".arff" com os quatro Exemplos extras da Tabela 3.16 (basta abrir o arquivo "Tabela_do_Tempo.arff" no editor do Weka, fazer as modificações e salvar com um novo nome, digamos "Teste.arff").
< 
< Carregue no "Weka Explorer" o **Conjunto de Treinamento** "Tabela_do_Tempo.arff" da forma usual, i.e., clicando no "Preprocess" da barra superior e depois em "Open file\...". A seguir clique em "Classify", escolha em "Choose" o algoritmo desejado, digamos "J48", e em "Test options" escolha "Supplied test set". Pressionando a tecla "Set", aparece a opção "Open file\..." com a qual é possível carregar o **Conjunto de Teste** "Teste.arff".
< 
< Em "More options" habilite a opção "Output predictions" e dispare o programa com a opção "Start". Na seção "Classifier output", devem aparecer as quatro predições buscadas.
---
> **Passo 8** -- Para testar novos Exemplos no Classificador sem sair da
> interface "Weka Explorer", há a opção "Supplied test set". Vamos supor
> que os quatro novos Exemplos da Tabela 3.16 de nosso material de Teoria
> devam ser testados no "Weka Explorer".
> 
> Primeiramente crie um arquivo ".arff" com os quatro Exemplos extras da
> Tabela 3.16 (basta abrir o arquivo "Tabela_do_Tempo.arff" no editor do
> Weka, fazer as modificações e salvar com um novo nome, digamos
> "Teste.arff").
> 
> Carregue no "Weka Explorer" o **Conjunto de Treinamento**
> "Tabela_do_Tempo.arff" da forma usual, i.e., clicando no "Preprocess" da
> barra superior e depois em "Open file\...". A seguir clique em
> "Classify", escolha em "Choose" o algoritmo desejado, digamos "J48", e
> em "Test options" escolha "Supplied test set". Pressionando a tecla
> "Set", aparece a opção "Open file\..." com a qual é possível carregar o
> **Conjunto de Teste** "Teste.arff".
> 
> Em "More options" habilite a opção "Output predictions" e dispare o
> programa com a opção "Start". Na seção "Classifier output", devem
> aparecer as quatro predições buscadas.
1622,1626c2726,2757
< A geração de Árvores de Decisão normalmente é comparativamente mais rápida que outros métodos de classificação. Árvores de Decisão pequenas são fáceis de entender e Árvores grandes podem ser convertidas em Regras de Classificação. Geralmente a taxa de acerto de classificação de Exemplos de Teste, ou seja, a Acurácia das Árvores de Decisão, é compatível com outros métodos equivalentes, ou um pouco abaixo de métodos mais complexos. Porém, em Aprendizado de Máquina raramente se encontra um método com desempenho superior que seus pares para qualquer conjunto de dados.
< 
< Não foram estudados aqui casos reais de inconsistências, ausência de dados ou exceções na Base de Dados, para citar apenas alguns dos possíveis problemas. Suponha que durante a indução da Árvore de Decisão dois Exemplos ligeiramente distintos, mas que percorrem o mesmo caminho, pertençam a classes distintas! Neste caso, verifica-se que há inconsistência nos dados e uma análise pontual deverá determinar e eliminar o problema. Considere casos reais de Exemplos ausentes representados por caminhos logicamente possíveis, como um dos valores possíveis que determinado atributo pode assumir, mas que não estão presentes na Base de Dados. Que classe atribuir a estes casos? Algum critério deverá ser adotado para estes casos, como o de atribuir o valor da classe estatisticamente predominante no conjunto de Exemplos.
< 
< Além dessas situações, há os casos de dados espúrios causados por coleta equivocada, mas com valores lógicos perfeitamente dentro das possibilidades aceitas para cada atributo, e que não terão sido detectados na fase inicial de limpeza de dados porque a natureza desses problemas é de incompatibilidade com o modelo gerado ou o conceito aprendido. O tratamento de problemas desta natureza foge ao escopo desta primeira abordagem à geração ou indução de Árvores de Decisão, mas tais problemas podem ser estudados na referência bibliográfica fornecida na parte final deste material.
---
> A geração de Árvores de Decisão normalmente é comparativamente mais
> rápida que outros métodos de classificação. Árvores de Decisão pequenas
> são fáceis de entender e Árvores grandes podem ser convertidas em Regras
> de Classificação. Geralmente a taxa de acerto de classificação de
> Exemplos de Teste, ou seja, a Acurácia das Árvores de Decisão, é
> compatível com outros métodos equivalentes, ou um pouco abaixo de
> métodos mais complexos. Porém, em Aprendizado de Máquina raramente se
> encontra um método com desempenho superior que seus pares para qualquer
> conjunto de dados.
> 
> Não foram estudados aqui casos reais de inconsistências, ausência de
> dados ou exceções na Base de Dados, para citar apenas alguns dos
> possíveis problemas. Suponha que durante a indução da Árvore de Decisão
> dois Exemplos ligeiramente distintos, mas que percorrem o mesmo caminho,
> pertençam a classes distintas! Neste caso, verifica-se que há
> inconsistência nos dados e uma análise pontual deverá determinar e
> eliminar o problema. Considere casos reais de Exemplos ausentes
> representados por caminhos logicamente possíveis, como um dos valores
> possíveis que determinado atributo pode assumir, mas que não estão
> presentes na Base de Dados. Que classe atribuir a estes casos? Algum
> critério deverá ser adotado para estes casos, como o de atribuir o valor
> da classe estatisticamente predominante no conjunto de Exemplos.
> 
> Além dessas situações, há os casos de dados espúrios causados por coleta
> equivocada, mas com valores lógicos perfeitamente dentro das
> possibilidades aceitas para cada atributo, e que não terão sido
> detectados na fase inicial de limpeza de dados porque a natureza desses
> problemas é de incompatibilidade com o modelo gerado ou o conceito
> aprendido. O tratamento de problemas desta natureza foge ao escopo desta
> primeira abordagem à geração ou indução de Árvores de Decisão, mas tais
> problemas podem ser estudados na referência bibliográfica fornecida na
> parte final deste material.
1631c2762,2763
< 1\. Explique **com suas próprias palavras** a seguinte afirmação: numa **Árvore de Decisão**, os nós testam **Atributos** (WITTEN & FRANK, 2005).
---
> 1\. (20%) Explique **com suas próprias palavras** a seguinte afirmação:
> numa **Árvore de Decisão**, os nós testam **Atributos**.
1633c2765,2766
< 2\. Explique **com suas próprias palavras**, o que é "superajuste" ou "*overfitting*", seus efeitos e dê um exemplo.
---
> 2\. (30%) Explique **com suas próprias palavras**, o que é "superajuste"
> ou "*overfitting*", seus efeitos e dê um exemplo.
1635,1639c2768,2784
< 3\. Carregue o arquivo "iris.arff" no Weka e elimine os atributos "sepalwidth" (largura da sépala) e "sepallength" (comprimento da sépala). Para fazer esta operação, basta selecionar estes dois atributos no "Weka Explorer" e depois clicar em "Remove". Devem sobrar apenas três atributos: "petallength" (comprimento da pétala), "petalwidth" (largura da pétala) e "class" (classe), com 150 Exemplos, divididos entre "Iris-setosa", "Iris-versicolor" e "Iris-virginica".
< 
< \(a\) Gere a Árvore de Decisão com o algoritmo "J4.8", analise a representação gráfica da árvore e explique por que esta Árvore de Decisão deve cometer menos erros de classificação que a Árvore de Decisão da Figura 3.2 de nosso material didático.
< 
< \(b\) No "Weka Explorer", vá em "Visualize", ajuste "PlotSize" e "PointSize", clique em "Update" e escolha a representação com os atributos "petalwidth" e "petallength". Analise esta figura (que deve se parecer à Figura 3.1 de nosso material didático).
---
> 3\. Carregue o arquivo "iris.arff" (anexo) no Weka e elimine os
> atributos "sepalwidth" (largura da sépala) e "sepallength" (comprimento
> da sépala). Para fazer esta operação, basta selecionar estes dois
> atributos no "Weka Explorer" e depois clicar em "Remove". Devem sobrar
> apenas três atributos: "petallength" (comprimento da pétala),
> "petalwidth" (largura da pétala) e "class" (classe), com 150 Exemplos,
> divididos entre "Iris-setosa", "Iris-versicolor" e "Iris-virginica".
> 
> \(a\) (30%) -- Gere a Árvore de Decisão com o algoritmo "J4.8", anexe a
> representação gráfica da árvore e explique por que esta Árvore de
> Decisão deve cometer menos erros de classificação que a Árvore de
> Decisão da Figura 3.2, de nosso material didático.
> 
> \(b\) (20%) -- No "Weka Explorer", vá em "Visualize", ajuste "PlotSize"
> e "PointSize", clique em "Update" e escolha a representação com os
> atributos "petalwidth" e "petallength". Anexe esta figura (que deve se
> parecer à Figura 3.1 de nosso material didático).
1644c2789,2792
< FISHER, R. A. **The Use of Multiple Measurements in Taxonomic Problems**. Annals of Eugenics, Vol. 7, Issue 2, pages 179-188, 1936. In http://onlinelibrary.wiley.com/doi/10.1111/j.1469-1809.1936.tb02137.x/abstract. Acessado em 20.02.2013.
---
> FISHER, R. A. **The Use of Multiple Measurements in Taxonomic
> Problems**. Annals of Eugenics, Vol. 7, Issue 2, pages 179-188, 1936. In
> http://onlinelibrary.wiley.com/doi/10.1111/j.1469-1809.1936.tb02137.x/abstract.
> Acessado em 20.02.2013.
1646c2794,2795
< HAN, J. & KAMBER, M. **Data Mining: Concepts and Techniques.** San Francisco: Morgan Kaufmann Publishers, 2008.
---
> HAN, J. & KAMBER, M. **Data Mining: Concepts and Techniques.** San
> Francisco: Morgan Kaufmann Publishers, 2008.
1648c2797,2799
< PINHEIRO, C. A. R. **Inteligência Analítica: Mineração de Dados e Descoberta de Conhecimento.** Rio de Janeiro: Editora Ciência Moderna Ltda., 2008.
---
> PINHEIRO, C. A. R. **Inteligência Analítica: Mineração de Dados e
> Descoberta de Conhecimento.** Rio de Janeiro: Editora Ciência Moderna
> Ltda., 2008.
1650c2801,2802
< QUINLAN, J. R. **Induction of Decision Trees**. Machine Learning, Vol. 1, No. 1, pp. 81-106. Boston: Kluwer Academic Publishers, 1986.
---
> QUINLAN, J. R. **Induction of Decision Trees**. Machine Learning, Vol.
> 1, No. 1, pp. 81-106. Boston: Kluwer Academic Publishers, 1986.
1652c2804,2805
< REZENDE, S. O. (Organizadora). **Sistemas Inteligentes: Fundamentos e Aplicações.** Barueri: Editora Manole Ltda., 2005.
---
> REZENDE, S. O. (Organizadora). **Sistemas Inteligentes: Fundamentos e
> Aplicações.** Barueri: Editora Manole Ltda., 2005.
1654c2807,2809
< ROCHA, M.; CORTEZ, P. & NEVES, J. M. **Análise Inteligente de Dados: Algoritmos e Implementação em Java.** Lisboa: Editora de Informática, 2008.
---
> ROCHA, M.; CORTEZ, P. & NEVES, J. M. **Análise Inteligente de Dados:
> Algoritmos e Implementação em Java.** Lisboa: Editora de Informática,
> 2008.
1656c2811,2813
< TAN, P.N.; STEINBACH, M. & KUMAR, V. **Introdução ao Data Mining Mineração de Dados.** Rio de Janeiro: Editora Ciência Moderna Ltda., 2009.
---
> TAN, P.N.; STEINBACH, M. & KUMAR, V. **Introdução ao Data Mining
> Mineração de Dados.** Rio de Janeiro: Editora Ciência Moderna Ltda.,
> 2009.
1658c2815,2817
< WITTEN, I. H. & FRANK, E. **Data Mining: Practical Machine Learning Tools and Techniques.** Second Edition. Amsterdam: Morgan Kaufmann Publishers, 2005.
---
> WITTEN, I. H. & FRANK, E. **Data Mining: Practical Machine Learning
> Tools and Techniques.** Second Edition. Amsterdam: Morgan Kaufmann
> Publishers, 2005.
1660c2819,2820
< Weka. The Waikato University. In http://www.cs.waikato.ac.nz/ml/weka. Acessado em 03.03.13.
---
> Weka. The Waikato University. In <http://www.cs.waikato.ac.nz/ml/weka/>
> . Acessado em 03.03.13.
1662,1663c2822,2823
< 4.  Classificação e Regras de Classificação
<     =======================================
---
>  Classificação e Regras de Classificação
> =======================================
1665,1666c2825,2826
<     1.  Introdução
<         ----------
---
> Introdução
> ----------
1668c2828,2832
< No contexto de Aprendizado de Máquina, a Classificação pressupõe que um Modelo tenha sido gerado ou induzido a partir de Exemplos de Treinamento. Com este Modelo, novos Exemplos de Teste podem ser classificados. A Figura 4.1 ilustra as três fases desse processo: **Treinamento**, **Aprendizado** e **Classificação**.
---
> No contexto de Aprendizado de Máquina, a Classificação pressupõe que um
> Modelo tenha sido gerado ou induzido a partir de Exemplos de
> Treinamento. Com este Modelo, novos Exemplos de Teste podem ser
> classificados. A Figura 4.1 ilustra as três fases desse processo:
> **Treinamento**, **Aprendizado** e **Classificação**.
1670c2834,2835
< Figura . -- Treinamento, Aprendizado e Classificação em um Sistema Inteligente Simples.
---
> Figura . -- Treinamento, Aprendizado e Classificação em um Sistema
> Inteligente Simples.
1672c2837,2839
< Há várias maneiras de representar o conhecimento embutido num Modelo, sendo as mais comuns Árvores de Decisão e **Regras de Classificação**. As Regras de Classificação assumem a forma genérica:
---
> Há várias maneiras de representar o conhecimento embutido num Modelo,
> sendo as mais comuns Árvores de Decisão e **Regras de Classificação**.
> As Regras de Classificação assumem a forma genérica:
1676,1678c2843,2850
< sendo "Valor" um resultado discreto, como sim/não, baixo/médio/alto verdadeiro/falso etc. Quando os resultados esperados não pertencem a classes discretas, ou seja, quando "Valor" for uma variável real, a classificação recebe o nome de **Regressão**.
< 
< A Classificação através de Regras de Classificação e o processo de geração automática de Regras de Classificação serão os temas desta unidade.
---
> sendo "Valor" um resultado discreto, como sim/não, baixo/médio/alto
> verdadeiro/falso etc. Quando os resultados esperados não pertencem a
> classes discretas, ou seja, quando "Valor" for uma variável real, a
> classificação recebe o nome de **Regressão**.
> 
> A Classificação através de Regras de Classificação, e o processo de
> geração automática de Regras de Classificação serão os temas desta
> unidade.
1683,1689c2855,2883
< O **Aprendizado Supervisionado** se dá através de um **Algoritmo de Aprendizado**, cuja função é criar uma representação do conhecimento extraído de um conjunto de **Exemplos de Treinamento**. Há várias formas possíveis de representação, mas a que nos interessa aqui são as **Regras de Classificação**.
< 
< Os Exemplos de Treinamento, por sua vez, são uma forma conveniente de estruturar os dados de uma empresa ou de um certo domínio do saber. Todos os Exemplos de Treinamento têm o mesmo número de atributos, sendo a diferença entre eles representada pelos valores que cada atributo assume.
< 
< O algoritmo de aprendizado recebe este nome porque ele cria um modelo cuja aplicação específica não foi pensada pelo seu projetista. Ou seja, ele demonstra certa capacidade de adaptação que melhora seu desempenho depois de uma fase de treinamento. Alguns algoritmos de aprendizado demonstram a capacidade de aprendizado incremental e podem ir melhorando seu desempenho com o acúmulo de experiência. Esta capacidade é muito apreciada porque concede certa **autonomia** aos **Sistemas Inteligentes**.
< 
< Uma equipe de físicos, engenheiros e cientistas da computação, responsáveis pelo lançamento de sondas espaciais, conseguiu recentemente desenvolver um algoritmo de aprendizado que permite a uma sonda espacial sair de sua trajetória para desviar-se de uma possível colisão com um meteorito ou cometa inesperado, e retornar à rota original. Alguns robôs atualmente conseguem, sem ajuda externa, voltar à posição vertical depois de uma queda acidental causada por irregularidade no terreno e continuar normalmente sua tarefa de rotina.
---
> O **Aprendizado Supervisionado** se dá através de um **Algoritmo de
> Aprendizado**, cuja função é criar uma representação do conhecimento
> extraído de um conjunto de **Exemplos de Treinamento**. Há várias formas
> possíveis de representação, mas a que nos interessa aqui são as **Regras
> de Classificação**.
> 
> Os Exemplos de Treinamento, por sua vez, são uma forma conveniente de
> estruturar os dados de uma empresa ou de um certo domínio do saber.
> Todos os Exemplos de Treinamento têm o mesmo número de atributos, sendo
> a diferença entre eles representada pelos valores que cada atributo
> assume.
> 
> O algoritmo de aprendizado recebe este nome porque ele cria um modelo
> cuja aplicação específica não foi pensada pelo seu projetista. Ou seja,
> ele demonstra certa capacidade de adaptação que melhora seu desempenho
> depois de uma fase de treinamento. Alguns algoritmos de aprendizado
> demonstram a capacidade de aprendizado incremental, e podem ir
> melhorando seu desempenho com o acúmulo de experiência. Esta capacidade
> é muito apreciada porque concede certa **autonomia** aos **Sistemas
> Inteligentes**.
> 
> Uma equipe de físicos, engenheiros e cientistas da computação,
> responsáveis pelo lançamento de sondas espaciais, conseguiu recentemente
> desenvolver um algoritmo de aprendizado que permite a uma sonda espacial
> sair de sua trajetória para desviar-se de uma possível colisão com um
> meteorito ou cometa inesperado, e retornar à rota original. Alguns robôs
> atualmente conseguem, sem ajuda externa, voltar à posição vertical
> depois de uma queda acidental causada por irregularidade no terreno e
> continuar normalmente sua tarefa de rotina.
1694,1696c2888,2902
< Um algoritmo de aprendizado pode variar desde aqueles que simplesmente escolhem um dos atributos do Conjunto de Treinamento como a resposta possível a um teste, caso do algoritmo ***oneR*** (uma Regra), passando por aqueles cuja resposta a um novo teste é uma combinação linear dos valores dos atributos, até a utilização de complicados modelos não-lineares, como as ***Redes Neurais***, ou o aprendizado estatístico das ***Máquinas de Vetor de Suporte***, ou ***Support Vector Machines***, **SVM**.
< 
< A finalidade desta unidade não é estudar detalhadamente algoritmos de aprendizado. Como há um grande número de ferramentas de acesso livre que implementam estes algoritmos, nosso objetivo é passar uma ideia geral do funcionamento desses algoritmos, cujo entendimento é indispensável para o ajuste adequado de seus parâmetros e para a correta interpretação de seus resultados.
---
> Um algoritmo de aprendizado pode variar desde aqueles que simplesmente
> escolhem um dos atributos do Conjunto de Treinamento como a resposta
> possível a um teste, caso do algoritmo ***oneR*** (uma Regra), passando
> por aqueles cuja resposta a um novo teste é uma combinação linear dos
> valores dos atributos, até a utilização de complicados modelos
> não-lineares, como as ***Redes Neurais***, ou o aprendizado estatístico
> das ***Máquinas de Vetor de Suporte***, ou ***Support Vector
> Machines***, ***SVM***.
> 
> A finalidade desta unidade não é estudar detalhadamente algoritmos de
> aprendizado. Como há um grande número de ferramentas de acesso livre que
> implementam estes algoritmos, nosso objetivo é passar uma ideia geral do
> funcionamento desses algoritmos, cujo entendimento é indispensável para
> o ajuste adequado de seus parâmetros e para a correta interpretação de
> seus resultados.
1701,1705c2907,2924
< É possivelmente o Algoritmo de Aprendizado para classificação mais simples e, no entanto, seu desempenho pode ser surpreendentemente bom, dependendo da Base de Dados (WITTEN & FRANK, 2005). Esse algoritmo aposta na hipótese de que basta consultar apenas um dos atributos para classificar corretamente os Exemplos de Teste. A tarefa então do algoritmo é encontrar durante o treinamento o atributo que apresenta a menor taxa de erros de classificação.
< 
< O algoritmo *oneR* tem bom desempenho para Bases de Dados em que um dos atributos é claramente mais importante que o restante, porque seus valores quase sempre darão uma pista de qual deve ser a classificação correta. Para Bases de Dados em que todos os atributos contribuem com igual peso na resposta, a taxa de acerto do algoritmo tende a ser inversamente proporcional ao número de atributos.
< 
< Para compreendermos como o *oneR* calcula a taxa de erros de cada atributo, vamos utilizar a clássica Tabela do Tempo, criada por (QUINLAN, 1986), e reproduzida na Tabela 4.1.
---
> É possivelmente o Algoritmo de Aprendizado para classificação mais
> simples e, no entanto, seu desempenho pode ser surpreendentemente bom,
> dependendo da Base de Dados (Witten & Frank, 2005). Esse algoritmo
> aposta na hipótese de que basta consultar apenas um dos atributos para
> classificar corretamente os Exemplos de Teste. A tarefa então do
> algoritmo é encontrar durante o treinamento o atributo que apresenta a
> menor taxa de erros de classificação.
> 
> O algoritmo *oneR* tem bom desempenho para Bases de Dados em que um dos
> atributos é claramente mais importante que o restante, porque seus
> valores quase sempre darão uma pista de qual deve ser a classificação
> correta. Para Bases de Dados em que todos os atributos contribuem com
> igual peso na resposta, a taxa de acerto do algoritmo tende a ser
> inversamente proporcional ao número de atributos.
> 
> Para compreendermos como o *oneR* calcula a taxa de erros de cada
> atributo, vamos utilizar a clássica Tabela do Tempo, criada por
> (Quinlan, 1986), e reproduzida na Tabela 4.1.
1726c2945,2947
< Primeiramente isolamos um dos atributos, digamos "Dia", e verificamos qual a distribuição das classes "Sim" e "Não" no atributo de saída "Partida".
---
> Primeiramente isolamos um dos atributos, digamos "Dia", e verificamos
> qual a distribuição das classes "Sim" e "Não" no atributo de saída
> "Partida".
1747c2968,2972
< Vamos considerar como "sucesso" a classe ("Sim" ou "Não") que aparecer com maior frequência, i.e., a maioria, para cada uma das opções possíveis ("Ensolarado", "Nublado", "Chuvoso") do atributo "Dia", e como "erro" a menos frequente. Então uma inspeção na Tabela 4.2 mostra a seguinte distribuição:
---
> Vamos considerar como "sucesso" a classe ("Sim" ou "Não") que aparecer
> com maior frequência, i.e., a maioria, para cada uma das opções
> possíveis ("Ensolarado", "Nublado", "Chuvoso") do atributo "Dia", e como
> "erro" a menos frequente. Então uma inspeção na Tabela 4.2 mostra a
> seguinte distribuição:
1758,1760c2983,2984
< Com base na Tabela 4.3 já podemos gerar algumas regras de classificação iniciais:
< 
< Dia(Ensolarado) → Partida=Não ou ***IF*** Dia**=**Ensolarado ***THEN*** Partida**=**Não (R 4.1)
---
> Com base na Tabela 4.3 já podemos gerar algumas regras de classificação
> iniciais:
1762c2986,2987
< Dia(Nublado) → Partida=Sim ou ***IF*** Dia**=**Nublado ***THEN*** Partida**=**Sim (R 4.2)
---
> Dia(Ensolarado) → Partida=Não ou ***IF*** Dia**=**Ensolarado ***THEN***
> Partida**=**Não (R 4.1)
1764c2989,2990
< Dia(Chuvoso) → Partida=Sim ou ***IF*** Dia**=**Chuvoso ***THEN*** Partida**=**Sim (R 4.3)
---
> Dia(Nublado) → Partida=Sim ou ***IF*** Dia**=**Nublado ***THEN***
> Partida**=**Sim (R 4.2)
1766c2992,3002
< Os resultados mostram que em dia ensolarado não há partidas, possivelmente por se tratar de um esporte em quadra coberta e talvez porque os participantes prefiram neste tipo de dia outra atividade a céu aberto. Convém ressaltar que este conjunto de regras baseadas unicamente no atributo "Dia" apresenta uma taxa de erros de 4 em 14, ou 4/14. Vamos reproduzir a tabela de (WITTEN & FRANK, 2005) que aplica o mesmo procedimento para os outros atributos e ver se algum deles apresenta uma taxa de erros menor.
---
> Dia(Chuvoso) → Partida=Sim ou ***IF*** Dia**=**Chuvoso ***THEN***
> Partida**=**Sim (R 4.3)
> 
> Os resultados mostram que em dia ensolarado não há partidas,
> possivelmente por se tratar de um esporte em quadra coberta e talvez
> porque os participantes prefiram neste tipo de dia outra atividade a céu
> aberto. Convém ressaltar que este conjunto de regras baseadas unicamente
> no atributo "Dia" apresenta uma taxa de erros de 4 em 14, ou 4/14. Vamos
> reproduzir a tabela de (Witten & Frank, 2005) que aplica o mesmo
> procedimento para os outros atributos e ver se algum deles apresenta uma
> taxa de erros menor.
1783,1799c3019,3075
< A Tabela 4.4 revela que os atributos "Dia" e "Umidade" apresentam as menores taxas de erros. Adotando qualquer critério arbitrário de desempate, vamos ficar com o conjunto de erros gerados pelo atributo "Umidade" e gerar as seguintes Regras de Classificação:
< 
< Umidade(Alta) → Partida=Não ou ***IF*** Umidade**=**Alta ***THEN*** Partida**=**Não (R 4.4)
< 
< Umidade(Normal) → Partida=Sim ou ***IF*** Umidade**=**Normal ***THEN*** Partida**=**Sim (R 4.5)
< 
< Portanto, quando o algoritmo **oneR** tiver que classificar um novo exemplo, somente o atributo "Umidade" será considerado, e o resultado será baseado nas Regras de Classificação "R 4.4" e "R 4.5". Isso significa que se os Exemplos de Treinamento forem usados como Exemplos de Teste, e supondo que entre os 14 Exemplos de Treinamento não haja contradição entre si, o algoritmo **oneR** deve acertar 10 vezes e errar 4.
< 
< Mas, e se o Conjunto de Teste for diferente do Conjunto de Treinamento? Não será a estimativa de 10 acertos e 4 erros demasiadamente otimista ou ela se confirmará com os novos dados? E se o número de Exemplos de Treinamento tivesse sido 140, em vez de 14, que implicações isso teria nas estimativas de acertos?
< 
< Há outros algoritmos de classificação bem mais refinados que o **oneR** e que, na maioria dos casos, produzem resultados com taxa de sucesso mais elevada. Um dos algoritmos de classificação mais famosos é o ***PRISM*** (CENDROWSKA, 1987), que utiliza o princípio de "cobertura", i.e., ele vai criando regras que se aplicam ao maior número possível de exemplos do Conjunto de Treinamento, até que toda a tabela esteja "coberta" pelas regras produzidas. Seu desenvolvimento foi inspirado nos "pontos fracos" do algoritmo de indução de Árvores de Decisão ID3 (QUINLAN, 1986), como a dificuldade de entender as árvores muito grandes e complexas geradas pelo algoritmo ID3.
< 
< Não vamos aqui nos deter em particularidades do **PRISM** porque os resultados gerados pelo oneR são suficientemente representativos para os nossos propósitos de abordar os métodos de avaliação dos resultados produzidos pelo modelo induzido. E ao avaliarmos os resultados, estamos de certa forma avaliando a capacidade de predição de um modelo para determinada Base de Dados.
< 
< Abordar um modelo pelo seu desempenho é interessante porque há evidências empíricas de que nenhum algoritmo tem desempenho superior aos demais para qualquer Base de Dados. A estrutura interna do conjunto de dados desempenha um papel decisivo no desempenho do algoritmo e na qualidade dos resultados.
< 
< O algoritmo oneR, com toda sua simplicidade, pode ser imbatível para uma Base de Dados que tenha um atributo que se destaque sobre os demais, cujos valores são redundantes ou irrelevantes. E pode ser uma catástrofe para uma Base de Dados constituída por centenas ou milhares de atributos, todos igualmente importantes. Da mesma forma, qualquer algoritmo pode ter uma taxa de sucesso baixa se o Conjunto de Treinamento não constituir uma amostra representativa do universo de teste.
---
> A Tabela 4.4 revela que os atributos "Dia" e "Umidade" apresentam as
> menores taxas de erros. Adotando qualquer critério arbitrário de
> desempate, vamos ficar com o conjunto de erros gerados pelo atributo
> "Umidade" e gerar as seguintes Regras de Classificação:
> 
> Umidade(Alta) → Partida=Não ou ***IF*** Umidade**=**Alta ***THEN***
> Partida**=**Não (R 4.4)
> 
> Umidade(Normal) → Partida=Sim ou ***IF*** Umidade**=**Normal ***THEN***
> Partida**=**Sim (R 4.5)
> 
> Portanto, quando o algoritmo **oneR** tiver que classificar um novo
> exemplo, somente o atributo "Umidade" será considerado, e o resultado
> será baseado nas Regras de Classificação "R 4.4" e "R 4.5". Isso
> significa que se os Exemplos de Treinamento forem usados como Exemplos
> de Teste, e supondo que entre os 14 Exemplos de Treinamento não haja
> contradição entre si, o algoritmo **oneR** deve acertar 10 vezes e errar
> 4.
> 
> Mas, e se o Conjunto de Teste for diferente do Conjunto de Treinamento?
> Não será a estimativa de 10 acertos e 4 erros demasiadamente otimista ou
> ela se confirmará com os novos dados? E se o número de Exemplos de
> Treinamento tivesse sido 140, em vez de 14, que implicações isso teria
> nas estimativas de acertos?
> 
> Há outros algoritmos de classificação bem mais refinados que o **oneR**
> e que, na maioria dos casos, produzem resultados com taxa de sucesso
> mais elevada. Um dos algoritmos de classificação mais famosos é o
> ***PRISM*** (Cendrowska, 1987), que utiliza o princípio de "cobertura",
> i.e., ele vai criando regras que se aplicam ao maior número possível de
> exemplos do Conjunto de Treinamento, até que toda a tabela esteja
> "coberta" pelas regras produzidas. Seu desenvolvimento foi inspirado nos
> "pontos fracos" do algoritmo de indução de Árvores de Decisão ID3
> (Quinlan, 1986), como a dificuldade de entender as árvores muito grandes
> e complexas geradas pelo algoritmo ID3.
> 
> Não vamos aqui nos deter em particularidades do **PRISM** porque os
> resultados gerados pelo oneR são suficientemente representativos para os
> nossos propósitos, de abordar os métodos de avaliação dos resultados
> produzidos pelo modelo induzido. E ao avaliarmos os resultados, estamos
> de certa forma avaliando a capacidade de predição de um modelo para
> determinada Base de Dados.
> 
> Abordar um modelo pelo seu desempenho é interessante porque há
> evidências empíricas de que nenhum algoritmo tem desempenho superior aos
> demais para qualquer Base de Dados. A estrutura interna do conjunto de
> dados desempenha um papel decisivo no desempenho do algoritmo e na
> qualidade dos resultados.
> 
> O algoritmo oneR, com toda sua simplicidade, pode ser imbatível para uma
> Base de Dados que tenha um atributo que se destaque sobre os demais,
> cujos valores são redundantes ou irrelevantes. E pode ser uma catástrofe
> para uma Base de Dados constituída por centenas ou milhares de
> atributos, todos igualmente importantes. Da mesma forma, qualquer
> algoritmo pode ter uma taxa de sucesso baixa se o Conjunto de
> Treinamento não constituir uma amostra representativa do universo de
> teste.
1804,1814c3080,3106
< Após o treinamento para gerar um Modelo através do Algoritmo de Aprendizado, é de grande importância fazer uma avaliação do desempenho do modelo. Em outras palavras, interessa saber quão preditivo é o Modelo Aprendido. Há várias metodologias consagradas para este fim. Vamos iniciar nossa abordagem ao tema relembrando a **Acurácia** de um Classificador Binário.
< 
< Considere que nosso Classificador Binário esteja sendo usado para fazer um diagnóstico médico. Se as respostas possíveis para este diagnóstico forem "Positivo" e "Negativo", quatro possibilidades de predição podem ocorrer:
< 
< 1.  Se o paciente for portador de uma doença e o Classificador acertar no diagnóstico, dizemos que este caso é um **Verdadeiro Positivo** ou **VP**;
< 
< 2.  Se o paciente não for portador da doença e o Classificador acertar no diagnóstico, dizemos que este caso é um **Verdadeiro Negativo** ou **VN**;
< 
< 3.  Se o paciente for portador da doença, mas o Classificador errar no diagnóstico indicando que ele está são, dizemos que este caso é um **Falso Negativo** ou **FN**;
< 
< 4.  Se o paciente não for portador da doença, mas o Classificador errar no diagnóstico indicando que ele está doente, dizemos que este caso é um **Falso Positivo** ou **FP**.
---
> Após o treinamento para gerar um Modelo através do Algoritmo de
> Aprendizado, é de grande importância fazer uma avaliação do desempenho
> do modelo. Em outras palavras, interessa saber quão preditivo é o Modelo
> Aprendido. Há várias metodologia consagradas para este fim. Vamos
> iniciar nossa abordagem ao tema relembrando a **Acurácia** de um
> Classificador Binário.
> 
> Considere que nosso Classificador Binário esteja sendo usado para fazer
> um diagnóstico médico. Se as respostas possíveis para este diagnóstico
> forem "Positivo" e "Negativo", quatro possibilidades de predição podem
> ocorrer:
> 
> 1.  Se o paciente for portador de uma doença e o Classificador acertar
>     > no diagnóstico, dizemos que este caso é um **Verdadeiro Positivo**
>     > ou **VP**;
> 
> 2.  Se o paciente não for portador da doença e o Classificador acertar
>     > no diagnóstico, dizemos que este caso é um **Verdadeiro Negativo**
>     > ou **VN**;
> 
> 3.  Se o paciente for portador da doença, mas o Classificador errar no
>     > diagnóstico indicando que ele está são, dizemos que este caso é um
>     > **Falso Negativo** ou **FN**;
> 
> 4.  Se o paciente não for portador da doença, mas o Classificador errar
>     > no diagnóstico indicando que ele está doente, dizemos que este
>     > caso é um **Falso Positivo** ou **FP**.
1816c3108,3109
< Essas quatro combinações de resultados estão representadas na **Matriz de Confusão** mostrada na Tabela 4.5.
---
> Essas quatro combinações de resultados estão representadas na **Matriz
> de Confusão** mostrada na Tabela 4.5.
1825c3118,3120
< A Precisão ou Acurácia do Classificador se expressa pelo número de classificações corretas (VP+VN) divididas pelo número total de classificações (VP+VN+FP+FN),
---
> A Precisão ou Acurácia do Classificador se expressa pelo número de
> classificações corretas (VP+VN) divididas pelo número total de
> classificações (VP+VN+FP+FN),
1829,1831c3124,3134
< Ocorre que em situações reais o custo de um **Falso Positivo** pode não ser igual ao de um **Falso Negativo**, e a Acurácia não consegue captar adequadamente essa situação de interesse.
< 
< Suponha que um classificador usado para Detecção de Anomalia tenha que atribuir a cada um dos 100 testes um rótulo de "Situação=Normal" ou "Situação=Anormal". Suponha ainda que a relação entre donos honestos de cartão de crédito e golpistas seja de 96 para 4 e o classificador tenha colocado 99 portadores de cartão na classe "Normal" e apenas um dos golpistas na classe "Anormal". Neste caso a Acurácia do Classificador será de,
---
> Ocorre que em situações reais o custo de um **Falso Positivo** pode não
> ser igual ao de um **Falso Negativo**, e a Acurácia não consegue captar
> adequadamente essa situação de interesse.
> 
> Suponha que um classificador usado para Detecção de Anomalia tenha que
> atribuir a cada um dos 100 testes um rótulo de "Situação=Normal" ou
> "Situação=Anormal". Suponha ainda que a relação entre donos honestos de
> cartão de crédito e golpistas seja de 96 para 4 e o classificador tenha
> colocado 99 portadores de cartão na classe "Normal" e apenas um dos
> golpistas na classe "Anormal". Neste caso a Acurácia do Classificador
> será de,
1835,1837c3138,3151
< A interpretação baseada apenas na Acurácia indicaria um excelente desempenho, mas na realidade este é um péssimo classificador para uma operadora de cartões de crédito, porque seu interesse em detectar os golpistas é bem maior do que os donos honestos de cartão! Há um sem número de situações semelhantes a esta. Pense nos danos diferenciados, do ponto de vista de saúde pública, entre fornecer um falso diagnóstico positivo para um paciente são e um falso diagnóstico negativo para um paciente com uma doença contagiosa.
< 
< Para detectar estes casos de conjuntos não-balanceados de Falso Positivo e Falso Negativo, podemos definir a **Taxa de Verdadeiro Negativo**, também conhecida por **Especificidade**, como sendo o número de Verdadeiro Negativo (VN) dividido pelo número total de negativos, que é a soma de Verdadeiro Negativo (VN) mais Falso Positivo (FP), ou seja,
---
> A interpretação baseada apenas na Acurácia indicaria um excelente
> desempenho, mas na realidade este é um péssimo classificador para uma
> operadora de cartões de crédito, porque seu interesse em detectar os
> golpistas é bem maior do que os donos honestos de cartão! Há um sem
> número de situações semelhantes a esta. Pense nos danos diferenciados,
> do ponto de vista de saúde pública, entre fornecer um falso diagnóstico
> positivo para um paciente são e um falso diagnóstico negativo para um
> paciente com uma doença contagiosa.
> 
> Para detectar estes casos de conjuntos não-balanceados de Falso Positivo
> e Falso Negativo, podemos definir a **Taxa de Verdadeiro Negativo**,
> também conhecida por **Especificidade**, como sendo o número de
> Verdadeiro Negativo (VN) dividido pelo número total de negativos, que é
> a soma de Verdadeiro Negativo (VN) mais Falso Positivo (FP), ou seja,
1841c3155,3157
< Se o indicador Taxa de Verdadeiro Negativo for utilizado para o caso citado dos cartões de crédito, teremos uma Taxa de Verdadeiro Negativo de,
---
> Se o indicador Taxa de Verdadeiro Negativo for utilizado para o caso
> citado dos cartões de crédito, teremos uma Taxa de Verdadeiro Negativo
> de,
1845c3161,3165
< Para outras situações, pode ser mais conveniente utilizar a **Taxa de Verdadeiro Positivo** , também conhecida por **Sensibilidade**, como sendo o número de Verdadeiro Positivo (VP) dividido pelo número total de positivos, que é a soma de Verdadeiro Positivo (VP) mais Falso Negativo (FN), ou seja,
---
> Para outras situações, pode ser mais conveniente utilizar a **Taxa de
> Verdadeiro Positivo** , também conhecida por **Sensibilidade**, como
> sendo o número de Verdadeiro Positivo (VP) dividido pelo número total de
> positivos, que é a soma de Verdadeiro Positivo (VP) mais Falso Negativo
> (FN), ou seja,
1849,1851c3169,3182
< Com estes indicadores em mente, suponha que se queira avaliar qual será o desempenho do Modelo gerado pelo Algoritmo de Aprendizado para determinada Base de Dados. Se utilizarmos o mesmo Conjunto de Treinamento como Conjunto de Teste, muito possivelmente a estimativa de desempenho resultará excessivamente otimista para testes reais, com novos Conjuntos de Teste.
< 
< Outra alternativa é reservar parte do Conjunto de Treinamento para ser usada como Conjunto de Teste. Mas qual o tamanho ideal da partição do conjunto de Exemplos de Treinamento? E como escolher os elementos deste subconjunto do Conjunto de Treinamento que serão usados para teste? E se o Conjunto de Teste for muito pequeno? Felizmente a Estatística tem estudos bastante robustos sobre questões dessa natureza que podem nos auxiliar.
---
> Com estes indicadores em mente, suponha que se queira avaliar qual será
> o desempenho do Modelo gerado pelo Algoritmo de Aprendizado para
> determinada Base de Dados. Se utilizarmos o mesmo Conjunto de
> Treinamento como Conjunto de Teste, muito possivelmente a estimativa de
> desempenho resultará excessivamente otimista para testes reais, com
> novos Conjuntos de Teste.
> 
> Outra alternativa é reservar parte do Conjunto de Treinamento para ser
> usada como Conjunto de Teste. Mas qual o tamanho ideal da partição do
> conjunto de Exemplos de Treinamento? E como escolher os elementos deste
> subconjunto do Conjunto de Treinamento que serão usados para teste? E se
> o Conjunto de Teste for muito pequeno? Felizmente a Estatística tem
> estudos bastante robustos sobre questões dessa natureza que podem nos
> auxiliar.
1856,1862c3187,3216
< As duas técnicas citadas, conhecidas como **Técnica de Ressubstituição** e **Técnica de Reamostragem**, apresentam pontos fortes e fracos, e justificam a criação de vários **métodos de avaliação de desempenho** de classificadores. Vamos analisar apenas alguns dos principais métodos de avaliação de desempenho.
< 
< ### Método da Ressubstituição ou *"Use training set"* 
< 
< Neste método o Conjunto de Treinamento é também utilizado como Conjunto de Teste, conforme mostra a Figura 4.2. Se o Conjunto de Treinamento for uma amostra representativa do universo do problema, suas estimativas de desempenho para um Conjunto de Teste composto por Exemplos não vistos anteriormente podem ser muito boas. Caso contrário, o modelo poderá apresentar muitos erros de generalização durante os testes, seja por problemas de excesso de complexidade do Modelo, que costuma causar *overfitting*, ou por Poda inadequada.
< 
< Por outro lado, o fato de o conjunto completo de treinamento ser usado para gerar o Modelo constitui uma vantagem sobre os métodos de reamostragem, principalmente se o número de Exemplos de Treinamento for pequeno.
---
> As duas técnicas citadas, conhecidas como **Técnica de Ressubstituição**
> e **Técnica de Reamostragem**, apresentam pontos fortes e fracos, e
> justificam a criação de vários **métodos de avaliação de desempenho** de
> classificadores. Vamos analisar apenas alguns dos principais métodos de
> avaliação de desempenho.
> 
> **Método da Ressubstituição ou *"Use training set"***
> 
> Neste método o Conjunto de Treinamento é também utilizado como Conjunto
> de Teste, conforme mostra a Figura 4.2. Se o Conjunto de Treinamento for
> uma amostra representativa do universo do problema, suas estimativas de
> desempenho para um Conjunto de Teste composto por Exemplos não vistos
> anteriormente podem ser muito boas. Caso contrário, o modelo poderá
> apresentar muitos erros de generalização durante os testes, seja por
> problemas de excesso de complexidade do Modelo, que costuma causar
> *overfitting*, ou por Poda inadequada.
> 
> Por outro lado, o fato de o conjunto completo de treinamento ser usado
> para gerar o Modelo constitui uma vantagem sobre os métodos de
> reamostragem, principalmente se o número de Exemplos de Treinamento for
> pequeno.
> 
> Figura . -- Na Ressubistituição, o Conjunto de Treinamento também é o
> Conjunto de Teste.
> 
> De fato, na simulação Weka da Tabela do Tempo (Tabela 4.1) com o
> algoritmo oneR usando o método *"Use training set"*, o número de
> instâncias ou exemplos classificados corretamente foi 10 (71%), e 4
> (29%) classificados incorretamente, conforme esperado. A Matriz de
> Confusão para os 14 Exemplos está mostrada na Tabela 4.6.
1864,1868c3218,3219
< Figura . -- Na Ressubistituição, o Conjunto de Treinamento também é o Conjunto de Teste.
< 
< De fato, na simulação Weka da Tabela do Tempo (Tabela 4.1) com o algoritmo oneR usando o método *"Use training set"*, o número de instâncias ou exemplos classificados corretamente foi 10 (71%), e 4 (29%) classificados incorretamente, conforme esperado. A Matriz de Confusão para os 14 Exemplos está mostrada na Tabela 4.6.
< 
< Tabela . -- Matriz de Confusão para a Tabela do Tempo com o oneR e o Método *"Use training set"*.
---
> Tabela . -- Matriz de Confusão para a Tabela do Tempo com o oneR e o
> Método *"Use training set"*.
1875c3226,3231
< Quando repetimos os mesmos procedimentos, porém usando o algoritmo *PRISM*, os resultados foram os seguintes: simulação Weka da Tabela do Tempo (Tabela 4.1) com o algoritmo *PRISM* usando o método *"Use training set"*, o número de instâncias ou exemplos classificados corretamente foi 14 (100%), e 0 (0%) classificados incorretamente. A Matriz de Confusão para os 14 Exemplos está mostrada na Tabela 4.7.
---
> Quando repetimos os mesmos procedimentos, porém usando o algoritmo
> *PRISM*, os resultados foram os seguintes: simulação Weka da Tabela do
> Tempo (Tabela 4.1) com o algoritmo *PRISM* usando o método *"Use
> training set"*, o número de instâncias ou exemplos classificados
> corretamente foi 14 (100%), e 0 (0%) classificados incorretamente. A
> Matriz de Confusão para os 14 Exemplos está mostrada na Tabela 4.7.
1877c3233,3234
< Tabela . -- Matriz de Confusão para a Tabela do Tempo com o *PRISM* e o Método *"Use training set"*.
---
> Tabela . -- Matriz de Confusão para a Tabela do Tempo com o *PRISM* e o
> Método *"Use training set"*.
1884,1888c3241
< ### Método da Divisão da Amostra ou *Holdout* ou *Percentage Split*
< 
< Consiste na divisão dos Exemplos de Treinamento em dois subconjuntos disjuntos, um para Treinamento, outro para Teste, conforme mostra a Figura 4.3. O valor das porcentagens de cada um dos conjuntos é geralmente expresso numa única porcentagem maior que 50%, estando subentendido que o conjunto menor é o complemento para 100%. O valor de divisão mais comum é 66% para Treinamento e 34% para Teste, embora não haja evidências empíricas que justifiquem essa escolha de 2/3 e 1/3.
< 
< Sua vantagem é a simplicidade, mas dependendo da composição obtida, as classes dos Exemplos podem não estar igualmente representadas nos dois conjuntos. Outra limitação desse método está no fato de que menos Exemplos são usados no Treinamento, podendo ter um impacto negativo no desempenho do Modelo induzido.
---
> **Método da Divisão da Amostra ou *Holdout* ou *Percentage Split***
1890c3243,3267
< Figura . -- No *Holdout*, os Exemplos de Treinamento são Divididos em Dois Subconjuntos.
---
> Consiste na divisão dos Exemplos de Treinamento em dois conjuntos
> disjuntos, um para Treinamento, outro para Teste, conforme mostra a
> Figura 4.3. O valor das porcentagens de cada um dos conjuntos é
> geralmente expresso numa única porcentagem maior que 50%, estando
> subentendido que o conjunto menor é o complemento para 100%. O valor de
> divisão mais comum é 66% para Treinamento e 34% para Teste, embora não
> haja evidências empíricas que justifiquem essa escolha de 2/3 e 1/3.
> 
> Sua vantagem é a simplicidade, mas dependendo da composição obtida, as
> classes dos Exemplos podem não estar igualmente representadas nos dois
> conjuntos. Outra limitação desse método está no fato de que menos
> Exemplos são usados no Treinamento, podendo ter um impacto negativo no
> desempenho do Modelo induzido.
> 
> Figura . -- No *Holdout*, os Exemplos de Treinamento são Divididos em
> Dois Subconjuntos.
> 
> Para Conjuntos de Teste excessivamente pequenos, dividir o já escasso
> número de Exemplos de Teste pode ter um efeito desastroso ou na geração
> do Modelo ou na sua avaliação de desempenho. De fato, na simulação Weka
> da Tabela do Tempo com o algoritmo oneR usando o método da *"Percentage
> Split"*, com o Conjunto de Treinamento correspondendo a 66% dos
> Exemplos, o número de instâncias ou exemplos classificados corretamente
> foi 2 (40%), e 3 (60%) classificados incorretamente!. A Matriz de
> Confusão para os 5 Exemplos considerados está mostrada na Tabela 4.8.
1892,1894c3269,3270
< Para Conjuntos de Teste excessivamente pequenos, dividir o já escasso número de Exemplos de Teste pode ter um efeito desastroso ou na geração do Modelo ou na sua avaliação de desempenho. De fato, na simulação Weka da Tabela do Tempo com o algoritmo oneR usando o método da *"Percentage Split"*, com o Conjunto de Treinamento correspondendo a 66% dos Exemplos, o número de instâncias ou exemplos classificados corretamente foi 2 (40%), e 3 (60%) classificados incorretamente!. A Matriz de Confusão para os 5 Exemplos considerados está mostrada na Tabela 4.8.
< 
< Tabela . -- Matriz de Confusão para a Tabela do Tempo com o *oneR* e o Método da *"Percentage Split"*.
---
> Tabela . -- Matriz de Confusão para a Tabela do Tempo com o *oneR* e o
> Método da *"Percentage Split"*.
1901c3277,3283
< Quando repetimos os mesmos procedimentos, porém usando o algoritmo *PRISM*, os resultados foram os seguintes: simulação Weka da Tabela do Tempo com o algoritmo *PRISM* usando o método *"Percentage split"*, com o Conjunto de Treinamento correspondendo a 66% dos Exemplos, o número de instâncias ou exemplos classificados corretamente foi 4 (80%), e 1 (20%) classificado incorretamente. A Matriz de Confusão para os 5 Exemplos está mostrada na Tabela 4.9.
---
> Quando repetimos os mesmos procedimentos, porém usando o algoritmo
> *PRISM*, os resultados foram os seguintes: simulação Weka da Tabela do
> Tempo com o algoritmo *PRISM* usando o método *"Percentage split"*, com
> o Conjunto de Treinamento correspondendo a 66% dos Exemplos, o número de
> instâncias ou exemplos classificados corretamente foi 4 (80%), e 1 (20%)
> classificado incorretamente. A Matriz de Confusão para os 5 Exemplos
> está mostrada na Tabela 4.9.
1903c3285,3286
< Tabela . -- Matriz de Confusão para a Tabela do Tempo com o *PRISM* e o Método *"Use training set"*.
---
> Tabela . -- Matriz de Confusão para a Tabela do Tempo com o *PRISM* e o
> Método *"Use training set"*.
1910,1914c3293
< ### Método da Validação Cruzada ou *Cross-validation*
< 
< Neste método, os Exemplos de Treinamento são aleatoriamente divididos em *k* partições mutuamente exclusivas ou "*folds*", sendo *k* normalmente igual a 10. A Figura 4.4 mostra um exemplo para *k = 4*, ou seja, 3/4 dos Exemplos de Treinamento são usados para Treinamento e 1/4 dos Exemplos de Treinamento são reservados para a fase de Teste.
< 
< A cada iteração um desses *folds* será usado como Conjunto de Teste, enquanto que os outros serão usados para Treinamento. O nome de validação cruzada se justifica então pelo fato de que cada *fold* será usado *(k-1)* vezes para Treinamento e uma vez para Teste. O erro total será a soma dos erros de todas as *k* execuções, enquanto que o erro médio é o erro total dividido pelo número *k* de partições.
---
> **Método da Validação Cruzada ou *Cross-validation***
1916c3295,3315
< Figura . -- Na Validação Cruzada, o Conjunto de Treinamento é Dividido em *k* Partições.
---
> Neste método, os Exemplos de Treinamento são aleatoriamente divididos em
> *k* partições mutuamente exclusivas ou "*folds*", sendo *k* normalmente
> igual a 10. A Figura 4.4 mostra um exemplo para *k = 4*, ou seja, 3/4
> dos Exemplos de Treinamento são usados para Treinamento e 1/4 dos
> Exemplos de Treinamento são reservados para a fase de Teste.
> 
> A cada iteração um desses *folds* será usado como Conjunto de Teste,
> enquanto que os outros serão usados para Treinamento. O nome de
> validação cruzada se justifica então pelo fato de que cada *fold* será
> usado *(k-1)* vezes para Treinamento e uma vez para Teste. O erro total
> será a soma dos erros de todas as *k* execuções, enquanto que o erro
> médio é o erro total dividido pelo número *k* de partições.
> 
> Figura . -- Na Validação Cruzada, o Conjunto de Treinamento é Dividido
> em *k* Partições.
> 
> De fato, na simulação Weka da Tabela do Tempo com o algoritmo oneR
> usando o método da "Cross-validation", com *k* = 10 *folds*, o número de
> instâncias ou exemplos classificados corretamente foi 5 (36%), e 9 (66%)
> classificados incorretamente!. A Matriz de Confusão para os 14 Exemplos
> considerados está mostrada na Tabela 4.10.
1918,1920c3317,3318
< De fato, na simulação Weka da Tabela do Tempo com o algoritmo oneR usando o método da "Cross-validation", com *k* = 10 *folds*, o número de instâncias ou exemplos classificados corretamente foi 5 (36%), e 9 (66%) classificados incorretamente!. A Matriz de Confusão para os 14 Exemplos considerados está mostrada na Tabela 4.10.
< 
< Tabela . -- Matriz de Confusão para a Tabela do Tempo com o *oneR* e o Método da *"Cross-validation"*.
---
> Tabela . -- Matriz de Confusão para a Tabela do Tempo com o *oneR* e o
> Método da *"Cross-validation"*.
1927c3325,3330
< Na simulação Weka da Tabela do Tempo com o algoritmo *PRISM* usando o método da *"Cross-validation"*, com *k* = 10 *folds*, o número de instâncias ou Exemplos classificados corretamente foi 12 (86%), e 0 (0%) classificados incorretamente! (com 3 Exemplos não classificados). A Matriz de Confusão para os Exemplos considerados está mostrada na Tabela 4.11.
---
> Na simulação Weka da Tabela do Tempo com o algoritmo *PRISM* usando o
> método da *"Cross-validation"*, com *k* = 10 *folds*, o número de
> instâncias ou Exemplos classificados corretamente foi 12 (86%), e 0 (0%)
> classificados incorretamente! (com 3 Exemplos não classificados). A
> Matriz de Confusão para os Exemplos considerados está mostrada na Tabela
> 4.11.
1929c3332,3333
< Tabela . - Matriz de Confusão para a Tabela do Tempo com o *PRISM* e o Método da *"Cross-validation"*.
---
> Tabela . - Matriz de Confusão para a Tabela do Tempo com o *PRISM* e o
> Método da *"Cross-validation"*.
1936,1940c3340
< ### Método Deixe-Um-De-Fora ou *Leave-One-Out*
< 
< É um caso especial do Método da Validação Cruzada em que o número de partições *k* é igual ao número de Exemplos *N*, isto é, *k = N*, e cada partição é composta por apenas um Exemplo, como mostra a Figura 4.5. A vantagem é que mais dados são usados para o Treinamento, mas a desvantagem é seu custo computacional para os casos em que *N* for muito grande.
< 
< Figura . -- No *Leave-One-Out*, o Conjunto de Treinamento é Dividido em *N* Partições.
---
> **Método Deixe-Um-De-Fora ou *Leave-One-Out***
1942c3342,3358
< Na simulação Weka da Tabela do Tempo com o algoritmo oneR usando o método da *"Cross-validation"*, com *k* = 14 *folds*, número idêntico ao de Exemplos ou instâncias, portanto *k = N*, o resultado da classificação foi idêntico ao da *"Cross-validation"*, sendo o número de Exemplos classificadas corretamente 5 (36%), e 9 (66%) classificados incorretamente!. A Matriz de Confusão para os 14 Exemplos considerados está mostrada na Tabela 4.12.
---
> É um caso especial do Método da Validação Cruzada em que o número de
> partições *k* é igual ao número de Exemplos *N*, isto é, *k = N*, e cada
> partição é composta por apenas um Exemplo, como mostra a Figura 4.5. A
> vantagem é que mais dados são usados para o Treinamento, mas a
> desvantagem é seu custo computacional para os casos em que *N* for muito
> grande.
> 
> Figura . -- No *Leave-One-Out*, o Conjunto de Treinamento é Dividido em
> *N* Partições.
> 
> Na simulação Weka da Tabela do Tempo com o algoritmo oneR usando o
> método da *"Cross-validation"*, com *k* = 14 *folds*, número idêntico ao
> de Exemplos ou instâncias, portanto *k = N*, o resultado da
> classificação foi idêntico ao da *"Cross-validation"*, sendo o número de
> Exemplos classificadas corretamente 5 (36%), e 9 (66%) classificados
> incorretamente!. A Matriz de Confusão para os 14 Exemplos considerados
> está mostrada na Tabela 4.12.
1944c3360,3361
< Tabela . -- Matriz de Confusão para a Tabela do Tempo com o *oneR* e o Método da *"Leave-one-out"*.
---
> Tabela . -- Matriz de Confusão para a Tabela do Tempo com o *oneR* e o
> Método da *"Leave-one-out"*.
1951c3368,3373
< Repetindo o mesmo Conjunto de Teste, porém com o Algoritmo PRISM, usando o método da *"Cross-validation"*, com *k* = 14 *folds*, o resultado da classificação foi idêntico ao da *"Cross-validation"*, sendo o número de Exemplos classificadas corretamente 11 (79%), 0 (0%) classificados incorretamente e 3 Exemplos não classificados. A Matriz de Confusão para os 11 Exemplos considerados está mostrada na Tabela 4.13.
---
> Repetindo o mesmo Conjunto de Teste, porém com o Algoritmo PRISM, usando
> o método da *"Cross-validation"*, com *k* = 14 *folds*, o resultado da
> classificação foi idêntico ao da *"Cross-validation"*, sendo o número de
> Exemplos classificadas corretamente 11 (79%), 0 (0%) classificados
> incorretamente e 3 Exemplos não classificados. A Matriz de Confusão para
> os 11 Exemplos considerados está mostrada na Tabela 4.13.
1953c3375,3376
< Tabela . -- Matriz de Confusão para a Tabela do Tempo com o *oneR* e o Método da *"Leave-one-out"*.
---
> Tabela . -- Matriz de Confusão para a Tabela do Tempo com o *oneR* e o
> Método da *"Leave-one-out"*.
1960c3383,3385
< Nesta série de simulações, o algoritmo PRISM produziu um classificador com melhor desempenho que o classificador do algoritmo oneR para o mesmo Conjunto de Treinamento.
---
> Neste conjunto de simulações, o algoritmo PRISM produziu um
> classificador com melhor desempenho que o classificador do algoritmo
> oneR para este Conjunto de Treinamento.
1965,1969c3390,3402
< Nesta unidade, vimos um algoritmo simples, conhecido como oneR, usado para gerar Regras de Classificação. Outros algoritmos mais refinados usam princípios mais complexos, como o de cobertura, para produzir Regras de Classificação (caso do PRISM).
< 
< Foram apresentados alguns indicadores que auxiliam o usuário a decidir se os resultados obtidos são satisfatórios ou não. Também foram apresentados alguns métodos para estimar o desempenho futuro do classificador em situação de testes reais.
< 
< Duas simulações comparativas entre o desempenho do algoritmo oneR e PRISM para a Tabela do Tempo foram apresentadas para ajudar a fixar os conceitos aprendidos.
---
> Nesta unidade, vimos um algoritmo simples, conhecido como oneR, usado
> para gerar Regras de Classificação. Outros algoritmos mais refinados
> usam princípios mais complexos, como o de cobertura, para produzir
> Regras de Classificação (caso do PRISM).
> 
> Foram apresentados alguns indicadores que auxiliam o usuário a decidir
> se os resultados obtidos são satisfatórios ou não. Também foram
> apresentados alguns métodos para estimar o desempenho futuro do
> classificador em situação de testes reais.
> 
> Duas simulações comparativas entre o desempenho do algoritmo oneR e
> PRISM para a Tabela do Tempo foram apresentadas para ajudar a fixar os
> conceitos aprendidos.
1974,1976c3407,3408
< 1\. Explique **com suas próprias palavras** as vantagens e desvantagens das **Árvores de Decisão** e **Regras de Classificação**.
< 
< 2\. Explique **com suas próprias palavras** os Métodos *"**Cross-validation**"* e *"**Holdout**"*.
---
> 1\. (20%) Explique **com suas próprias palavras** as vantagens e
> desvantagens das **Árvores de Decisão** e **Regras de Classificação**.
1978c3410,3411
< 3\. Carregue o arquivo **"iris.arff"** (anexo) no Weka e faça a Classificação usando o algoritmo **"oneR"**, com o método ***"Cross-validation"*** (10 *Folds*).
---
> 2\. (30%) Explique **com suas próprias palavras** os Métodos
> *"**Cross-validation**"* e *"**Holdout**"*.
1980,1982c3413,3424
< \(a\) Faça uma análise da **Matriz de Confusão** gerada, reproduzindo os valores obtidos na simulação.
< 
< \(b\) Ainda com base nos resultados da simulação no Weka, explique **com suas próprias palavras** por que a classe **"Iris Setosa"** tem a mais alta taxa de **Verdadeiro Positivo** *("TP Rate")*, enquanto que a **"Iris Versicolor"**, a mais baixa (consulte a Figura 3.1 do Capítulo 3).
---
> 3\. Carregue o arquivo **"iris.arff"** (anexo) no Weka e faça a
> Classificação usando o algoritmo **"oneR"**, com o método
> ***"Cross-validation"*** (10 *Folds*).
> 
> \(a\) (30%) -- Faça uma análise da **Matriz de Confusão** gerada,
> reproduzindo os valores obtidos na simulação.
> 
> \(b\) (20%) -- Ainda com base nos resultados da simulação no Weka,
> explique **com suas próprias palavras** por que a classe **"Iris
> Setosa"** tem a mais alta taxa de **Verdadeiro Positivo** *("TP Rate")*,
> enquanto que a **"Iris Versicolor"**, a mais baixa (consulte a Figura
> 3.1 do Capítulo 3).
1987,2015c3429,3498
< CENDROWSKA, J. **PRISM: An Algorithm for Inducing Modular Rules**. International Journal of Man-Machine Studies. Vol. 27, pp. 349-370, 1987. In http://sci2s.ugr.es/keel/pdf/algorithm/articulo/1987-Cendrowska-IJMMS.pdf. Acessado em 06.03.2013.
< 
< QUINLAN, J. R. **Induction of Decision Trees**. Machine Learning, Vol. 1, No. 1, pp. 81-106. Boston: Kluwer Academic Publishers, 1986.
< 
< REZENDE, S. O. (Organizadora). **Sistemas Inteligentes: Fundamentos e Aplicações.** Barueri: Editora Manole Ltda, 2005.
< 
< ROCHA, M.; CORTEZ, P. & NEVES, J. M. **Análise Inteligente de Dados: Algoritmos e Implementação em Java.** Lisboa: Editora de Informática, 2008.
< 
< TAN, P.N.; STEINBACH, M. & KUMAR, V. **Introdução ao Data Mining Mineração de Dados.** Rio de Janeiro: Editora Ciência Moderna Ltda., 2009.
< 
< WITTEN, I. H. & FRANK, E. **Data Mining: Practical Machine Learning Tools and Techniques.** Second Edition. Amsterdam: Morgan Kaufmann Publishers, 2005.
< 
< 5.  Máquina de Vetores de Suporte ou *Support Vector Machine*
<     =========================================================
< 
<     1.  Introdução
<         ----------
< 
< Nas unidades anteriores, foi usado o recurso de representar um **Exemplo de Treinamento** por um ponto num plano cartesiano, como no caso da flor Íris (Figura 5.1). As Regras de Classificação, por sua vez, eram representadas por retas tracejadas e ilustravam como o **Modelo Aprendido** classificava os Exemplos.
< 
< Figura . -- Representação de Exemplos de Treinamento no Plano Cartesiano. ![](./media/image22.png){width="5.625in" height="3.7263888888888888in"}[^4]
< 
< Tanto as **Regras de Associação** e **Classificação** quanto as **Árvores de Decisão** podem ser vistas como representantes de um paradigma de aprendizado supervisionado denominado **Aprendizado Orientado a Conhecimento**, porque são de fácil compreensão e utilização pelos seres humanos. Outro nome que se dá a este tipo de aprendizado é **Paradigma de Aprendizado Simbólico**, porque ele cria **Representações Simbólicas do Modelo** gerado, tais como Árvores de Decisão, Regras etc.
< 
< Vamos agora estudar um novo paradigma de aprendizado supervisionado, conhecido como **Paradigma de Modelos Funcionais**, que em geral apresenta resultados com melhor precisão que os representantes do paradigma Orientado a Conhecimento, mas que para entender como se chegou a determinado resultado há que ter um certo preparo em matemática. Este tipo de aprendizado também é conhecido como **Paradigma do Aprendizado Estatístico**, porque ele utiliza **Modelos Estatísticos** para guiar a geração do Modelo induzido durante o treinamento.
< 
< Como o escopo desta unidade não é a apresentação da teoria matemática dessa classe de algoritmos, vamos reduzir a um mínimo as deduções matemáticas e nos valer de ilustrações gráficas e interpretações geométricas das ideias fundamentais deste interessante tópico.
< 
< Dois dos algoritmos de aprendizado supervisionado mais populares dos Modelos Funcionais, são as **Redes Neurais**[^5] ou *Neural Networks*, e as **Máquinas de Vetores** **de Suporte** **(MVS)** ou *Support Vector Machine (SVM)*. A teoria matemática sobre as Máquinas de Vetores de Suporte foi apresentada à comunidade científica por (CORTES & VAPNIK, 1995), em meados da década de 1990, e desde então suas implementações algorítmicas têm produzido resultados animadores para o problema do **reconhecimento de padrões** em Bases de Dados.
---
> CENDROWSKA, J. **PRISM: An Algorithm for Inducing Modular Rules**.
> International Journal of Man-Machine Studies. Vol. 27, pages 349-370,
> 1987. In http://
> http://sci2s.ugr.es/keel/pdf/algorithm/articulo/1987-Cendrowska-IJMMS.pdf.
> Acessado em 06.03.2013.
> 
> QUINLAN, J. R. **Induction of Decision Trees**. Machine Learning, Vol.
> 1, No. 1, pp. 81-106. Boston: Kluwer Academic Publishers, 1986.
> 
> REZENDE, S. O. (Organizadora). **Sistemas Inteligentes: Fundamentos e
> Aplicações.** Barueri: Editora Manole Ltda, 2005.
> 
> ROCHA, M.; CORTEZ, P. & NEVES, J. M. **Análise Inteligente de Dados:
> Algoritmos e Implementação em Java.** Lisboa: Editora de Informática,
> 2008.
> 
> TAN, P.N.; STEINBACH, M. & KUMAR, V. **Introdução ao Data Mining
> Mineração de Dados.** Rio de Janeiro: Editora Ciência Moderna Ltda.,
> 2009.
> 
> WITTEN, I. H. & FRANK, E. **Data Mining: Practical Machine Learning
> Tools and Techniques.** Second Edition. Amsterdam: Morgan Kaufmann
> Publishers, 2005.
> 
> Máquina de Vetores de Suporte ou *Support Vector Machine*
> =========================================================
> 
> Introdução
> ----------
> 
> Nas unidades anteriores, foi usado o recurso de representar um **Exemplo
> de Treinamento** por um ponto num plano cartesiano, como no caso da flor
> Íris (Figura 5.1). As Regras de Classificação, por sua vez, eram
> representadas por retas tracejadas e ilustravam como o **Modelo
> Aprendido** classificava os Exemplos.
> 
> Figura . -- Representação de Exemplos de Treinamento no Plano
> Cartesiano. ![](media/image22.png){width="5.625in"
> height="3.7263888888888888in"}[^4]
> 
> Tanto as **Regras de Associação** e **Classificação** quanto as
> **Árvores de Decisão** podem ser vistas como representantes de um
> paradigma de aprendizado supervisionado denominado **Aprendizado
> Orientado a Conhecimento**, porque são de fácil compreensão e utilização
> pelos seres humanos. Outro nome que se dá a este tipo de aprendizado é
> **Paradigma de Aprendizado Simbólico**, porque ele cria **Representações
> Simbólicas do Modelo** gerado, tais como Árvores de Decisão, Regras etc.
> 
> Vamos agora estudar um novo paradigma de aprendizado supervisionado,
> conhecido como **Paradigma de Modelos Funcionais**, que em geral
> apresenta resultados com melhor precisão que os representantes do
> paradigma Orientado a Conhecimento, mas que para entender como se chegou
> a determinado resultado há que ter um certo preparo em matemática. Este
> tipo de aprendizado também é conhecido como **Paradigma do Aprendizado
> Estatístico**, porque ele utiliza **Modelos Estatísticos** para guiar a
> geração do Modelo induzido durante o treinamento.
> 
> Como o escopo desta unidade não é a apresentação da teoria matemática
> dessa classe de algoritmos, vamos reduzir a um mínimo as deduções
> matemáticas e nos valer de ilustrações gráficas e interpretações
> geométricas das ideias fundamentais deste interessante tópico.
> 
> Dois dos algoritmos de aprendizado supervisionado mais populares dos
> Modelos Funcionais, são as **Redes Neurais**[^5] ou *Neural Networks*, e
> as **Máquinas de Vetores** **de Suporte** ou *Support Vector Machine*. A
> teoria matemática sobre as Máquinas de Vetores de Suporte foi
> apresentada à comunidade científica por (Cortes e Vapnik, 1995), em
> meados da década de 1990, e desde então suas implementações algorítmicas
> têm produzido resultados animadores para o problema do **reconhecimento
> de padrões** em Bases de Dados.
2020,2034c3503,3554
< Nesta introdução a **Máquinas de Vetores de Suporte** (**MVS**), vamos passar a representar um **Exemplo de Treinamento** por um vetor, e o **Modelo Aprendido**, por outro vetor, chamado de **Vetor Peso** **w**. Qual a vantagem dessa forma de representação? A vantagem é que para classificar um Exemplo, bastará fazer o produto de dois vetores, algo computacionalmente simples. No contexto de classificação com MVS, mostraremos que o resultado dessa multiplicação será sempre ou "+1" ou "-1". Dessa forma, por meio da operação de **produto interno** entre dois vetores, os **Exemplos de Teste** serão classificados como pertencentes ou à classe "y = +1" ou à "y = -1".
< 
< Embora o algoritmo de aprendizado de um Modelo Funcional seja bem diferente daqueles algoritmos de aprendizado Orientado a Conhecimento, a formalização do problema da classificação continua a mesma. Em termos práticos, estamos simplesmente substituindo um módulo de classificação por outro, que desempenha a mesma função, possivelmente de forma mais complexa, porém com melhores resultados para muitos casos.
< 
< Um classificador binário é equivalente a uma função que faz o mapeamento de um conjunto de **atributos de entrada**, agora representados por um vetor **X**, em uma das classes "y = +1" ou à "y = -1". Em termos matemáticos,
< 
< $y = f\left( \mathbf{x} \right),\ \ \ \ \ \ \ \ \ y \in \left\{ - 1,\  + 1 \right\}\text{\ \ \ \ \ \ \ }e\text{\ \ \ \ \ }\mathbf{x} \in \mathbb{R}^{N}$ (5.1)
< 
< Por exemplo, num plano cartesiano, um ponto $\mathbf{x} \in \mathbb{R}^{2}$ pode ser descrito tanto por suas coordenadas (x~1~, x~2~), quanto por um vetor. Por esta razão, daqui para frente, em vez de utilizarmos o termo Exemplos de Treinamento, vamos falar em Vetores de Treinamento (cuja ilustração aparece na Figura 5.2). Da mesma forma, falaremos em **Vetores de Teste** em vez de Exemplos de Teste.
< 
< Para efeito didático, consideraremos um ponto no plano ou um vetor como representações equivalentes, e usaremos sempre a representação mais conveniente para o argumento em questão.
< 
< Por opção metodológica, vamos comparar as MVS com as Redes Neurais, com o propósito de mostrar como algumas das dificuldades mais sérias apresentadas pelas Redes Neurais têm sido superadas com as MVS. Mas, aproveitamos para reafirmar uma constatação empírica mencionada em outra unidade de que em Mineração de Dados não existe um algoritmo que sempre mostre desempenho superior aos demais para qualquer Base de Dados. Muitos autores consideram a Mineração de Dados mais uma arte que uma ciência, porque via de regra é preciso certo traquejo do operador e uma boa dose de experimentos empíricos para melhorar os resultados práticos.
< 
< Aliás, um dos objetivos do curso de **Sistemas Inteligentes**, e especialmente desta unidade, é propiciar experiências que favoreçam o desenvolvimento da sensibilidade indispensável a um usuário competente da **Mineração de Dados**.
---
> Nesta introdução a **Máquinas de Vetores de Suporte** (**MVS**), vamos
> passar a representar um **Exemplo de Treinamento** por um vetor, e o
> **Modelo Aprendido**, por outro vetor, chamado de **Vetor Peso** **w**.
> Qual a vantagem dessa forma de representação? A vantagem é que para
> classificar um Exemplo, bastará fazer o produto de dois vetores, algo
> computacionalmente simples. No contexto de classificação com MVS,
> mostraremos que o resultado dessa multiplicação será sempre ou "+1" ou
> "-1". Dessa forma, por meio da operação de **produto interno** entre
> dois vetores, os **Exemplos de Teste** serão classificados como
> pertencentes ou à classe "y = +1" ou à "y = -1".
> 
> Embora o algoritmo de aprendizado de um Modelo Funcional seja bem
> diferente daqueles algoritmos de aprendizado Orientado a Conhecimento, a
> formalização do problema da classificação continua a mesma. Em termos
> práticos, estamos simplesmente substituindo um módulo de classificação
> por outro, que desempenha a mesma função, possivelmente de forma mais
> complexa, porém com melhores resultados para muitos casos.
> 
> Um classificador binário é equivalente a uma função que faz o mapeamento
> de um conjunto de **atributos de entrada**, agora representados por um
> vetor **X**, em uma das classes "y = +1" ou à "y = -1". Em termos
> matemáticos,
> 
> $y = f\left( \mathbf{x} \right),\ \ \ \ \ \ \ \ \ y \in \left\{ - 1,\  + 1 \right\}\text{\ \ \ \ \ \ \ e\ \ \ \ \ }\mathbf{x} \in \mathbb{R}^{N}$
> (5.1)
> 
> Por exemplo, num plano cartesiano, um ponto
> $\mathbf{x} \in \mathbb{R}^{2}$ pode ser descrito tanto por suas
> coordenadas (x~1~, x~2~), quanto por um vetor. Por esta razão, daqui
> para frente, em vez de utilizarmos o termo Exemplos de Treinamento,
> vamos falar em Vetores de Treinamento (cuja ilustração aparece na Figura
> 5.2. Da mesma forma, falaremos em **Vetores de Teste** em vez de
> Exemplos de Teste.
> 
> Para efeito didático, consideraremos um ponto no plano ou um vetor como
> representações equivalentes, e usaremos sempre a representação mais
> conveniente para o argumento em questão.
> 
> Por opção metodológica, vamos comparar as MVS com as Redes Neurais, com
> o propósito de mostrar como algumas das dificuldades mais sérias
> apresentadas pelas Redes Neurais têm sido superadas com as MVS. Mas,
> aproveitamos para reafirmar uma constatação empírica mencionada em outra
> unidade de que em Mineração de Dados não existe um algoritmo que sempre
> mostre desempenho superior aos demais para qualquer Base de Dados.
> Muitos autores consideram a Mineração de Dados mais uma arte que uma
> ciência, porque via de regra é preciso certo traquejo do operador e uma
> boa dose de experimentos empíricos para melhorar os resultados práticos.
> 
> Aliás, um dos objetivos do curso de **Sistemas Inteligentes**, e
> especialmente desta unidade, é propiciar experiências que favoreçam o
> desenvolvimento da sensibilidade indispensável a um usuário competente
> da **Mineração de Dados**.
2041,2043c3561,3574
< Vamos voltar ao conjunto de dados da flor Íris, porque este exemplo clássico apresenta situações típicas de um problema de classificação real. Olhando a Figura 5.1, nota-se que não há qualquer dificuldade para distinguir a Íris Setosa das Íris Versicolor e Virgínica. Mas a situação é bem diferente quando consideramos a Íris Versicolor com a Virgínica, porque há uma região comum a ambas. Encontrar um classificador que separe linearmente estes dois tipos de Íris constitui uma tarefa nada simples.
< 
< Vamos então dividir o problema em duas partes e considerar inicialmente apenas os tipos Setosa e Versicolor, já que a separação entre ambas parece ser bem mais simples. Com os resultados obtidos para os casos linearmente separáveis, vamos estendê-los aos casos não separáveis linearmente, com algumas adaptações.
---
> Vamos voltar ao conjunto de dados da flor Íris, porque este exemplo
> clássico apresenta situações típicas de um problema de classificação
> real. Olhando a Figura 5.1, nota-se que não há qualquer dificuldade para
> distinguir a Íris Setosa das Íris Versicolor e Virgínica. Mas a situação
> é bem diferente quando consideramos a Íris Versicolor com a Virgínica,
> porque há uma região comum a ambas. Encontrar um classificador que
> separe linearmente estes dois tipos de Íris constitui uma tarefa nada
> simples.
> 
> Vamos então dividir o problema em duas partes e considerar inicialmente
> apenas os tipos Setosa e Versicolor, já que a separação entre ambas
> parece ser bem mais simples. Com os resultados obtidos para os casos
> linearmente separáveis, vamos estendê-los aos casos não separáveis
> linearmente, com algumas adaptações.
2045c3576,3577
< A Figura 5.3 apresenta os dados apenas da Íris Setosa e Versicolor, com vários **classificadores** possíveis. Qual deles devemos escolher?
---
> A Figura 5.3 apresenta os dados apenas da Íris Setosa e Versicolor, com
> vários **classificadores** possíveis. Qual deles devemos escolher?
2049,2057c3581,3628
< Talvez antes de dar uma resposta a esta pergunta, seria oportuno colocar outra questão ainda mais básica. Por que tentar fazer a separação entre as classes usando uma reta e não uma curva que se adapte aos dados? Porque usar uma reta, ou uma função linear para separar classes é matematicamente menos custoso do que outras formas de curvas, ou funções polinomiais, além de tornar o problema do *overfitting* menos provável. A equação de uma reta exige um tratamento matemático simples, resultando num custo computacional mais baixo do que o custo dos polinômios de grau maior ou igual a dois.
< 
< Dentre todas as possibilidades, o classificador azul parece ser o menos indicado porque ele comete vários erros de classificação durante o treinamento. Seu poder de generalização já se mostra antecipadamente comprometido. Mas dentre os restantes, qual deles vai apresentar o melhor desempenho na fase de teste? Ou seja, qual deles tem a melhor capacidade de generalização? Será este o melhor critério a utilizar para escolher um classificador?
< 
< Em outros algoritmos de Aprendizado Supervisionado de Classificadores Lineares, como o Perceptron[^6] (ROSENBLATT, 1957), os três classificadores da Figura 5.3 que não cometem erros de classificação durante o treinamento seriam considerados igualmente bons. Aliás, como na resposta do Perceptron, e das **Redes Neurais** em geral, há um **componente probabilístico**, em cada simulação com o mesmo conjunto de Vetores de Treinamento, qualquer uma das três retas poderia ser escolhida alternadamente como o classificador linear. Para o Perceptron, desde que um classificador linear faça a separação das classes sem cometer erros durante o treinamento, ele é tão bom quanto seus pares que mostrarem o mesmo resultado.
< 
< Para as **MVS**, no entanto, que utilizam um **algoritmo determinístico**, existe um classificador considerado melhor que todos os demais, porque ele possivelmente vai minimizar os erros de classificação na fase de teste. E este classificador é o que maximiza suas margens, tornando-as as mais largas possíveis antes de tocar os primeiros pontos do plano, que representam os **Vetores de Suporte** (Figura 5.4). Note que o **vetor peso** **w**, também conhecido como **vetor normal w**, é perpendicular à reta que representa o classificador. Portanto, conhecendo-se o vetor **w**, a inclinação do classificador estará determinada.
< 
< Note que o classificador vermelho da Figura 5.3, por exemplo, também separaria sem erros as duas classes, mas suas margens não seriam tão largas quanto as mostradas na Figura 5.4. E como encontrar este classificador que maximiza as margens? Primeiramente considerando o conjunto de pontos como um **Conjunto Convexo**, e depois encontrando a menor distância entre eles. A reta de separação, i.e., o classificador, é perpendicular ao menor segmento que une os dois conjuntos.
---
> Talvez antes de dar uma resposta a esta pergunta, seria oportuno colocar
> outra questão ainda mais básica. Por que tentar fazer a separação entre
> as classes usando uma reta e não uma curva que se adapte aos dados?
> Porque usar uma reta, ou uma função linear para separar classes é
> matematicamente menos custoso do que outras formas de curvas, ou funções
> polinomiais, além de tornar o problema do *overfitting* menos provável.
> A equação de uma reta exige um tratamento matemático simples, resultando
> num custo computacional mais baixo do que o custo dos polinômios de grau
> maior ou igual a dois.
> 
> Dentre todas as possibilidades, o classificador azul parece ser o menos
> indicado porque ele comete vários erros de classificação durante o
> treinamento. Seu poder de generalização já se mostra antecipadamente
> comprometido. Mas dentre os restantes, qual deles vai apresentar o
> melhor desempenho na fase de teste? Ou seja, qual deles tem a melhor
> capacidade de generalização? Será este o melhor critério a utilizar para
> escolher um classificador?
> 
> Em outros algoritmos de Aprendizado Supervisionado de Classificadores
> Lineares, como o Perceptron[^6] (Rosenblatt, 1957), os três
> classificadores da Figura 5.3 que não cometem erros de classificação
> durante o treinamento seriam considerados igualmente bons. Aliás, como
> na resposta do Perceptron, e das **Redes Neurais** em geral, há um
> **componente probabilístico**, em cada simulação com o mesmo conjunto de
> Vetores de Treinamento, qualquer uma das três retas poderia ser
> escolhida alternadamente como o classificador linear. Para o Perceptron,
> desde que um classificador linear faça a separação das classes sem
> cometer erros durante o treinamento, ele é tão bom quanto seus pares que
> mostrarem o mesmo resultado.
> 
> Para as **MVS**, no entanto, que utilizam um **algoritmo
> determinístico**, existe um classificador considerado melhor que todos
> os demais, porque ele possivelmente vai minimizar os erros de
> classificação na fase de teste. E este classificador é o que maximiza
> suas margens, tornando-as as mais largas possíveis antes de tocar os
> primeiros pontos do plano, que representam os **Vetores de Suporte**
> (Figura 5.4). Note que o **vetor peso** **w**, também conhecido como
> **vetor normal w**, é perpendicular à reta que representa o
> classificador. Portanto, conhecendo-se o vetor **w**, a inclinação do
> classificador estará determinada.
> 
> Note que o classificador vermelho da Figura 5.3, por exemplo, também
> separaria sem erros as duas classes, mas suas margens não seriam tão
> largas quanto as mostradas na Figura 5.4. E como encontrar este
> classificador que maximiza as margens? Primeiramente considerando o
> conjunto de pontos como um **Conjunto Convexo**, e depois encontrando a
> menor distância entre eles. A reta de separação, i.e., o classificador,
> é perpendicular ao menor segmento que une os dois conjuntos.
2064,2066c3635,3642
< Se conectarmos cada ponto de um conjunto aos demais pontos restantes, o polígono externo que resulta será um polígono convexo, e o conjunto de pontos delimitados por este polígono será chamado de **conjunto convexo**.
< 
< A Figura 5.5 mostra como as duas classes de Vetores de Treinamento podem ser representadas por dois conjuntos convexos (com as conexões dos pontos internos omitidas para tornar mais clara a apresentação).
---
> Se conectarmos cada ponto de um conjunto aos demais pontos restantes, o
> polígono externo que resulta será um polígono convexo, e o conjunto de
> pontos delimitados por este polígono será chamado de **conjunto
> convexo**.
> 
> A Figura 5.5 mostra como as duas classes de Vetores de Treinamento podem
> ser representadas por dois conjuntos convexos (com as conexões dos
> pontos internos omitidas para tornar mais clara a apresentação).
2070,2076c3646,3670
< A vantagem de se considerar as classes como se fossem dois conjuntos convexos é que na busca pelo menor segmento que une estes dois conjuntos, não ocorre o problema do **mínimo local**. Enquanto a distância entre ambos estiver diminuindo, a direção seguida estará correta.
< 
< A analogia para este procedimento é que o **Algoritmo de Aprendizado** pode ser visto como um método de otimização[^7] de uma **Função Custo**. A cada iteração do processo de aprendizado a Função Custo é avaliada e, se seu valor decrescer, os pesos do vetor peso **w** são atualizados. O processo continua até encontrar o valor mínimo.
< 
< Esta forma de otimização produz bons resultados quando a Função Custo não apresenta mínimos locais, i.e., quando há apenas um **mínimo global**. No caso das Redes Neurais, geralmente a Função Custo apresenta mínimos locais, o que obriga a adoção de mecanismos mais complexos de otimização, como manter alguns registros do que se acredita ser o mínimo global atual, e continuar atualizando os pesos do vetor **w** mesmo que a Função Custo esteja aumentando (Figura 5.6).
< 
< Se um novo mínimo for encontrado, os registros antigos são apagados e novos valores de peso são adotados. Embora este procedimento heurístico aumente as possibilidades de detectar o mínimo global, não há nenhuma garantia de que ele será encontrado, a menos que se pague um alto custo computacional com uma busca exaustiva.
---
> A vantagem de se considerar as classes como se fossem dois conjuntos
> convexos é que na busca pelo menor segmento que une estes dois
> conjuntos, não ocorre o problema do **mínimo local**. Enquanto a
> distância entre ambos estiver diminuindo, a direção seguida está
> correta.
> 
> A analogia para este procedimento é que o **Algoritmo de Aprendizado**
> pode ser visto como um método de otimização[^7] de uma **Função Custo**.
> A cada iteração do processo de aprendizado a Função Custo é avaliada e,
> se seu valor decrescer, os pesos do vetor peso **w** são atualizados. O
> processo continua até encontrar o valor mínimo.
> 
> Esta forma de otimização produz bons resultados quando a Função Custo
> não apresenta mínimos locais, i.e., quando há apenas um **mínimo
> global**. No caso das Redes Neurais, geralmente a Função Custo apresenta
> mínimos locais, o que obriga a adoção de mecanismos mais complexos de
> otimização, como manter alguns registros do que se acredita ser o mínimo
> global atual, e continuar atualizando os pesos do vetor **w** mesmo que
> a Função Custo esteja aumentando (Figura 5.5).
> 
> Se um novo mínimo for encontrado, os registros antigos são apagados e
> novos valores de peso são adotados. Embora este procedimento heurístico
> aumente as possibilidades de detectar o mínimo global, não há nenhuma
> garantia de que ele será encontrado, a menos que se pague um alto custo
> computacional com uma busca exaustiva.
2085,2087c3679,3696
< Se as duas classes não forem linearmente separáveis, a teoria de MVS prevê o mapeamento dos pontos do **Espaço de Entrada** para outro espaço de maior dimensão, conhecido como **Espaço de Característica**. A Figura 5.7 mostra uma situação em que os dados não podem ser linearmente separados. Para fazer a separação entre ambas podemos usar não uma reta, mas uma curva descrita por uma função polinomial, ou tentar um recurso matemático conhecido como "**Truque do Núcleo**" ou *"**Kernel Trick**"*.
< 
< O uso de funções polinomiais, além de apresentar risco de alto custo computacional, pode favorecer o ajuste excessivo da curva polinomial aos Vetores de Treinamento, podendo então ocorrer problemas de ***overfitting*** decorrentes da **instabilidade** causada pela enorme influência que um ou outro vetor pode ter sobre a curva polinomial. Já o princípio de **margem máxima** das MVS traz mais **estabilidade** na classificação, diminuindo as chances de *overfitting*. Para entender melhor este comportamento, vamos primeiramente ver o que significa usar um *kernel*[^8].
---
> Se as duas classes não forem linearmente separáveis, a teoria de MVS
> prevê o mapeamento dos pontos do **Espaço de Entrada** para outro espaço
> de maior dimensão, conhecido como **Espaço de Característica**. A Figura
> 5.7 mostra uma situação em que os dados não podem ser linearmente
> separados. Para fazer a separação entre ambas podemos usar não uma reta,
> mas uma curva descrita por uma função polinomial, ou tentar um recurso
> matemático conhecido como "**Truque do Núcleo**" ou *"**Kernel
> Trick**"*.
> 
> O uso de funções polinomiais, além de apresentar risco de alto custo
> computacional, pode favorecer o ajuste excessivo da curva polinomial aos
> Vetores de Treinamento, podendo então ocorrer problemas de
> ***overfitting*** decorrente da **instabilidade** causada pela enorme
> influência que um ou outro vetor pode ter sobre a curva polinomial. Já o
> princípio de **margem máxima** das MVS traz mais **estabilidade** na
> classificação, diminuindo as chances de *overfitting*. Para entender
> melhor este comportamento, vamos primeiramente ver o que significa usar
> um *kernel*[^8].
2091,2109c3700,3765
< A ideia por trás dos *kernels* é mapear os Vetores num espaço de dimensão mais elevada que a original. Por exemplo, se o espaço original dos Vetores de Entrada for bidimensional, podemos introduzir algumas redundâncias em suas coordenadas e mapear estes mesmos vetores num espaço tridimensional. Qual o propósito disso? É que duas classes não separáveis linearmente num espaço bidimensional podem se tornar linearmente separáveis num espaço tridimensional, como ilustra a Figura 5.8.
< 
< Figura . -- Transformação Não Linear do Espaço de Entrada para o Espaço de Características.
< 
< Essa transformação em que os vetores são representados num espaço de dimensão mais elevada, geralmente é uma transformação não linear ϕ(**x**). O espaço de partida dessa transformação não linear é conhecido como **Espaço de Entrada** e o espaço com dimensão mais alta é conhecido como **Espaço de Características**.
< 
< O que se busca com esta transformação é linearizar o Espaço de Características, e com isso tornar os dados linearmente separáveis. Pode parecer paradoxal, mas através de uma transformação não linear é possível linearizar o Espaço de Características.
< 
< Vamos reproduzir um exemplo, apresentado por (SCHÖLKOPF & SMOLA, 2001), ilustrando como esta transformação não linear pode ser feita. Suponha um **Espaço de Entrada** **bidimensional**, composto por duas classes não separáveis linearmente. Aplicando-se o truque do *kernel*, vamos mapear esses dados num **Espaço de Características tridimensional**, como ilustrado na Figura 5.9.
< 
< Observando-se o resultado da operação mostrada na Figura 5.9, verifica-se que a **transformação não linear** ϕ(**x**) não criou novas variáveis; ainda estamos trabalhando com x~1~ e x~2~ no início e no fim da transformação. As variáveis z~1~, z~2~ e z~3~ são apenas elementos intermediários que ajudam no entendimento da transformação operada nos dados. Isso significa que não será necessário computar explicitamente a transformação ϕ(**x**) para obtermos no Espaço de Entrada resultados semelhantes àqueles que obteríamos se as operações tivessem sido feitas no Espaço de Características.
< 
< Figura . -- Exemplo de Transformação Não Linear do Espaço de Entrada para o Espaço de Características.
< 
< O **truque do *kernel*** permite que as operações de **produto interno** entre dois vetores no Espaço de Características sejam computadas como se ainda estivéssemos no Espaço de Entrada. Como, para efeitos práticos, não houve efetivamente aumento da dimensão do espaço onde ocorrem as operações de produto interno, o truque do *kernel* oferece a possibilidade de escapar das complicações que as operações no Espaço de Características poderiam trazer. Por isso, os matemáticos dizem que *kernels* podem ajudar a fugir da **Praga da Dimensionalidade**.
< 
< Existem vários *kernels* conhecidos (*Polynomial*, RBF etc.), alguns desenvolvidos para aplicações específicas, como *kernels* para bioinformática, para classificação de imagens ou caracteres etc. Como as MVS se enquadram no paradigma do aprendizado supervisionado, isso significa que existe um Conjunto de Vetores de Treinamento, cujos rótulos de classe são previamente conhecidos. Portanto, com um pouco de teoria e uma dose de experimentação é possível desenvolver *kernels* que aumentem a taxa de sucesso durante o treinamento.
< 
< Se o Conjunto de Treinamento for uma amostra representativa dos Vetores de Teste, então uma alta taxa de sucesso no treinamento possivelmente significará boa capacidade de generalização para o teste. Caso contrário, não será possível fazer previsões confiáveis com relação à taxa de sucesso nos testes.
---
> A ideia por trás dos *kernels* é mapear os Vetores num espaço de
> dimensão mais elevada que a original. Por exemplo, se o espaço original
> dos Vetores de Entrada for bidimensional, podemos introduzir algumas
> redundâncias em suas coordenadas e mapear estes mesmos vetores num
> espaço tridimensional. Qual o propósito disso? É que duas classes não
> separáveis linearmente num espaço bidimensional podem se tornar
> linearmente separáveis num espaço tridimensional, como ilustra a Figura
> 5.8.
> 
> Figura . -- Transformação Não Linear do Espaço de Entrada para o Espaço
> de Características.
> 
> Essa transformação em que os vetores são representados num espaço de
> dimensão mais elevada, geralmente é uma transformação não linear
> ϕ(**x**). O espaço de partida dessa transformação não linear é conhecido
> como **Espaço de Entrada** e o espaço com dimensão mais alta é conhecido
> como **Espaço de Características**.
> 
> O que se busca com esta transformação é linearizar o Espaço de
> Características, e com isso tornar os dados linearmente separáveis. Pode
> parecer paradoxal, mas através de uma transformação não linear é
> possível linearizar o Espaço de Características.
> 
> Vamos reproduzir um exemplo, apresentado por (Schölkopt & Smola, 2001),
> ilustrando como esta transformação não linear pode ser feita. Suponha um
> **Espaço de Entrada** **bidimensional**, composto por duas classes não
> separáveis linearmente. Aplicando-se o truque do *kernel*, vamos mapear
> esses dados num **Espaço de Características tridimensional**, como
> ilustrado na Figura 5.9.
> 
> Observando-se o resultado da operação mostrada na Figura 5.9,
> verifica-se que a **transformação não linear** ϕ(**x**) não criou novas
> variáveis; ainda estamos trabalhando com x~1~ e x~2~ no início e no fim
> da transformação. As variáveis z~1~, z~2~ e z~3~ são apenas elementos
> intermediários que ajudam no entendimento da transformação operada nos
> dados. Isso significa que não será necessário computar explicitamente a
> transformação ϕ(**x**) para obtermos no Espaço de Entrada resultados
> semelhantes àqueles que obteríamos se as operações tivessem sido feitas
> no Espaço de Características.
> 
> Figura . -- Transformação Não Linear do Espaço de Entrada para o Espaço
> de Características.
> 
> O **truque do *kernel*** permite que as operações de **produto interno**
> entre dois vetores no Espaço de Características sejam computadas como se
> ainda estivéssemos no Espaço de Entrada. Como, para efeitos práticos,
> não houve efetivamente aumento da dimensão do espaço onde ocorrem as
> operações de produto interno, o truque do *kernel* oferece a
> possibilidade de escapar das complicações que as operações no Espaço de
> Características poderiam trazer. Por isso, os matemáticos dizem que
> *kernels* podem permitir fugir da **Praga da Dimensionalidade**.
> 
> Existem vários *kernels* conhecidos (*Polynomial*, RBF etc.), alguns
> desenvolvidos especialmente para aplicações específicas, como *kernels*
> para bioinformática, para classificação de imagens ou caracteres etc.
> Como as MVS se enquadram no paradigma do aprendizado supervisionado,
> isso significa que existe um Conjunto de Vetores de Treinamento, cujos
> rótulos de classe são previamente conhecidos. Portanto, com um pouco de
> teoria e uma dose de experimentação é possível desenvolver *kernels* que
> aumentem a taxa de sucesso durante o treinamento.
> 
> Se o Conjunto de Treinamento for uma amostra representativa dos Vetores
> de Teste, então uma alta taxa de sucesso no treinamento possivelmente
> significará boa capacidade de generalização para o teste. Caso
> contrário, não será possível fazer previsões confiáveis com relação à
> taxa de sucesso nos testes.
2114,2116c3770,3809
< Há casos porém em que mesmo com a linearização do Espaço de Características, obtida com o truque do *kernel*, as classes continuarão não separáveis linearmente. O que fazer nessa situação?
< 
< A solução adotada pelas MVS foi criar uma "**margem suave**" que admite ruídos, mas estabelece uma penalidade para cada caso de classificação equivocada. Considere um parâmetro ***C***, chamado de **Parâmetro de Complexidade *C***, que aplica uma pena a cada vetor classificado erroneamente. A Figura 5.10 ilustra diversas situações envolvendo violações das bordas de classificação.
---
> Há casos porém em que mesmo com a linearização do Espaço de
> Características, obtida com o truque do *kernel*, as classes continuarão
> não separáveis linearmente. O que fazer nessa situação?
> 
> A solução adotada pelas MVS foi criar uma "**margem suave**" que admite
> ruídos, mas estabelece uma penalidade para cada caso de classificação
> equivocada. Considere um parâmetro ***C***, chamado de **Parâmetro de
> Complexidade *C***, que aplica uma pena a cada vetor classificado
> erroneamente. A Figura 5.10 ilustra diversas situações envolvendo
> violações das bordas de classificação.
> 
> Se considerarmos primeiramente as margens verdes tracejadas do
> Classificador da Figura 5.10, notamos que embora os vetores 1 e 2 tenham
> violado os limites das margens verdes, eles estão classificados do lado
> correto do plano. Os vetores 3, 4 e 5, por sua vez, estão do lado oposto
> ao que deveriam estar. Portanto, a penalização para estes casos
> distintos deve ser diferenciada, de acordo com a distância da margem.
> 
> O ajuste do **parâmetro C** ajuda a encontrar um **compromisso entre a
> tolerância a vetores classificados erroneamente** devido a margens
> amplas (valor de C baixo) **e a minimização dos erros de treinamento**
> (valor de C alto, e margens estreitas). As margens verdes correspondem a
> um Fator de Complexidade C baixo (\~1), enquanto que as margens
> vermelhas correspondem a um valor de C alto (\~10).
> 
> Note que a minimização dos erros de treinamento nem sempre é uma
> garantia de elevada taxa de sucesso na fase de testes. Isso depende de
> quão representativo é o Conjunto de Treinamento com relação ao Conjunto
> de Teste, e do *kernel* escolhido. Para encontrar o melhor valor de C,
> geralmente são coletados vários resultados empíricos usando o método da
> *Cross-validation*.
> 
> A Figura 5.10 ainda ilustra o fato de que, uma vez encontrado a reta de
> separação dos dados, apenas os Vetores de Suporte (aqueles pontos que
> tocam as margens) passam a ter importância para a fase de testes. Todos
> os demais Vetores de Treinamento podem ser desconsiderados porque eles
> não têm qualquer influência sobre as margens. A implicação desse fato
> para o desempenho do classificador é decisiva, uma vez que para
> classificar um novo ponto no plano, basta considerar os Vetores de
> Suporte, que são os delimitadores das margens.
2118,2126c3811,3812
< Se considerarmos primeiramente as margens verdes tracejadas do Classificador da Figura 5.10, notamos que embora os vetores 1 e 2 tenham violado os limites das margens verdes, eles estão classificados do lado correto do plano. Os vetores 3, 4 e 5, por sua vez, estão do lado oposto ao que deveriam estar. Portanto, a penalização para estes casos distintos deve ser diferenciada, de acordo com a distância da margem.
< 
< O ajuste do **parâmetro C** ajuda a encontrar um **compromisso entre a tolerância a vetores classificados erroneamente** devido a margens amplas (valor de C baixo) **e a minimização dos erros de treinamento** (valor de C alto, e margens estreitas). As margens verdes correspondem a um Fator de Complexidade C baixo (\~1), enquanto que as margens vermelhas correspondem a um valor de C alto (\~10).
< 
< Note que a minimização dos erros de treinamento nem sempre é uma garantia de elevada taxa de sucesso na fase de testes. Isso depende de quão representativo é o Conjunto de Treinamento com relação ao Conjunto de Teste, e do *kernel* escolhido. Para encontrar o melhor valor de C, geralmente são coletados vários resultados empíricos usando o método da *Cross-validation*.
< 
< A Figura 5.10 ainda ilustra o fato de que, uma vez encontrado a reta de separação dos dados, apenas os Vetores de Suporte (aqueles pontos que tocam as margens) passam a ter importância para a fase de testes. Todos os demais Vetores de Treinamento podem ser desconsiderados porque eles não têm qualquer influência sobre as margens. A implicação desse fato para o desempenho do classificador é decisiva, uma vez que para classificar um novo ponto no plano, basta considerar os Vetores de Suporte, que são os delimitadores das margens.
< 
< Figura . -- Diferentes Margens com Diferentes Capacidades de Generalização.
---
> Figura . -- Diferentes Margens com Diferentes Capacidades de
> Generalização.
2131c3817,3820
< Vamos agora, de forma sucinta, dar uma ideia de como as bordas de decisão de uma MVS podem ser obtidas matematicamente num espaço bidimensional. Considere o plano cartesiano da Figura 5.11 e os respectivos vetores **x** e **w**.
---
> Vamos agora, de forma sucinta, dar uma ideia de como as bordas de
> decisão de uma MVS podem ser obtidas matematicamente num espaço
> bidimensional. Considere o plano cartesiano da Figura 5.11 e os
> respectivos vetores **x** e **w**.
2135c3824,3830
< O Produto Interno de dois vetores, também chamado de Produto Escalar ou Produto de Ponto, gera como resultado uma grandeza escalar, ou seja, um número real. Para sua representação, podemos usar tanto um ponto, w⋅x, quanto os sinais de maior e menor, \<w,x\>. As letras em negrito representam um vetor, enquanto que as letras simples representam uma grandeza escalar. Usando Produto Escalar, qualquer segmento de reta pode ser representado no plano da forma mostrada na Figura 5.12.
---
> O Produto Interno de dois vetores, também chamado de Produto Escalar ou
> Produto de Ponto, gera como resultado uma grandeza escalar, ou seja, um
> número real. Para sua representação, podemos usar tanto um ponto, w⋅x,
> quanto os sinais de maior e menor, \<w,x\>. As letras em negrito
> representam um vetor, enquanto que as letras simples representam uma
> grandeza escalar. Usando Produto Escalar, qualquer segmento de reta pode
> ser representado no plano da forma mostrada na Figura 5.12.
2139,2141c3834,3835
< Para representar uma reta e suas margens, usamos o mesmo procedimento (Figura 5.13).
< 
< Figura . - Equação do Classificador e Margens.
---
> Para representar uma reta e suas margens, usamos o mesmo procedimento
> (Figura 5.13).
2143c3837,3840
< Como estamos interessados em maximizar as margens, ou seja, tornar o módulo da subtração de **x~1~** por **x~2~**, \|\|**x~1~** - **x~2~**\|\|, o mais largo possível, isso equivale a minimizar o módulo do vetor peso **w**, já que
---
> Como estamos interessados em maximizar as margens, ou seja, tornar
> módulo da subtração de **x~1~** por **x~2~**, \|\|**x~1~** -
> **x~2~**\|\|, o mais largo possível, isso equivale a minimizar o módulo
> do vetor peso **w**, já que
2147c3844,3845
< A Equação mostra que quanto menor o módulo de **w**, mais largas serão as margens!
---
> A Equação mostra que quanto menor o módulo de **w**, mais largas serão
> as margens!
2149c3847
< Dessa forma, a **Função de Aprendizado** de uma MVS consiste em "testar" coordenadas para **w** de tal modo que seu módulo decresça a um mínimo, fazendo com que as margens se alarguem, até o limite em que elas toquem os primeiros Vetores de Treinamento nas bordas de decisão. Quando isso ocorrer, estes Vetores de Treinamento que foram atingidos pelas margens do Classificador, se tornam os **Vetores de Suporte** da MVS.
---
> Figura . -- Equação do Classificador e Margens.
2151c3849,3860
< Existem técnicas matemáticas de otimização deste problema, por exemplo a **Programação Quadrática**, bastante conhecida entre os matemáticos, e que foram aproveitadas por (CORTES & VAPNIK, 1995) para desenvolver o algoritmo da MVS. Sucintamente o problema pode ser formalizado da forma exposta a seguir.
---
> Dessa forma, a **Função de Aprendizado** de uma MVS consiste em "testar"
> coordenadas para **w** de tal modo que seu módulo decresça a um mínimo,
> fazendo com que as margens se alarguem, até o limite em que elas toquem
> os primeiros Vetores de Treinamento nas bordas de decisão. Quando isso
> ocorrer, estes Vetores de Treinamento que foram atingidos pelas margens
> do Classificador, se tornam os **Vetores de Suporte** da MVS.
> 
> Existem técnicas matemáticas de otimização deste problema, por exemplo a
> **Programação Quadrática**, bastante conhecida entre os matemáticos, e
> que foram aproveitadas por (Cortes & Vapnik, 1995) para desenvolver o
> algoritmo da MVS. Sucintamente o problema pode ser formalizado da forma
> exposta a seguir.
2153c3862,3863
< Dado um **Conjunto de Treinamento**: (**x~1~**, y~1~), (**x~2~**, y~2~) \... (**x~N~**, y~N~)
---
> Dado um **Conjunto de Treinamento**: (**x~1~**, y~1~), (**x~2~**, y~2~)
> \... (**x~N~**, y~N~)
2155c3865,3866
< O **Hiperplano com Margem Máxima** é definido pelo par (**w**, b) que resolve o seguinte problema:
---
> O **Hiperplano com Margem Máxima** é definido pelo par (**w**, b) que
> resolve o seguinte problema:
2161,2163c3872,3891
< Mais detalhes de como solucionar a forma dual desse problema de Programação Quadrática podem ser obtidos na Referência Bibliográfica desta unidade de estudo.
< 
< Há uma interessante implementação de MVS, proposta por (PLATT, 1998), conhecida como **SMO** *(Sequential Minimal Optimization)*, que em vez de considerar todos os Vetores de Treinamento conjuntamente, eles são divididos em pares e seus valores ótimos são deduzidos analiticamente. Embora o número de operações matemáticas aumente com relação à forma mais tradicional de resolver numericamente o problema com um sistema de equações, estas operações matemáticas da forma analítica são simples, operações aritméticas básicas, e portanto muito rápidas num computador. Dessa forma, o ganho no tempo total de computação pode ser significativo.
---
> Mais detalhes de como solucionar a forma dual desse problema de
> Programação Quadrática podem ser obtidos na Referência Bibliográfica
> desta unidade de estudo.
> 
> Há uma interessante implementação de MVS, proposta por (Platt, 1998),
> conhecida como **SMO** *(Sequential Minimal Optimization)*, que em vez
> de considerar todos os Vetores de Treinamento conjuntamente, eles são
> divididos em pares e seus valores ótimos são deduzidos analiticamente.
> Embora o número de operações matemáticas aumente com relação à forma
> mais tradicional de resolver numericamente o problema com um sistema de
> equações, estas operações matemáticas da forma analítica são simples,
> operações aritméticas básicas, e portanto muito rápidas num computador.
> Dessa forma, o ganho no tempo total de computação pode ser
> significativo.
> 
> Outro atrativo muito interessante da implementação SMO é que não é
> necessário carregar simultaneamente todos os Vetores de Treinamento na
> memória principal do computador. Considerando aplicações reais, com
> centenas de milhares ou milhões de Vetores de Treinamento, o algoritmo
> SMO pode ser o mais indicado.
2165,2167c3893
< Outro atrativo muito interessante da implementação SMO é que não é necessário carregar simultaneamente todos os Vetores de Treinamento na memória principal do computador. Considerando aplicações reais, com centenas de milhares ou milhões de Vetores de Treinamento, o algoritmo SMO pode ser o mais indicado.
< 
< Como Visualizar as Bordas Decisão de uma SVM Usando o Weka
---
> Como Visualizar as Bordas Decisão de uma MVS Usando o Weka
2170c3896,3900
< A ferramenta Weka (Weka, 2013) permite rodar várias implementações de **SVM**, ajustar o **Parâmetro de Complexidade C**, entre outros, e visualizar as **Bordas de Decisão** obtidas.**\
---
> A ferramenta Weka (Weka, 2013) permite rodar várias implementações de
> **SVM**, ajustar o **Parâmetro de Complexidade C**, entre outros, e
> visualizar as **Bordas de Decisão** obtidas.
> 
> **\
2173c3903,3907
< **Passo 1 -** Primeiramente vamos carregar o arquivo "iris.arff" no Weka e eliminar dois de seus Atributos, para tornar os resultados visualmente mais interessantes. Carregue no "Weka Explorer" o arquivo "íris.arff", selecione os Atributos "sepallength" e "sepalwidth", e dê um clique em "Remove", como mostra a Figura 5.14.
---
> **Passo 1 -** Primeiramente vamos carregar o arquivo "iris.arff" no Weka
> e eliminar dois de seus Atributos, para tornar os resultados visualmente
> mais interessantes. Carregue no "Weka Explorer" o arquivo "íris.arff"
> (anexo), selecione os Atributos "sepallength" e "sepalwidth", e dê um
> clique em "Remove", como mostra a Figura 5.14.
2175c3909,3910
< ![](./media/image43.png){width="4.222916666666666in" height="3.1680555555555556in"}
---
> ![](media/image43.png){width="4.222916666666666in"
> height="3.1680555555555556in"}
2179c3914,3915
< Salve o novo arquivo com o nome "iris_mod.arff", dando um clique no botão "Save\..." (no canto superior direito do "Weka Explorer").
---
> Salve o novo arquivo com o nome "iris_mod.arff", dando um clique no
> botão "Save\..." (no canto superior direito do "Weka Explorer").
2184c3920,3922
< **Passo 2** -- Vamos abrir o arquivo modificado "íris_mod.arff" no "Weka GUI Chooser" (Figura 5.15), clicando primeiro na opção "Vizualization" e depois em "BoundaryVisualizer".
---
> **Passo 2** -- Vamos abrir o arquivo modificado "íris_mod.arff" no "Weka
> GUI Chooser" (Figura 5.15), clicando primeiro na opção "Vizualization" e
> depois em "BoundaryVisualizer".
2186c3924
< ![](./media/image45.png){width="2.3402777777777777in" height="1.4in"}
---
> ![](media/image45.png){width="2.3402777777777777in" height="1.4in"}
2190c3928,3930
< ![](./media/image47.png){width="4.722916666666666in" height="4.947916666666667in"}Uma janela semelhante à mostrada na Figura 5.16 deve aparecer.
---
> ![](media/image47.png){width="4.722916666666666in"
> height="4.947916666666667in"}Uma janela semelhante à mostrada na Figura
> 5.16 deve aparecer.
2194c3934,3940
< **Passo 3** -- Clique no Botão "Open File", localize o arquivo "íris_mod.arff" e carregue no "BoundaryVisualizer. Os Vetores de Treinamento (representados por pontos) devem aparecer na tela de visualização do "BoundaryVisualizer" (Figura 5.17). (Como o "BoundaryVisualizer" leva em conta os ajustes da última vez em que ele foi utilizado, a imagem que aparece na tela pode variar de simulação para simulação.) .
---
> **Passo 3** -- Clique no Botão "Open File", localize o arquivo
> "íris_mod.arff" e carregue no "BoundaryVisualizer. Os Vetores de
> Treinamento (representados por pontos) devem aparecer na tela de
> visualização do "BoundaryVisualizer" (Figura 5.17). (Como o
> "BoundaryVisualizer" leva em conta os ajustes da última vez em que ele
> foi utilizado, a imagem que aparece na tela pode variar de simulação
> para simulação.) .
2196c3942,3943
< ![](./media/image49.png){width="4.815972222222222in" height="4.827083333333333in"}
---
> ![](media/image49.png){width="4.815972222222222in"
> height="4.827083333333333in"}
2198c3945,3946
< Figura . -- Dados do Arquivo "íris_mod.arff" na Tela do "BoundaryVizualizer.
---
> Figura . -- Dados do Arquivo "íris_mod.arff" na Tela do
> "BoundaryVizualizer.
2203c3951,3954
< **Passo 4** -- Na parte superior direita, em "Classifier", clique em "Choose" (Figura 5.17), escolha "Classifiers" , depois "functions" e, finalmente "SMO", como ilustra a Figura 5.18. Inicialmente deixe os valores default do SMO.
---
> **Passo 4** -- Na parte superior direita, em "Classifier", clique em
> "Choose" (Figura 5.17), escolha "Classifiers" , depois "functions" e,
> finalmente "SMO", como ilustra a Figura 5.18. Inicialmente deixe os
> valores default do SMO.
2205c3956
< ![](./media/image51.png){width="5.23125in" height="5.229861111111111in"}
---
> ![](media/image51.png){width="5.23125in" height="5.229861111111111in"}
2209c3960,3974
< Marque a opção "Plot training data" (Figura 5.18), na parte inferior direita, para que ao final da simulação apareçam não apenas as bordas de decisão do classificador, mas também os dados usados no treinamento. Dê um clique em "Start" (Figura 5.18).
---
> Marque a opção "Plot training data" (Figura 5.18), na parte inferior
> direita, para que ao final da simulação apareçam não apenas as bordas de
> decisão do classificador, mas também os dados usados no treinamento. Dê
> um clique em "Start" (Figura 5.18).
> 
> Lentamente as bordas de decisão do classificador vão se formando,
> enquanto uma linha horizontal corre a tela indicando que a simulação
> está em progresso.
> 
> **Passo 5** -- O número de Vetores de Treinamento classificados
> erroneamente deve ser em torno de 6. Vá com o mouse novamente na parte
> superior direita do "BoundaryVisualizer" e clique com o botão da
> esquerda sobre a palavra "SMO", ao lado de "Choose", no campo
> "Classifieres". Uma janela de ajustes dos parâmetros do SMO, semelhante
> à mostrada na Figura 5.19, deve se abrir.
2211,2215c3976,3977
< Lentamente as bordas de decisão do classificador vão se formando, enquanto uma linha horizontal corre a tela indicando que a simulação está em progresso.
< 
< **Passo 5** -- O número de Vetores de Treinamento classificados erroneamente deve ser em torno de 6. Vá com o mouse novamente na parte superior direita do "BoundaryVisualizer" e clique com o botão da esquerda sobre a palavra "SMO", ao lado de "Choose", no campo "Classifieres". Uma janela de ajustes dos parâmetros do SMO, semelhante à mostrada na Figura 5.19, deve se abrir.
< 
< ![](./media/image53.png){width="3.861111111111111in" height="4.602083333333334in"}
---
> ![](media/image53.png){width="3.861111111111111in"
> height="4.602083333333334in"}
2219c3981,3982
< Nesta janela, no botão "More" há uma explicação sucinta de todos parâmetros mostrados.
---
> Nesta janela, no botão "More" há uma explicação sucinta de todos
> parâmetros mostrados.
2224c3987,3991
< **Passo 6 --** Faça novas simulações alterando o valor default do Parâmetro de Complexidade C de 1.0 para 2.0, 5.0, 30.0 etc. e confira o número de Vetores de Treinamento que continuam classificados erroneamente. Com ajuste de C = 2.0 e kernel "PolyKernel" foi rodada uma simulação, cujos resultados são mostrados na Figura 5.20.
---
> **Passo 6 --** Faça novas simulações variando o valor default do
> Parâmetro de Complexidade C de 1.0 para 2.0, 5.0, 30.0 etc. e confira o
> número de Vetores de Treinamento que continuam classificados
> erroneamente. Com ajuste de C = 2.0 e kernel "PolyKernel" foi rodada uma
> simulação, cujos resultados são mostrados na Figura 5.20.
2226c3993
< ![](./media/image55.png){width="3.75in" height="2.5in"}
---
> ![](media/image55.png){width="3.75in" height="2.5in"}
2228c3995,3996
< Figura . -- Bordas de Decisão da Simulação para C = 2.0 e Kernel "PolyKernel".
---
> Figura . -- Bordas de Decisão da Simulação para C = 2.0 e kernel
> "PolyKernel".
2230c3998,3999
< Quando o valor do parâmetro C foi alterado para 91, as Bordas de Decisão se alteraram, como mostra a Figura 5.21.
---
> Quando o valor do parâmetro C foi alterado para 91, as Bordas de Decisão
> se alteraram, como mostra a Figura 5.21.
2232c4001
< ![](./media/image56.png){width="4.0in" height="2.5in"}
---
> ![](media/image56.png){width="4.0in" height="2.5in"}
2234c4003,4004
< Figura . -- Bordas de Decisão da Simulação para C = 91 e Kernel "PolyKernel".
---
> Figura . -- Bordas de Decisão da Simulação para C = 2.0 e kernel
> "PolyKernel".
2236c4006,4010
< Como pode ser observado, há dois ou três pontos verdes e azuis que se parecem com "outliers". Vamos retirar alguns deles, ativando a opção "Remove points" (Figura 5.21), e ver como a Borda de Decisão se altera. A Figura 5.22 mostra o resultado da remoção de alguns pontos azuis da tela, usando o botão esquerdo do mouse.
---
> Como pode ser observado, há dois ou três pontos verdes e azuis que se
> parecem com "outliers". Vamos retirar alguns deles, ativando a opção
> "Remove points" (Figura 5.21), e ver como a Borda de Decisão se altera.
> A Figura 5.22 mostra o resultado da remoção de alguns pontos azuis da
> tela, usando o botão esquerdo do mouse.
2238c4012
< ![](./media/image58.png){width="4.8in" height="4.814583333333333in"}
---
> ![](media/image58.png){width="4.8in" height="4.814583333333333in"}
2242c4016,4018
< Como pode ser observado na Figura 5.22, a Borda de Decisão superior sofreu uma alteração significativa, mostrando que Vetores de Treinamento próximos das Margens têm um peso muito grande nos resultados obtidos.
---
> Como pode ser observado na Figura 5.22, a Borda de Decisão superior
> sofreu uma alteração significativa, mostrando que Vetores de Treinamento
> próximos das Margens têm um peso muito grande nos resultados obtidos.
2247c4023,4027
< **Passo 7** -- Novos kernels podem ser escolhidos entre os ajustes do SMO. As cores do painel do "BoundaryVisualizer" podem ser alteradas, clicando sobre os nomes das três "iris" no campo intermediário "Class color". Outros ajustes interessantes podem ser feitos no "BoundaryVisualizer" e testados em novas simulações. Bom trabalho!
---
> **Passo 7** -- Novos kernels podem ser escolhidos entre os ajustes do
> SMO. As cores do painel do "BoundaryVisualizer" podem ser alteradas,
> clicando sobre os nomes das três "iris" no campo intermediário "Class
> color". Outros ajustes interessantes podem ser feitos no
> "BoundaryVisualizer" e testados em novas simulações. Bom trabalho!
2252c4032,4033
< Nesta unidade, apresentamos um tipo de algoritmo de **Aprendizado Estatístico** conhecido como **Máquina de Vetores de Suporte** (**MVS** ou **SVM**).
---
> Nesta unidade, apresentamos um tipo de algoritmo de **Aprendizado
> Estatístico** conhecido como **Máquina de Vetores de Suporte**.
2256,2268c4037,4085
< -   Por ser um **algoritmo determinístico**, se uma simulação for repetida como os mesmos valores iniciais e os mesmos parâmetros, obtém-se o mesmo resultado (diferentemente do que ocorre com as Redes Neurais).
< 
< -   Durante o aprendizado não se verifica o problema de **mínimos locais** na otimização da Função Custo de aprendizado. Há apenas um **mínimo global** que corresponde ao classificador com **margem máxima**.
< 
< -   As MVS estão menos sujeitas ao problema do *overfitting* comparativamente às Redes Neurais, porque a indução do classificador é menos sensível à retirada ou acréscimo de um ou outro Vetor de Treinamento (a menos que seja um Vetor de Suporte. Na prática, porém, os Vetores de Suporte constituem uma pequena fração dos Vetores de Treinamento).
< 
< Comparando com os algoritmos de Aprendizado Orientado a Conhecimento, as MVS apresentam tempo de treinamento mais elevado, porém sua taxa de acerto costuma ser mais elevada, porque o princípio de Margem (Suave) Máxima pode ser funcionalmente equivalente a uma borda de decisão não linear.
< 
< Como desvantagem com relação aos algoritmos de Aprendizado Orientado a Conhecimento, podemos citar a dificuldade em interpretar os resultados do aprendizado, que na prática é um conjunto de pesos do vetor **w**, ou algo equivalente. Outro aspecto que pode ser visto como uma desvantagem das MVS em relação a outros modelos, é que não é possível incorporar Conhecimento do Domínio do Problema no Modelo gerado. Numa Rede Neural, por exemplo, a topologia da rede reflete o Conhecimento do Domínio do Problema. Além disso, redes com multicamadas de neurônios podem aprender a ignorar Atributos irrelevantes (WITTEN & FRANK, 2005).
< 
< Através de exemplos e interpretações geométricas, tentamos mostrar que o desempenho de uma MVS pode ser substancialmente influenciado pela escolha do ***kernel*** e do **Parâmetro de Complexidade C**. Por se tratar de um algoritmo de aprendizado supervisionado, ou seja, os rótulos das classes dos Vetores de Treinamento já são previamente conhecidos, é possível desenvolver um *kernel* específico para uma aplicação especial (embora não seja algo muito simples) e avaliar empiricamente o desempenho do *kernel* usando o método da *Cross-validation*.
< 
< Os argumentos e as ilustrações aqui utilizados para explicar o algoritmo das MVS foram baseados num **espaço bidimensional**. No entanto, eles podem ser estendidos para o **espaço tridimensional**, quando então a reta que representa o classificador deve ser substituída por um **plano**. Da forma semelhante, os mesmos argumentos podem ser aplicados a **espaços com mais de três dimensões**, e neste caso o classificador passa a ser representado por um **hiperplano**.
---
> -   Por ser um **algoritmo determinístico**, se uma simulação for
>     > repetida como os mesmos valores iniciais e os mesmos parâmetros,
>     > obtém-se o mesmo resultado.
> 
> -   Durante o aprendizado não se verifica o problema de **mínimos
>     > locais** na otimização da Função Custo de aprendizado. Há apenas
>     > um **mínimo global** que corresponde ao classificador com **margem
>     > máxima**.
> 
> -   As MVS estão menos sujeitas ao problema do *overfitting*
>     > comparativamente às Redes Neurais, porque a indução do
>     > classificador é menos sensível à retirada ou acréscimo de um ou
>     > outro Vetor de Treinamento (a menos que seja um Vetor de Suporte.
>     > Na prática, porém, os Vetores de Suporte constituem uma fração dos
>     > Vetores de Treinamento).
> 
> Comparando com os algoritmos de Aprendizado Orientado a Conhecimento, as
> MVS apresentam tempo de treinamento mais elevado, porém sua taxa de
> acerto costuma ser mais elevada, porque o princípio de Margem (Suave)
> Máxima pode ser funcionalmente equivalente a uma borda de decisão não
> linear.
> 
> Como desvantagem com relação aos algoritmos de Aprendizado Orientado a
> Conhecimento, podemos citar a dificuldade em interpretar os resultados
> do aprendizado, que na prática é um conjunto de pesos do vetor **w**, ou
> algo equivalente. Outro aspecto que pode ser visto como uma desvantagem
> das MVS em relação a outros modelos, é que não é possível incorporar
> Conhecimento do Domínio do Problema no Modelo gerado. Numa Rede Neural,
> por exemplo, a topologia da rede reflete o Conhecimento do Domínio do
> Problema. Além disso, redes com multicamadas de neurônios podem aprender
> a ignorar Atributos irrelevantes (Witten & Frank, 2005).
> 
> Através de exemplos e interpretações geométricas, tentamos mostrar que o
> desempenho de uma MVS pode ser substancialmente influenciado pela
> escolha do ***kernel*** e do **Parâmetro de Complexidade C**. Por se
> tratar de um algoritmo de aprendizado supervisionado, ou seja, os
> rótulos das classes dos Vetores de Treinamento já são previamente
> conhecidos, é possível desenvolver um *kernel* específico para uma
> aplicação especial (embora não seja algo muito simples) e avaliar
> empiricamente o desempenho do *kernel* usando o método da
> *Cross-validation*.
> 
> Os argumentos e ilustrações aqui utilizados para explicar o algoritmo
> das MVS foram baseados num **espaço bidimensional**. No entanto, eles
> podem ser estendidos para o **espaço tridimensional**, quando então a
> reta que representa o classificador deve ser substituída por um
> **plano**. Da forma semelhante, os mesmos argumentos podem ser aplicados
> a **espaços com mais de três dimensões**, e neste caso o classificador
> passa a ser representado por um **hiperplano**.
2273,2275c4090,4091
< 1\. Explique **com suas próprias palavras** o que vem a ser um ***kernel*** no contexto de SVM.
< 
< 2\. Explique **com suas próprias palavras** qual a função do **Fator de Complexidade *C*** e como ele pode afetar tanto a taxa de erros de treinamento como a de classificação.
---
> 1\. (20%) Explique **com suas próprias palavras** o que vem a ser um
> ***kernel*** no contexto de SVM.
2277,2281c4093,4112
< 3\. Carregue o arquivo **"iris.arff"** no Weka e faça a classificação com uma **Máquina de Vetores de Suporte** usando o algoritmo **"*SMO*"**, (clique na aba "*Classify*", depois "*Choose*", escolha "*functions*" e clique em "SMO") com o método ***"Cross-validation"*** (10 *Folds*).
< 
< \(a\) Escolha valores para o **Fator de Complexidade *C*** entre 1 e 5 e analise os resultados da Matriz de Confusão. (Para ajustar o valor de ***C***, clique com o botão esquerdo do mouse sobre a palavra "*SMO*", ao lado de "*Choose*", e mude o valor de **C** na janela que deve se abrir).
< 
< \(b\) Compare o desempenho dos *kernels* "***PolyKernel***" e "***RBFKernel***". (Para escolher o tipo de *kernel*, clique com o botão esquerdo do mouse sobre a palavra "*SMO*", ao lado de "*Choose*", e escolha o *kernel* na janela que deve se abrir).
---
> 2\. (30%) Explique **com suas próprias palavras** qual a função do
> **Fator de Complexidade *C*** e como ele pode afetar tanto a taxa de
> erros de treinamento como a de classificação.
> 
> 3\. Carregue o arquivo **"iris.arff"** (anexo) no Weka e faça a
> classificação com uma **Máquina de Vetores de Suporte** usando o
> algoritmo **"*SMO*"**, (clique na aba "*Classify*", depois "*Choose*",
> escolha "*functions*" e clique em "SMO") com o método
> ***"Cross-validation"*** (10 *Folds*).
> 
> \(a\) (30%) -- Escolha valores para o **Fator de Complexidade *C***
> entre 1 e 5 e analise os resultados da Matriz de Confusão. (Para ajustar
> o valor de ***C***, clique com o botão esquerdo do mouse sobre a palavra
> "*SMO*", ao lado de "*Choose*", e mude o valor de **C** na janela que
> deve se abrir).
> 
> \(b\) (20%) -- Compare o desempenho dos *kernels* "***PolyKernel***" e
> "***RBFKernel***". (Para escolher o tipo de *kernel*, clique com o botão
> esquerdo do mouse sobre a palavra "*SMO*", ao lado de "*Choose*", e
> escolha o *kernel* na janela que deve se abrir).
2286c4117,4118
< CORTES, C. & VAPNIK, V. **Support Vector Networks**. Netherlands: Machine Learning, 20, pp. 273-297, Springer Verlag, 1995.
---
> CORTES, C. & VAPNIK, V. **Support Vector Networks**. Netherlands:
> Machine Learning, 20, pp. 273-297, Springer Verlag, 1995.
2288c4120,4123
< PLATT, J. **Fast Training of Support Vector Machines Using Sequential Minimal Optimization**. http://research.microsoft.com/apps/pubs/?id=68391 . Acessado em 22.03.13.
---
> PLATT, J. **Fast Training of Support Vector Machines Using Sequential
> Minimal Optimization**.
> http://research.microsoft.com/apps/pubs/?id=68391 . Acessado em
> 22.03.13.
2290c4125,4126
< REZENDE, S. O. (Organizadora). **Sistemas Inteligentes: Fundamentos e Aplicações.** Barueri: Editora Manole Ltda., 2005.
---
> REZENDE, S. O. (Organizadora). **Sistemas Inteligentes: Fundamentos e
> Aplicações.** Barueri: Editora Manole Ltda, 2005.
2292c4128,4130
< ROCHA, M.; CORTEZ, P. & NEVES, J. M. **Análise Inteligente de Dados: Algoritmos e Implementação em Java.** Lisboa: Editora de Informática, 2008.
---
> ROCHA, M.; CORTEZ, P. & NEVES, J. M. **Análise Inteligente de Dados:
> Algoritmos e Implementação em Java.** Lisboa: Editora de Informática,
> 2008.
2294c4132,4133
< ROSENBLATT, F. **The Perceptron: a Perceiving and Recognizing Automaton**. Report 85, pp. 460-1, Cornell Aeronautical Laboratory, 1957.
---
> ROSENBLATT, F. **The Perceptron: a Perceiving and Recognizing
> Automaton**. Report 85, 460-1, Cornell Aeronautical Laboratory, 1957.
2296c4135,4136
< SCHÖLKOPF, B. & SMOLA, A. J. **Learning with Kernels**. Cambridge: Cambridge Press, 2001.
---
> SCHÖLKOPF, B. & SMOLA, A. J. **Learning with Kernels**. Cambridge:
> Cambridge Press, 2001.
2298c4138,4140
< TAN, P.N.; STEINBACH, M. & KUMAR, V. **Introdução ao Data Mining Mineração de Dados.** Rio de Janeiro: Editora Ciência Moderna Ltda., 2009.
---
> TAN, P.N.; STEINBACH, M. & KUMAR, V. **Introdução ao Data Mining
> Mineração de Dados.** Rio de Janeiro: Editora Ciência Moderna Ltda.,
> 2009.
2300c4142,4144
< WITTEN, I. H. & FRANK, E. **Data Mining: Practical Machine Learning Tools and Techniques.** Second Edition. Amsterdam: Morgan Kaufmann Publishers, 2005.
---
> WITTEN, I. H. & FRANK, E. **Data Mining: Practical Machine Learning
> Tools and Techniques.** Second Edition. Amsterdam: Morgan Kaufmann
> Publishers, 2005.
2302c4146,4147
< Weka. The Waikato University. In http://www.cs.waikato.ac.nz/ml/weka. Acessado em 03.03.13.
---
> Weka. The Waikato University. In <http://www.cs.waikato.ac.nz/ml/weka/>
> . Acessado em 03.03.13.
2304c4149,4151
< WITTEN, I. H. & FRANK, E. **Data Mining: Practical Machine Learning Tools and Techniques.** Thirdy Edition. Amsterdam: Morgan Kaufmann Publishers, 2011.
---
> WITTEN, I. H. & FRANK, E. **Data Mining: Practical Machine Learning
> Tools and Techniques.** Thirdy Edition. Amsterdam: Morgan Kaufmann
> Publishers, 2011.
2306c4153
< 6.  Aplicações de SVM Usando Imagens
---
> 1.  Aplicações de SVM usando imagens
2312,2320c4159,4190
< Usar técnicas de classificação, como a SVM, para aplicações em imagens é de grande interesse e importância, tanto para a academia como para o mercado. Como exemplo, na medicina, é possível usar software para auxiliar o diagnóstico médico, chamado CAD (*Computer Aided Diagnosis*), analisando imagens de raio x, ultrassom, ressonância, tomografia, microscópio eletrônico, raio laser, etc. Este último tipo de imagens, conhecido como tomografia de coerência óptica (OCT, sigla em inglês), auxilia médicos no diagnóstico usando laser de baixa frequência, criando imagens tridimensionais de tumores.
< 
< Outro fator que motiva criar Sistemas Especialistas para análise de imagens é a existência de sistemas de gestão de exames, implantados nos principais hospitais e laboratórios, onde os exames são realizados e os resultados são digitalizados, inclusive as imagens dos exames. Assim, já existe uma gigantesca base de imagens, que poderia treinar vários Sistemas Especialistas, quando o diagnóstico já existe no prontuário do paciente.
< 
< Além das imagens médicas, também existem grandes demandas para análise de imagens em dispositivos móveis, para os quais aplicações estão começando a surgir, como o reconhecedor de faces em aplicativos com câmeras em *smartphones*.
< 
< Outra aplicação recente é a busca por imagens na *web*, como o aplicativo *Google Goggles,* que, com base numa foto de um objeto retorna páginas na *web* com imagens semelhantes. Esta busca por imagem ainda apresenta muitos erros, parecendo ser uma busca pelo histograma da imagem (isto será explicado neste capítulo).
< 
< Desta forma, se ressalta a importância em criar sistemas sofisticados para a análise de imagens, e este capítulo faz uma introdução à classificação de imagens usando SVM.
---
> Usar técnicas de classificação, como a SVM, para aplicações em imagens é
> de grande interesse e importância, tanto para a academia como para
> aplicações no mercado. Como exemplo, na medicina, é possível usar
> software para auxiliar o diagnóstico médico, chamado CAD (*Computer
> Aided Diagnosis*), ou diagnóstico auxiliado por computador, analisando
> imagens de raio x, ultrassom, ressonância, tomografia, microscópio
> eletrônico, raio laser, etc. Este último tipo de imagens, conhecida como
> tomografia de coerência óptica (OCT, sigla em inglês), onde médicos
> conseguem auxiliar no diagnóstico usando laser de baixa frequência,
> criando imagens tridimensional de tumores.
> 
> Outro fator que motiva criar sistemas especialistas para análise de
> imagens é a existência de sistemas de gestão de exames, implantados nos
> principais hospitais e laboratórios, onde os exames são realizados e os
> resultados são digitalizados, inclusive as imagens dos exames. Assim, já
> existe uma gigantesca base de imagens, que poderia treinar vários
> sistemas especialistas, quando o diagnóstico já existe no prontuário do
> paciente.
> 
> Além das imagens médicas, também existem grandes demandas para análise
> de imagens em dispositivos móveis, onde as aplicações estão começando a
> surgir, como o reconhecedor de faces em aplicativos com câmeras em
> *smartphones*.
> 
> Outra aplicação recente é a busca por imagens na *web*, como o
> aplicativo *Google Goggles*, onde basta tirar uma foto de um objeto e o
> aplicativo retorna páginas na *web* com imagens semelhantes. Basicamente
> este aplicativo faz busca pelo histograma da imagem.
> 
> Desta forma, se observa a importante de criar sistemas sofisticados para
> a análise de imagens, e este capítulo faz uma introdução à classificação
> de imagens usando SVM.
2322c4192
< Introdução à Classificação de Imagens Usando Weka e MATLAB
---
> Introdução à classificação de imagens usando Weka e MATLAB
2325,2327c4195,4205
< O leitor pode reproduzir os experimentos deste capítulo usando o software MATLAB^®^ , versão 2010, para criar as imagens e gerar o arquivo ".arff", que deverão ser lidos pelo Weka. Foram feitos testes de classificação em imagens usando o classificador SVM. Inicialmente foram geradas imagens sintéticas simples de uma face feliz e outra triste, como ilustra a Figura 6.1.
< 
< ![feliz](./media/image59.png){width="2.2618055555555556in" height="1.6916666666666667in"} ![triste](./media/image60.png){width="2.2243055555555555in" height="1.663888888888889in"}
---
> O leitor pode reproduzir os experimentos deste capítulo usando o
> software MATLAB^®^ , versão 2010, para criar as imagens e gerar o
> arquivo *arff* do Weka. Foram feitos testes de classificação em imagens
> usando o classificador *SVM*. Inicialmente foram geradas imagens
> sintéticas simples de uma face feliz e outra triste, como ilustra a
> Figura 6.1.
> 
> ![feliz](media/image59.png){width="2.2618055555555556in"
> height="1.6916666666666667in"}
> ![triste](media/image60.png){width="2.2243055555555555in"
> height="1.663888888888889in"}
2331c4209
< Figura . -- Face (a) Feliz e Face (b) Triste.
---
> Figura . -- Face (a) feliz e face (b) triste.
2333c4211,4217
< Essas imagens são matrizes quadradas de dimensão 7x7, onde o canto superior esquerdo é convencionado no MATLAB^®^ como o pixel (1,1), a primeira coordenada é o eixo vertical e a segunda coordenada, o eixo horizontal. Assim, os pixels dos olhos e das bocas das duas imagens da Figura 6.1 são definidos com o valor 1 (um) e o restante com o valor 0 (zero). Definimos uma imagem com dimensões 7x7 (Figura 6.1(a)) no MATLAB^®^, com os seguintes comandos:
---
> Essas imagens são matrizes quadrados de dimensão 7x7, onde o canto
> superior esquerdo é convencionado no MATLAB^®^ como o pixel (1,1), a
> primeira coordena é o eixo vertical e a segunda coordenada é o eixo
> horizontal. Assim, os pixels dos olhos e as bocas das imagens da Figura
> 6.1 são definidos com o valor 1 (um) e o restante com o valor 0 (zero).
> Assim, definimos uma imagem com dimensões 7x7 (Figura 6.1(a)) no
> MATLAB^®^, com os seguintes comandos:
2335c4219
< img_a = zeros(7,7); % cria imagem img_a com dimensões 7x7
---
> img_a = zeros(7,7); % cria imagens img_a com dimensões 7x7
2337,2338c4221,4222
< img_a(2,3) = 1; img_a(2,5) = 1; % define os olhos\
< img_a(4,2) = 1; img_a(4,6) = 1; img_a(5,3:5) = 1; % define a boca feliz
---
> img_a (2,3) = 1; img_a (2,5) = 1; % define os olhos\
> img_a (4,2) = 1; img_a (4,6) = 1; img_a (5,3:5)=1; % define a boca feliz
2340c4224
< Respectivamente, de forma semelhante para a imagem da Figura 6.1(b):
---
> respectivamente, de forma semelhante para a imagem da Figura 6.1(b):
2342c4226
< img_b = zeros(7,7); % cria imagem img_b com dimensões 7x7
---
> img_b = zeros(7,7); % cria imagens img_a com dimensões 7x7
2344,2345c4228,4230
< img_b(2,3) = 1; img_b(2,5) = 1; % define os olhos\
< img_b(6,2) = 1; img_b(6,6) = 1; img_b(5,3:5) = 1; % define a boca triste
---
> img_b (2,3) = 1; img_b (2,5) = 1; % define os olhos\
> img_b (6,2) = 1; img_b (6,6) = 1; img_b (5,3:5)=1; % define a boca
> triste
2347c4232,4236
< Em seguida, para gerar outras amostras das imagens feliz e triste, foram geradas translações aleatórias de 1 pixel na horizontal, Figura 6.2(a) (respectivamente, para a direção vertical, Figura 6.2(b)). Para a translação horizontal (respectivamente vertical), foram utilizados os seguintes comandos no MATLAB^®^:
---
> Em seguida, para gerar outras amostras das imagens feliz e triste, foram
> geradas translações aleatórias de 1 pixel na horizontal, Figura 6.2()
> (respectivamente, para a direção vertical, Figura 6.2(b)). Para a
> translação horizontal (respectivamente vertical), foram utilizados os
> seguintes comandos no MATLAB^®^:
2349c4238
< trans = 1; % para translações de um pixel na horizontal ou na vertical
---
> trans = 1;
2353c4242,4243
< img = imdilate(img,translate(strel(\[1\]),\[0 -trans+round(rand\*2\*trans)\]));
---
> img = imdilate(img,translate(strel(\[1\]),\[0
> -trans+round(rand\*2\*trans)\]));
2357c4247,4248
< img = imdilate(img,translate(strel(\[1\]),\[-trans+round(rand\*2\*trans) 0\]));
---
> img = imdilate(img,translate(strel(\[1\]),\[-trans+round(rand\*2\*trans)
> 0\]));
2359c4250,4253
< ![feliz_1h_0v](./media/image61.png){width="2.2895833333333333in" height="1.7194444444444446in"} ![feliz_0h_1v](./media/image62.png){width="2.1868055555555554in" height="1.7006944444444445in"}
---
> ![feliz_1h_0v](media/image61.png){width="2.2895833333333333in"
> height="1.7194444444444446in"}
> ![feliz_0h_1v](media/image62.png){width="2.1868055555555554in"
> height="1.7006944444444445in"}
2363c4257
< Figura . - Translação (a) Horizontal e (b) Vertical.
---
> Figura . - Translação (a) horizontal e (b) vertical.
2365c4259,4266
< Nestes comandos, foi utilizada a dilatação com elementos estruturantes especiais, onde o objetivo do comando *--trans+round(rand\*2\*trans)* é fornecer um número aleatório entre *-trans* e *trans* (para detalhes, consulte o *help* do MATLAB^®^). Assim, a imagem *img* é transladada de forma aleatória para a esquerda ou direita. Cálculo análogo é realizado para a translação vertical. Veja no código a seguir a função completa construída no MATLAB^®^ para gerar imagens aleatórias e também o arquivo ".arff"*,* que será usado no Weka para obter o resultado da classificação usando SVM:
---
> Nestes comandos, foi utilizada a dilatação com elementos estruturantes
> especiais, onde o objetivo do comando *--trans + round(rand\*2\*trans)*
> é fornecer um número aleatório entre *-trans* e *trans*. Assim, a imagem
> *img* é translada de forma aleatória para a esquerda ou direita. Cálculo
> análogo é realizado para a translação vertical. Veja no código a seguir
> a função completa construída no MATLAB^®^ para gerar imagens aleatórias
> e também o arquivo *".arff",* que será usado no Weka para obter o
> resultado da classificação usando SVM:
2387c4288,4289
< img = imdilate(img,translate(strel(\[1\]),\[0 -trans+round(rand\*2\*trans)\]));
---
> img = imdilate(img,translate(strel(\[1\]),\[0
> -trans+round(rand\*2\*trans)\]));
2391c4293,4294
< img = imdilate(img,translate(strel(\[1\]),\[-trans+round(rand\*2\*trans) 0\]));
---
> img = imdilate(img,translate(strel(\[1\]),\[-trans+round(rand\*2\*trans)
> 0\]));
2393c4296
< \% varre primeiro as linhas da imagem e cada pixel define um atributo
---
> \% varre primeiro as linhas e cada pixel define um classificador
2395c4298
< x1 = img(1,1);
---
> x1 =img(1,1);
2397c4300
< x2 = img(1,2);
---
> x2 =img(1,2);
2399c4302
< x3 = img(1,3);
---
> x3 =img(1,3);
2403c4306,4308
< x49= img(7,7);
---
> x49=img(7,7);
> 
> dt = date; % pega a data do sistema
2405c4310
< fid = fopen(str,\'r\'); % lê arquivo str
---
> fid = fopen(str,\'r\');
2407c4312
< if fid == -1 % se arquivo não existe, incluir cabeçalho
---
> if fid==-1 % se arquivo não existe, incluir cabeçalho
2409c4314
< fid = fopen(str,\'at+\');
---
> fid=fopen(str,\'at+\');
2425c4330
< else % senão, incluír os atributos da nova imagem feliz ou triste
---
> else % senão incluir os atributos da nova imagem feliz ou triste
2429c4334
< fid = fopen(str,\'at+\');
---
> fid=fopen(str,\'at+\');
2433,2435c4338,4339
< \% o próximo comando imprime "feliz" ou "triste", mais os 49 atributos (pixels)
< 
< fprintf(fid,\'%s,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d\\n\',\... resposta,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,x21,x22,x23,x24,x25,x26,x27,x28,x29,x30,x31,x32,x33,x34,x35,x36,x37,x38,x39,x40,x41,x42,x43,x44,x45,x46,x47,x48,x49);
---
> fprintf(fid,\'%s,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d,%5d\\n\',\...
> resposta,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,x21,x22,x23,x24,x25,x26,x27,x28,x29,x30,x31,x32,x33,x34,x35,x36,x37,x38,x39,x40,x41,x42,x43,x44,x45,x46,x47,x48,x49);
2439c4343
< fclose(fid); % fecha arquivo
---
> fclose(fid);
2443c4347,4352
< Um exemplo de uso desta função é imagens_aleatorias('face50.arff', 'feliz', 50, img_a), e após a execução deste comando no MATLAB^®^, esta função salva no disco o seguinte fragmento de arquivo ".arff", gerando 50 imagens da face feliz (Figura 6.1 (a)) com translações aleatórias de um pixel para a horizontal ou vertical. Este arquivo 'face50.arff' é usado como entrada de dados no Weka:
---
> Um exemplo de uso desta função é imagens_aleatorias('face50.arff',
> 'feliz', 50, img_a), e após a execução deste comando no MATLAB^®^, esta
> função salva no disco o seguinte fragmento de arquivo ".arff", gerando
> 50 imagens da face feliz (Figura 6.1(a)) com translações aleatórias de
> um pixel para a horizontal ou vertical. Este arquivo 'face50.arff' é
> usado como entrada de dados no Weka:
2508c4417,4419
< Usando a função anterior para gerar 50 amostras para a imagem feliz e 50 para a triste, o classificar SVM implementado no Weka obteve 100% de acerto, como mostra a seguinte matriz de confusão:
---
> Usando a função anterior para gerar 50 amostras para a imagem feliz e 50
> para a triste, o classificar *SVM* implementado no Weka \[9\] obteve
> 100% de acerto, como mostra a seguinte matriz de confusão:
2516c4427,4431
< Para translações horizontais e verticais ao mesmo tempo, como mostra a Figura 6.3, foram gerados dois conjuntos de amostras ao acaso de 50 translações cada. Na primeira, também foi obtido 100% de acerto. Porém, no segundo conjunto de amostras aleatórias geradas foi encontrada a seguinte matriz de confusão:
---
> Para translações horizontais e verticais ao mesmo tempo, como mostra a
> Figura 6.3, foram gerados dois conjuntos de amostras ao acaso de 50
> translações cada. Na primeira, também foi obtido 100% de acerto. Porém
> no segundo conjunto de amostras aleatórias gerada foi encontrada a
> seguinte matriz de confusão:
2522c4437
< 1 49 \| b = feliz
---
> 2.  49 \| b = feliz
2524c4439,4440
< ![](./media/image63.png){width="2.3520833333333333in" height="1.7604166666666667in"}
---
> ![](media/image63.png){width="2.3520833333333333in"
> height="1.7604166666666667in"}
2526c4442
< Figura . -- Face Transladada Horizontal e Vertical.
---
> Figura . -- Face transladada horizontal e vertical.
2528c4444,4446
< Neste caso com 96% de acerto. Ou seja, três imagens triste foram classificadas como feliz e uma imagem feliz foi classificada como triste. Um dos casos é apresentado na Figura 6.4.
---
> Neste caso com 96% de acerto. Ou seja, três imagens triste foram
> classificadas como feliz e uma imagem feliz foi classificada como
> triste. Um dos casos é apresentado na Figura 6.4.
2530c4448,4449
< ![triste_1h_1v_erro](./media/image64.png){width="2.3067935258092738in" height="1.7327154418197726in"}
---
> ![triste_1h_1v_erro](media/image64.png){width="2.140277777777778in"
> height="1.6076388888888888in"}
2532c4451
< Figura . -- Caso de Erro, com Translações Horizontais e Verticais.
---
> Figura . -- Caso de erro, com translações horizontais e verticais.
2534c4453,4457
< Agora, aumentando o número de imagens para 1000 amostras de translações aleatórias de um pixel na vertical e na horizontal foi obtido 100% de acerto. Este processo foi repetido 5 vezes e em todos os casos o resultado foi o mesmo. Ou seja, quando maior o número de amostras, melhor será o resultado da classificação.
---
> Agora, aumentando o número de imagens para 1000 amostras de translações
> aleatórias de um pixel na vertical e na horizontal foi obtido 100% de
> acerto. Este processo foi repetido 5 vezes e em todos os casos o
> resultado foi o mesmo. Ou seja, quando maior o número de amostras,
> melhor será o resultado da classificação.
2536c4459,4463
< Em seguida, foram realizados testes de translação com mais de um pixel na horizontal e na vertical. Em uma das simulações foi usada uma translação com 2 pixels. Neste caso, a boca e/ou os olhos poderão ser excluídos da imagem, como mostra a Figura 6.5, dificultando ainda mais o processo de classificação. Como resultado, foi obtida a seguinte matriz de confusão, considerando 100 amostras:
---
> Em seguida, foram realizados testes de translação com mais de um pixel
> na horizontal e na vertical. No caso foi usado 2 pixels. Neste caso, a
> boca e/ou os olhos poderão ser excluídos da imagem, como mostra a Figura
> 6.5, dificultando ainda mais o processo de classificação. Neste caso foi
> obtido a seguinte matriz de confusão, considerando 100 amostras:
2544c4471,4472
< ![](./media/image65.png){width="2.2958333333333334in" height="1.7180555555555554in"}
---
> ![](media/image65.png){width="2.2958333333333334in"
> height="1.7180555555555554in"}
2546c4474
< Figura . -- Foto Sem os Olhos.
---
> Figura . -- Foto sem os olhos.
2548c4476,4478
< Como esperado, foi obtido 79% de acerto. Rodamos novamente para outras 100 amostras, obtivemos 72% de acerto. Aumentando para 1000 amostras obtivemos 94.8%, com a seguinte matriz de confusão:
---
> Como esperado, foi obtido 79% de acerto. Rodamos novamente para outras
> 100 amostras, obtivemos 72% de acerto. Aumentando para 1000 amostras
> obtivemos 94.8%, com a seguinte matriz de convolução:
2556c4486,4488
< No lugar de fazer translações, também podemos utilizar rotações e reflexão. Finalmente, foram utilizados ruídos aleatórios de um pixel, dois pixels etc., de acordo com o seguinte trecho de código no MATLAB^®^:
---
> No lugar de fazer translações, também foram utilizados rotações e
> reflexão. Finalmente, foi utilizado ruídos aleatórios de um pixel, dois
> pixels etc., utilizando o seguinte trecho de código no MATLAB^®^:
2558c4490
< \% adiciona ruídos de um pixel na imagem 7x7
---
> \% adicionar ruídos de um pixel na imagem 7x7
2560c4492
< num = sum(sum(img));
---
> num=sum(sum(img));
2562c4494
< aux = img;
---
> aux=img;
2564c4496
< while (num\~=8) % para adicinar dois pixels de ruído, mudar de 8 para 9
---
> while (num\~=8)
2566c4498
< img = aux;
---
> img=aux;
2570c4502
< num = sum(sum(img));
---
> num=sum(sum(img));
2574,2617c4506,4612
< Para imagens com ruídos de um pixel a mais, ou seja, para 8 pixels com valor 1, foi obtido 100% de acerto para 100 amostras (o mesmo se repetiu para 9, 10 e 11 pixels, com geração de vários conjuntos de 100 amostras diferentes). Já para 12 pixels, ou seja com 5 pixels a mais de ruído, foi obtido 99% de acerto. Foram repetidos vários testes com 12 pixels com valor 1 e o resultado se manteve próximo a 99% de acerto. A Figura 6.6 ilustra um dos resultados classificados erroneamente.
< 
< ![feliz_12pixels_erro](./media/image66.png){width="2.402083333333333in" height="1.8034722222222221in"}
< 
< Figura . -- Imagem com Ruídos Classificada Erroneamente.
< 
< Como conclusões destes testes, podemos ressaltar que não é possível considerar todos os pixels de uma imagem como atributos, pois para uma imagem de 1000x1000 pixels (que é um tamanho razoável para imagens tratadas atualmente) o número de atributos utilizados no Weka torna-se inviável. Além disso, para uma simples imagem sintética 7x7 verificamos que variações geométricas de translação e da inclusão de ruídos, a classificação fica comprometida, sendo necessário aumentar o número de amostras significativamente para melhorar a classificação.
< 
< Além disso, é aconselhável usar atributos mais significativos para diminuir a quantidade de atributos sem comprometer o desempenho da classificação. Por exemplo, para o caso de imagens da face, é possível ter como atributos: o número de componentes conexos (pixels com valores 1's conectados usando vizinhança 8, por exemplo, ou seja, tomando-se o centro de um subconjunto 3x3 da imagem e verificando se existe algum dos 8 vizinhos também com valor 1), assim, estes pixels com valores 1's pertencem a um componente conexo; a área de cada componente conexo; o fecho convexo dos objetos, isto é, as bordas convexas nos olhos e na bocas das imagens da Figura 6.1 -- o fecho convexo da face triste possui área maior que a área da face feliz etc. Estes atributos, que representam a topologia dos objetos, podem ser mais representativos ao distinguir diferentes tipos de objetos.
< 
< O MATLAB^®^ oferece também recursos para calcular medidas geométricas de cada objeto usando o comando **regionpropos** -- para mais informações deste comando, consulte o *help* do MATLAB^®^. Porém, antes de analisar a topologia de cada objeto, a próxima seção apresenta uma técnica de classificação de imagens usando histogramas.
< 
< Classificação de Imagens Usando Histogramas
< -------------------------------------------
< 
< Como uma aplicação de classificação de imagens reais, em que não é possível considerar cada pixel da imagem com um atributo, nesta seção consideramos apenas os valores dos pixels das imagens, sem a preocupação com as formas que estes pixels possam representar na imagem.
< 
< Considere a imagem da Figura 6.7. Esta é uma imagem colorida, usando o padrão de cores RGB (do inglês: *Red* (vermelho), *Green* (verde) e *Blue* (azul), respectivamente). Esta imagem pode ser lida no MATLAB^®^ usando o comando *img = imread(\'Lena.jpg\');,* criando a variável *img*. Para visualizar esta imagem, digite o comando *imshow(img)*, como mostra a Figura 6.7.
< 
< Para verificar as dimensões desta variável *img*, basta digitar *whos* no MATLAB^®^. Na Figura 6.8, é possível observar que a imagem *img* possui dimensões 512x512x3. O último valor 3 representa as cores RGB, ou também chamadas de "as três bandas da imagem". O campo *Class* nesta Figura 6.8 representa o tipo de dados de cada pixel, em cada uma das três bandas. Neste exemplo o tipo é *uint8*, que significa um *byte* que pode assumir valores entre 0 e 255, representando tons de cinza.
< 
< ![](./media/image67.jpeg){width="3.1in" height="3.1in"}
< 
< Figura . -- Imagem em Cores, com Dimensões 512x512x3.
< 
< ![](./media/image68.png){width="5.4980260279965005in" height="1.070138888888889in"}
< -----------------------------------------------------------------------------------
< 
< Figura . --Comando Usado para Ler uma Imagem e Mostrar as suas Características.
< 
< Para os nossos testes de classificação usando histogramas, é possível analisar apenas uma banda de cores, por exemplo, digitando o comando *imgNC=img(:,:,2);.* Neste comando é considerado apenas a segunda banda da imagem. Para visualizar esta imagem, digite *imshow(imgNC)*, como mostra a Figura 6.9.
< 
< Para visualizar o histograma de uma imagem, use o comando *imhist(imgNC).* A Figura 6.10 mostra o resultado deste comando.
< 
< ![](./media/image69.jpeg){width="3.178124453193351in" height="3.178124453193351in"}
< 
< Figura . --Imagem em Nível de Cinza.
< 
< ![fzmac:Users:fz:Desktop:Sist_Intel_e\_MD:teste:untitled.tif](./media/image70.png){width="3.378284120734908in" height="3.378284120734908in"}
< --------------------------------------------------------------------------------------------------------------------------------------------
< 
< Figura . - Histograma da Imagem imgNC.
< 
< Agora, já é possível fazer um experimento completo de classificação em imagens usando como atributos o histograma de cada imagem, isto é, os 256 atributos referentes à cor de cada pixel para cada imagem, como apresentado na Figura 6.10. Para estes testes serão usadas 10 imagens, sendo 5 do tecido adiposo (Figura 6.11(a)) e 5 do tecido epitelial (Figura 6.11(b))[^9]. Estas imagens também foram classificadas usando medidas topológicas, como apresentado em (ZAMPIROLLI *et al.*, 2010)[^10] e resumido na próxima seção. Usando apenas o histograma na segunda banda das imagens (veja Figuras 6.12 e 6.13), a respectiva matriz de confusão é apresentada a seguir, com 100% de acerto. Esta facilidade na classificação ocorre pois as imagens do tecido adiposo são mais claras (muitos pixels com valores próximos do 255), quando comparadas com as imagens do tecido epitelial, como observado nos histogramas da Figura 6.13.
---
> Para imagens com ruídos de um pixels a mais, ou seja, para 8 pixels com
> valor 1, foi obtido 100% de acerto para 100 amostras (o mesmo se repetiu
> para 9, 10 e 11 pixels, com geração de vários conjuntos de 100 amostras
> diferentes). Já para 12 pixels, ou seja com 5 pixels a mais de ruído,
> foi obtido 99% de acerto. Foi repetido vários teste com 12 pixels com
> valor 1 e o resultado se manteve próximo a 99% de acerto. Veja na Figura
> 6.6 um dos resultados que classificou erroneamente.
> 
> Como conclusões destes testes, não é possível considerar todos os pixels
> de uma imagem como atributos, pois se tiver uma imagem de 1000x1000
> pixels (que é um tamanho razoável para as imagens tratadas atualmente).
> O número de atributos utilizados no Weka é inviável. Além disso, uma
> simples imagens sintética 7x7 verificamos que para variações geométricas
> de translação, rotação e reflexão, além da inclusão de ruídos, a
> classificação é comprometida, sendo necessário aumentar o número de
> amostras significativamente para melhorar a classificação.
> 
> ![feliz_12pixels_erro](media/image66.png){width="2.402083333333333in"
> height="1.8034722222222221in"}
> 
> Figura . -- Imagem com ruídos classificada erroneamente.
> 
> Além disso, é razoável usar atributos mais significativos para diminuir
> a quantidade de atributos sem comprometer o desempenho da classificação.
> Por exemplo, para o caso das imagens da face, é possível ter como
> atributos: o número de componentes conexas (pixels com valores 1's
> conectados usando vizinha 8 conectado por exemplo, ou seja, se o centro
> de um subconjunto 3x3 da imagem e verificando se existe algum dos 8
> vizinhos também com valor 1), assim, estes pixels com valores um
> pertencem a um componente conexo; a área de cada componente conexa;
> calcular o fecho convexo dos objetos, isto é, nos olhos e na bocas das
> imagens da Figura 6.1 -- o fecho convexo da face triste possui área
> maior que a área da face feliz; etc. Estes atributos, que representam a
> topologia dos objetos, podem ser mais representativos ao distinguir
> diferente tipos de objetos. O MATLAB^®^ oferece também recursos para
> calcular medidas geométricas de cada objeto usando o comando
> **regionpropos** -- para mais informações deste comando, consulte o
> *help* do MATLAB^®^. Porém, antes de analisar a topologia de cada
> objeto, a próxima seção apresenta classificação de imagens usando o
> histograma.
> 
> Classificação de imagens usando histograma
> ------------------------------------------
> 
> Como uma aplicação de classificação de imagens reais, onde não é
> possível considerar cada pixel da imagem com um atributo, esta seção
> considera apenas os valores dos pixels das imagens, sem a preocupação
> com as formas que estes pixels representam na imagem.
> 
> Considere a imagem da Figura 6.7. Esta é uma imagem colorida, usando o
> padrão de cores RGB (do inglês: vermelho, verde e azul,
> respectivamente). Esta imagem pode ser lida usando o comando *img =
> imread(\'Lena.jpg\');,* criando a variável *img*. Para visualizar esta
> imagem no MATLAB^®^, digite o comando *imshow(img)*, como mostra a
> Figura 6.7.
> 
> Para verificar as dimensões desta variável *img*, basta digitar *whos*
> no MATLAB^®^. Na Figura 6.8, é possível observar que a imagem *img*
> possui dimensões 512x512x3. O último valor 3 representa as cores RGB, ou
> também chamado as três bandas da imagem. O campo *Class* nesta Figura
> 6.8 representa o tipo de dados de cada pixel, em cada uma das três
> bandas. Neste exemplo o tipo é *uint8*, que significa um *byte* e pode
> assumir valores entre 0 e 255.
> 
> ![](media/image67.jpg){width="3.1in" height="3.1in"}
> 
> Figura . -- Imagem em cores, com dimensões 512x512x3.
> 
> ![](media/image68.png){width="5.4980260279965005in" height="1.070138888888889in"}
> ---------------------------------------------------------------------------------
> 
> Figura . --Comando usando para ler uma imagem e mostrar as suas
> características.
> 
> Para os nossos testes de classificação usando histograma, é possível
> analisar apenas uma banda de cores, por exemplo, usando o comando
> *imgNC=img(:,:,2);.* Neste comando é considerado apenas a segunda banda
> da imagem. Para visualizar esta imagem digite *imshow(imgNC)*, como
> mostra a Figura 6.9.
> 
> ![](media/image69.jpg){width="3.178124453193351in"
> height="3.178124453193351in"}
> 
> Figura . --Imagem em nível de cinza.
> 
> Para visualizar o histograma de uma imagem use o comando
> *imhist(imgNC)*, veja Figura 6.10 o resultado deste comando.
> 
> ![fzmac:Users:fz:Desktop:Sist_Intel_e\_MD:teste:untitled.tif](media/image70.png){width="3.378284120734908in" height="3.378284120734908in"}
> ------------------------------------------------------------------------------------------------------------------------------------------
> 
> Figura . - Histograma da imagem imgNC.
> 
> Agora, já é possível fazer um experimento completo de classificação em
> imagens usando como atributos o histograma de cada imagem, isto é, os
> 256 atributos referente a cor de cada pixel para cada imagem, como
> apresentado na Figura 6.10. Para estes testes serão usadas 10 imagens,
> sendo 5 do tecido adiposo (Figura 6.11(a)) e 5 do tecido epitelial
> (Figura 6.11(b))[^9]. Estas imagens também foram classificadas usando
> medidas topológicas, como apresentado em (Zampirolli *et al.*,
> 2010)[^10] e resumido na próxima seção. Usando apenas o histograma na
> segunda banda das imagens (veja Figuras 6.12 e 6.13) a matriz de
> confusão é a apresentada a seguir, com 100% de acerto. Esta facilidade
> na classificação ocorre pois as imagens do tecido adiposo são mais
> claras (muitos pixels com valores próximos do 255), comparado com as
> imagens do tecido epitelial, como observado nos histogramas da Figura
> 6.13.
2625c4620,4623
< ![fzmac:Users:fz:Desktop:Sist_Intel_e\_MD:teste:IMAGES:adiposo.tif](./media/image71.png){width="2.7190977690288713in" height="2.7190977690288713in"} ![fzmac:Users:fz:Desktop:Sist_Intel_e\_MD:teste:IMAGES:epitelial.tif](./media/image72.png){width="2.694096675415573in" height="2.694096675415573in"}
---
> ![fzmac:Users:fz:Desktop:Sist_Intel_e\_MD:teste:IMAGES:adiposo.tif](media/image71.png){width="2.7190977690288713in"
> height="2.7190977690288713in"}
> ![fzmac:Users:fz:Desktop:Sist_Intel_e\_MD:teste:IMAGES:epitelial.tif](media/image72.png){width="2.694096675415573in"
> height="2.694096675415573in"}
2629c4627
< Figura . -- Imagens dos Tecidos (a) Adiposo e (b) Epitelial.
---
> Figura . -- Imagens dos tecidos (a) adiposo e (b) epitelial.
2631c4629,4631
< ![fzmac:Users:fz:Desktop:Sist_Intel_e\_MD:teste:IMAGES:adiposo01NC_b2.tif](./media/image73.png){width="2.6486111111111112in" height="2.6486111111111112in"}![fzmac:Users:fz:Desktop:Sist_Intel_e\_MD:teste:IMAGES:epithelialNC_b2.tif](./media/image74.png){width="2.647222222222222in" height="2.647222222222222in"}
---
> ![fzmac:Users:fz:Desktop:Sist_Intel_e\_MD:teste:IMAGES:adiposo01NC_b2.tif](media/image73.png){width="2.6486111111111112in"
> height="2.6486111111111112in"}![fzmac:Users:fz:Desktop:Sist_Intel_e\_MD:teste:IMAGES:epithelialNC_b2.tif](media/image74.png){width="2.647222222222222in"
> height="2.647222222222222in"}
2635c4635,4636
< Figura . -- Imagens em Níveis de Cinza dos Tecidos (a) Adiposo e (b) Epitelial.
---
> Figura . -- Imagens em níveis de cinza dos tecidos (a) adiposo e (b)
> epitelial.
2637c4638,4640
< ![fzmac:Users:fz:Desktop:Sist_Intel_e\_MD:teste:hist_adip.tif](./media/image75.png){width="2.7506944444444446in" height="2.7506944444444446in"}![fzmac:Users:fz:Desktop:Sist_Intel_e\_MD:teste:hist_epit.tif](./media/image76.png){width="2.7111111111111112in" height="2.7111111111111112in"}
---
> ![fzmac:Users:fz:Desktop:Sist_Intel_e\_MD:teste:hist_adip.tif](media/image75.png){width="2.7506944444444446in"
> height="2.7506944444444446in"}![fzmac:Users:fz:Desktop:Sist_Intel_e\_MD:teste:hist_epit.tif](media/image76.png){width="2.7111111111111112in"
> height="2.7111111111111112in"}
2641c4644,4645
< Figura . -- Histogramas dos Tecidos (a) Adiposo e (b) Epitelial, das Imagens da Figura 6.12.
---
> Figura . -- Histogramas dos tecidos (a) adiposo e (b) epitelial, das
> imagens da Figura 6.12.
2643c4647,4649
< O código para ler as 10 imagens dos tecidos adiposo e epitelial é apresentado a seguir. Este código cria o arquivo "\_MEASURES.arff", que pode ser lido pelo Weka.
---
> O código para ler as 10 imagens dos tecidos adiposo e epitelial é
> apresentado a seguir. Este código cria o arquivo "\_MEASURES.arff", que
> pode ser lido pelo Weka.
2645c4651
< function script_histograma
---
> function script
2647c4653
< pasta = \[\'IMAGES/\' \]; % pasta onde estão as imagens
---
> pasta = \[\'IMAGES/\' \]; % pasta onde est„o as imagens
2649c4655
< d = dir(pasta); % comando para ler todos os arquivos de pasta
---
> d=dir(pasta); % comando para ler todos os arquivos de pasta
2653c4659
< for i = 3 : size(d,1) % para cada arquivo da pasta com final \".tif\"
---
> for i=3:size(d,1) % para cada arquivo da pasta com final \".tif\"
2655c4661
< str = \[pasta d(i).name\]
---
> str=\[pasta d(i).name\]
2661c4667
< addARFF(str); % função para adicionar o histograma em \".arff\"
---
> addARFF(str); % funÁ„o para adicionar o histograma em \".arff\"
2671c4677
< \% função para adicionar o histograma no arquivo \"\_MEASURES.arff\"
---
> \% funÁ„o para adicionar o histograma no arquivo \"\_MEASURES.arff\"
2675c4681
< img = imread(str); % ler imagem \".tif\" do disco
---
> img = imread(str); % ler imagem .tif do disco
2677c4683
< \[cont,I\] = imhist(img(:,:,2)); % calcular o histograma da imagem
---
> \[cont,I\]=imhist(img(:,:,2)); % calcular o histograma da imagem
2679c4685
< str_meas = \[\'\_MEASURES\' \'.arff\'\]; % arquivo \"\_MEASURES.arff\"
---
> str_meas = \[\'\_MEASURES\' \'.arff\'\];
2681c4687
< if fopen(str_meas,\'r\')==-1 % arquivo não existe, então crie cabeçalho
---
> if fopen(str_meas,\'r\')==-1 %arquivo n„o existe, ent„o crie cabeÁalho
2683c4689
< fid = fopen(str_meas,\'at+\');
---
> fid=fopen(str_meas,\'at+\');
2699c4705
< else % arquivo arff já existe, então inserir histograma da imagem
---
> else % arquivo arff j· existe, ent„o inserir o novo histograma
2705c4711
< \% adicionar em \"\_MEASURES.arff\" \"adip\" ou \"epit\"
---
> \% adicionao em arff \"adip\" ou \"epit\"
2717c4723
< \% adicionar em \"\_MEASURES.arff\" os 256 valores do histograma da imagem
---
> \% adiciona em arff os 256 valores do histograma
2735c4741
< fclose(fid); % fechar arquivo
---
> fclose(fid); % fecha arquivo
2739c4745
< Classificação de Imagens Usando Atributos Topológicos {#classificação-de-imagens-usando-atributos-topológicos .list-paragraph}
---
> Classificação de imagens usando atributos topológicos {#classificação-de-imagens-usando-atributos-topológicos .list-paragraph}
2742,2750c4748,4811
< Nem todas as aplicações de classificação em imagens considerando a abordagem de histograma é possível. Por exemplo, nos histogramas das imagens feliz e triste da primeira seção deste capítulo, o número de pixels com valor 1 em ambas imagens é 7, e, com valor 0, 42. Assim, não é possível usar histogramas para classificar estas imagens.
< 
< Além disso, nas imagens dos tecidos adiposo e epitelial, apresentadas na seção anterior, a facilidade na classificação usando apenas histogramas não deve ocorrer se o objetivo for analisar a topologia das células em um único tipo de tecido celular, por exemplo, para tentar prever o início de um tumor. Mais ainda, analisar a topologia celular pode auxiliar no diagnóstico do câncer, para prever se um tumor é benigno ou maligno.
< 
< Desta forma, esta seção apresenta um estudo sobre classificação em imagens considerando os atributos relacionados à topologia de objetos. Como estudo de caso, serão consideradas as mesmas 10 imagens apresentadas na seção anterior, 5 do tecido adiposo e 5 do tecido epitelial. A parte de segmentação de imagens e cálculo dos atributos de cada objeto é avançada, porém o arquivo ".arff" contendo estes dados está disponível para o leitor poder reproduzir a classificação destas 10 imagens (http://professor.ufabc.edu.br/∼fzampirolli /cells).
< 
< ### Segmentação
< 
< Uma das atividades mais importantes e complexas em visão computacional é encontrar, de forma automática, objetos em imagens, tendo como saída uma imagem em que cada objeto apresenta uma cor distinta, de forma a diferenciar um objeto de outro. Este processo pode ser chamado de segmentação em imagens.
---
> Nem todas as aplicações de classificação em imagens considerando a
> abordagem de histograma é possível. Por exemplo, se considerar
> histogramas nas imagens feliz e triste da primeira seção deste capítulo,
> o número de pixel com valor 1 em ambas imagens é 7 e com valor 0 o
> número é 42 pixels. Assim, não é possível usar histograma para
> classificar estas imagens.
> 
> Além disso, nas imagens dos tecidos adiposo e epitelial, apresentado na
> seção anterior, a facilidade na classificação usando apenas histogramas
> não deve ocorrer se o objetivo for analisar a topologia das células em
> um único tipo de tecido celular. Como exemplo, para tentar prever o
> início de um tumor. Mais ainda, analisar a topologia celular pode
> auxiliar no diagnóstico do câncer, para prever se um tumor é benigno ou
> maligno.
> 
> Desta forma, esta seção apresenta um estudo sobre classificação em
> imagens considerando os atributos relacionando à topologia de objetos.
> Como estudo de caso, serão consideradas as mesmas 10 imagens
> apresentadas na seção anterior, 5 do tecido adiposo e 5 do tecido
> epitelial.
> 
> **Segmentação**
> 
> Uma das atividades mais complexas em visão computacional é encontrar de
> forma automática objetos em imagens, tendo como saída uma imagem onde
> cada objeto apresenta uma cor distinta para poder diferenciar um objeto
> de outro. Este processo pode ser chamada de segmentação em imagens.
> 
> A segmentação nas 10 imagens dos tecidos adiposos e epitelial foram
> obtidas através de um processo semiautomáticos: em primeiro lugar um
> conjunto de transformações em imagens foram aplicadas e possível
> marcadores foram identificados de forma automática; após isso, um
> especialista usou uma interface para editar os marcadores, além de
> incluir e excluir marcadores. Todo este processo é detalhado em
> (Zampirolli *et al.*, 2010). Após a criação de um marcador para cada
> célula, foi usado uma transformação chamada Watershed, para segmentar o
> contorno de cada célula, como apresentado na Figura 6.14. Para cada
> imagem foi considerado 81 células, totalizando 810 células.
> 
> ![fzmac:Users:fz:02_Artigos:02_article:artigo2010_sibgrapi:cells:IMAGES:epithelial03_cells.jpg](media/image77.jpeg){width="2.721726815398075in"
> height="2.6338298337707786in"}
> 
> Figura . - Segmentação das células da Figura 6.13(b).
> 
> **Cálculo dos atributos**
> 
> Após a segmentação de cada imagem, é possível calcular vários atributos
> (como área, perímetro, etc.) para cada célula da imagem, usando por
> exemplo o comando ***regionprops***, apresentados a seguir (para mais
> detalhe consulte o *help* do MATLAB^®^). Outras 5 medidas, propostas por
> Chang em \[12\], também foram consideradas em de medidas em grafos, veja
> um exemplo de grafo na Figura 6.15. Consulte (Zampirolli *et al.*, 2010)
> para detalhes.
> 
> ![](media/image78.png){width="3.0214555993000873in"
> height="2.1338298337707786in"}
> 
> Figura . - Grafo de vizinhança gerado a partir da imagem segmentada.
> 
> **Classificação**
> 
> Após os cálculos dos vários atributos topológicos dos tecidos, foi
> gerado o arquivo arff, obtendo 99.8765 % e acerto na classificação, com
> a seguinte matriz de confusão:
2752,2770c4813
< A segmentação nas 10 imagens dos tecidos adiposo e epitelial foram obtidas através de um processo semiautomático: em primeiro lugar, algumas transformações em imagens foram aplicadas e possíveis marcadores foram identificados de forma automática; a seguir, um especialista usou uma interface para editar os marcadores, além de incluir e excluir certos marcadores. Todo este processo é detalhado em (ZAMPIROLLI *et al.*, 2010). Após a criação de um marcador para cada célula, foi usada uma transformação chamada *Watershed*, para segmentar o contorno de cada célula, como apresentado na Figura 6.14. Para cada imagem, foram consideradas 81 células, totalizando 810 células.
< 
< ![fzmac:Users:fz:02_Artigos:02_article:artigo2010_sibgrapi:cells:IMAGES:epithelial03_cells.jpg](./media/image77.jpeg){width="2.721726815398075in" height="2.6338298337707786in"}
< 
< Figura . - Segmentação das Células da Figura 6.12(b).
< 
< ### Cálculo dos Atributos
< 
< Após a segmentação de cada imagem, é possível calcular vários atributos (como área, perímetro, etc.) para cada célula da imagem, usando por exemplo o comando ***regionprops*** (para mais detalhes, consulte o *help* do MATLAB^®^). Outras 5 medidas foram propostas por CHANG (2005). Também foram consideradas medidas em grafos, veja um exemplo de grafo na Figura 6.15. Consulte (ZAMPIROLLI *et al.*, 2010) para detalhes.
< 
< ![](./media/image78.png){width="3.0214555993000873in" height="2.1338298337707786in"}
< 
< Figura . - Grafo de Vizinhança Gerado a partir da Imagem Segmentada.
< 
< ### Classificação 
< 
< Após os cálculos dos vários atributos topológicos dos tecidos, foi gerado o arquivo ".arff", obtendo 99.8765% de acerto na classificação, com a seguinte matriz de confusão (em http://professor.ufabc.edu.br/∼fzampirolli/cells, fazer *download* do aquivo ".arff", e seguir os seguintes passos no Weka: abrir arquivo ".arff" (*Explorer -\> open file* ) -\> *Classify -\> Choose -\> function -\> SMO -\> (Nom) class -\> Start*):
< 
< > a b \<\-- classified
---
> > a b \<\-- classified as
2776c4819
< A seguir são apresentados os pesos de cada atributo usando o SVM:
---
> A seguir é apresenta os pesos de cada atributo usando no SVM:
2815,2865c4858,4932
< O uso de aprendizado de máquina para classificar imagens é de grande importância na área de processamento digital de imagens porque geralmente produz resultados muito bons. Esta área está em crescimento devido ao avanço da tecnologia digital, demandando mais aplicações específicas. Este capítulo introduziu o uso de SVM aplicado no Reconhecimento de Padrões em imagens. Existem outros classificadores, como Redes Neurais, KNN, etc., que podem ser usados para desenvolver sistemas especialistas usando imagens.
< 
< Além disso, é possível fazer o pré-processamento e a classificação usando apenas o MATLAB^®^ , sem a necessidade de usar o Weka. Outra possibilidade é usar apenas linguagens de código aberto, como a linguagem Python, ou o Octave, no lugar do MATLAB^®^ .
< 
< Para trabalhos futuros podemos pesquisar novos atributos, além dos obtidos do histograma e de atributos geométricos de objetos segmentados na imagem, criando novas aplicações em classificação em imagens.
< 
< Lista de Exercícios
< -------------------
< 
< 1\. Reproduzir os exemplos das faces feliz e triste da primeira seção com translações aleatórias de 1, 2 e 3 pixels para a horizontal e para a vertical, para 5, 10, 50 e 100 amostras, usando o código da função imagens_aleatorias. Esta função também gera o arquivo ".arff" para ser usado no Weka. Verifique se as classificações coincidem com as apresentadas neste capítulo. Altere esta função, agora para gerar ruídos aleatórios e também verifique a classificação no Weka.
< 
< 2\. Reproduzir os exemplos de classificação usando o histograma dos tecidos epitelial e adiposo. Para isto use a função script_histograma, apresentado na segunda seção. Construa a sua própria base de imagens com pelo menos dois tipos distintos de histogramas e use esta função para verificar a sua classificação (por exemplo, fotos digitais de pessoas e de paisagens).
< 
< 3\. Além dos atributos apresentados na terceira seção para analisar a topologia dos tecidos epitelial e adiposo, sugerir mais outros atributos para tentar melhorar a classificação.
< 
< 4\. Sugerir outras aplicações de classificação de imagens e novas técnicas usadas para gerar os atributos.
< 
< Referência Bibliográfica
< ------------------------
< 
< CHANG, R.; WU, W.; MOON, W. K. & CHEN. D. **Automatic Ultrasound Segmentation and Morphology Based Diagnosis of Solid Breast Tumors**. Breast Cancer Research and Treatment, 89:179--18, 2005.
< 
< +--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
< | WOODS, R. E. & GONZALEZ, R. C. **Processamento Digital De Imagens** - 3ª Ed. Pearson Education -- Br -- 2011.                                                                                                            |
< |                                                                                                                                                                                                                          |
< | ZAMPIROLLI, F. A.; STRANSKY, B.; LORENA, A. C. & PAULON, F. L. D. M.: **Segmentation and Classification of Histological Images - Application of Graph Analysis and Machine Learning Methods.** In SIBGRAPI(2010)331-338. |
< +--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
< 
< **Equipamento promete melhorar diagnóstico do câncer de pele. In http://noticias.bol.uol.com.br/ultimas-noticias/ciencia/2013/08/07/equipamento -promete-melhorar-diagnostico-do-cancer-de-pele.htm. Acessado em 08.08.13.**
< 
< **Hospital de Ribeirão Preto usa sistema nacional para arquivar e gerenciar imagens médicas.** In http://revistapesquisa.fapesp.br/2013/07/12/acesso-digital. **Acessado em 08.08.13.**
< 
< **Mineração de dados por imagens auxilia diagnóstico médico. In http://www.usp.br/agen/?p=100292. Acessado em 08.08.13.**
< 
< **MATLAB^®^**. The Language of Technical Computing. In http://www.mathworks .com/products/matlab. Acessado em 15.08.13.
< 
< **Weka**. The Waikato University. In http://www.cs.waikato.ac.nz/ml/weka. Acessado em 03.03.13.
< 
< [^1]: Fonte: http://en.wikipedia.org/wiki/File:Iris_virginica.jpg (Acessado em 19.02.13).
< 
< [^2]: Fonte: http://en.wikipedia.org/wiki/File:Iris_versicolor_3.jpg (Acessado em 19.02.13).
< 
< [^3]: Fonte: http://en.wikipedia.org/wiki/File:Kosaciec_szczecinkowaty_Iris_setosa.jpg (Acessado em 19.02.13).
< 
< [^4]: Fonte: http://en.wikipedia.org/wiki/File:Iris_virginica.jpg (Acessado em 19.02.13).
< 
<     Fonte: http://en.wikipedia.org/wiki/File:Kosaciec_szczecinkowaty_Iris_setosa.jpg (Acessado em 19.02.13).
< 
<     Fonte: http://en.wikipedia.org/wiki/File:Iris_versicolor_3.jpg . (Acessado em 19.02.13).
< 
< [^5]: Em inglês, o termo *"neural"* é usado tanto para tópicos do sistema nervoso quanto para neurônios. Em português, no entanto, temos dois adjetivos distintos: neuronal e neural, sendo este último relacionado a nervos e ao sistema nervoso em geral. Como a inspiração inicial para as *"neural networks"* foram os neurônios, a tradução mais adequada para o português deveria ser "redes neuronais", mas como "redes neurais" acabou prevalecendo, vamos manter esta terminologia.
---
> Usar aprendizado de máquina para classificar imagens é de grande
> importância. Esta área esta em crescimento devido ao avanço da
> tecnologia, demando mais aplicações. Este capítulo introduz o uso de SVM
> aplicado no reconhecimento de padrões em imagens. Existem outros
> classificadores, como Redes Neurais, KNN, etc., que podem ser usados
> para desenvolver sistemas especialista usando imagens.
> 
> Outra possibilidade em trabalhos futuros é pesquisar novos atributos,
> além dos atributos obtidos do histograma e de atributos geométricos de
> objetos segmentados na imagem.
> 
> Referências Bibliográficas
> --------------------------
> 
> CHANG, R.,WU, W. , MOON, W. K., CHEN. D. **Automatic ultrasound
> segmentation and morphology based diagnosis of solid breast tumors**.
> Breast Cancer Research and Treatment, 89:179--18, 2005.
> 
> +----------------------------------------------------------------------+
> | Woods, Richard E.; Woods, Richard E.; Gonzalez, Rafael C.; Gonzalez, |
> | Rafael C. **Processamento Digital De Imagens** - 3ª Ed. Pearson      |
> | Education -- Br -- 2011.                                             |
> |                                                                      |
> | Zampirolli, F.A., Stransky, B., Lorena, A.C., Paulon, F.L.D.M.:      |
> | **Segmentation and Classification of Histological Images -           |
> | Application of Graph Analysis and Machine Learning Methods.** ;In    |
> | SIBGRAPI(2010)331-338                                                |
> +----------------------------------------------------------------------+
> 
> **Equipamento promete melhorar diagnóstico do câncer de pele. In
> <http://noticias.bol.uol.com.br/ultimas-noticias/ciencia/2013/08/07/equipamento-promete-melhorar-diagnostico-do-cancer-de-pele.htm>.
> Acessado em 08.08.13.**
> 
> **Hospital de Ribeirão Preto usa sistema nacional para arquivar e
> gerenciar imagens médicas.** In
> <http://revistapesquisa.fapesp.br/2013/07/12/acesso-digital>. **Acessado
> em 08.08.13.**
> 
> **Mineração de dados por imagens auxilia diagnóstico medico. In
> <http://www.usp.br/agen/?p=100292>. Acessado em 08.08.13.**
> 
> **MATLAB^®^**. The Language of Technical Computing. In
> <http://www.mathworks.com/products/matlab>. Acessado em 15.08.13.
> 
> **Weka**. The Waikato University. In
> <http://www.cs.waikato.ac.nz/ml/weka> . Acessado em 03.03.13.
> 
> [^1]: Fonte: http://en.wikipedia.org/wiki/File:Iris_virginica.jpg
>     (Acessado em 19.02.13).
> 
> [^2]: Fonte: http://en.wikipedia.org/wiki/File:Iris_versicolor_3.jpg
>     (Acessado em 19.02.13).
> 
> [^3]: Fonte:
>     http://en.wikipedia.org/wiki/File:Kosaciec_szczecinkowaty_Iris_setosa.jpg
>     (Acessado em 19.02.13).
> 
> [^4]: Fonte: http://en.wikipedia.org/wiki/File:Iris_virginica.jpg
>     (Acessado em 19.02.13).
> 
>     Fonte:
>     http://en.wikipedia.org/wiki/File:Kosaciec_szczecinkowaty_Iris_setosa.jpg
>     (Acessado em 19.02.13).
> 
>     Fonte: http://en.wikipedia.org/wiki/File:Iris_versicolor_3.jpg .
>     (Acessado em 19.02.13).
> 
> [^5]: Em inglês, o termo *"neural"* é usado tanto para tópicos do
>     sistema nervoso quanto para neurônios. Em português, no entanto,
>     temos dois adjetivos distintos: neuronal e neural, sendo este último
>     relacionado a nervos e ao sistema nervoso em geral. Como a
>     inspiração inicial para as *"neural networks"* foram os neurônios, a
>     tradução mais adequada para o português deveria ser "redes
>     neuronais", mas como "redes neurais" acabou prevalecendo, vamos
>     manter esta terminologia.
2867c4934,4935
< [^6]: O *Perceptron* é um tipo de Rede Neural simples, com apenas uma camada de neurônios.
---
> [^6]: O *Perceptron* é um tipo de Rede Neural simples, com apenas uma
>     camada de neurônios.
2871c4939,4941
< [^8]: Embora o termo "*kernel*" possa ser perfeitamente traduzido para o português como "núcleo", a tradução não parece ter prevalecido por aqui, sendo mais comum a utilização de *kernel*.
---
> [^8]: Embora o termo "*kernel*" possa ser perfeitamente traduzido para o
>     português como "núcleo", a tradução não parece ter prevalecido por
>     aqui, sendo mais comum a utilização de *kernel*.
